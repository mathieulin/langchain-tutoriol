{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e5490ab7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T08:44:52.208086Z",
     "start_time": "2023-10-09T08:44:52.201161800Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.chains.question_answering import load_qa_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d300f1",
   "metadata": {},
   "source": [
    "### Load Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b2b457c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T08:44:57.793915400Z",
     "start_time": "2023-10-09T08:44:54.610215Z"
    }
   },
   "outputs": [],
   "source": [
    "sm_loader = UnstructuredFileLoader(\"../data/muir_lake_tahoe_in_winter.txt\")\n",
    "sm_doc = sm_loader.load()\n",
    "\n",
    "lg_loader = UnstructuredFileLoader(\"../data/PaulGrahamEssays/worked.txt\")\n",
    "lg_doc = lg_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader, PyPDFLoader\n",
    "loader = PyPDFLoader(\"../data/Word-As-Image for Semantic Typography.pdf\")\n",
    "lg_doc = loader.load()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T08:44:59.439094300Z",
     "start_time": "2023-10-09T08:44:57.793915400Z"
    }
   },
   "id": "57646b6df76796e9"
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "10ff8c9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T08:45:03.828126200Z",
     "start_time": "2023-10-09T08:45:03.814128300Z"
    }
   },
   "outputs": [],
   "source": [
    "def doc_summary(docs):\n",
    "    print (f'You have {len(docs)} document(s)')\n",
    "    \n",
    "    num_words = sum([len(doc.page_content.split(' ')) for doc in docs])\n",
    "    \n",
    "    print (f'You have roughly {num_words} words in your docs')\n",
    "    print ()\n",
    "    print (f'Preview: \\n{docs[0].page_content.split(\". \")[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b92effa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T08:40:01.554482100Z",
     "start_time": "2023-10-09T08:40:01.537522800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 28 document(s)\n",
      "You have roughly 7985 words in your docs\n",
      "\n",
      "Preview: \n",
      "Word-As-Image for Semantic Typography\n",
      "Shir Iluz∗\n",
      "Tel-Aviv University, IsraelYael Vinker∗\n",
      "Tel-Aviv University, IsraelAmir Hertz\n",
      "Tel-Aviv University, Israel\n",
      "Daniel Berio\n",
      "Goldsmiths University, LondonDaniel Cohen-Or\n",
      "Tel-Aviv University, IsraelAriel Shamir\n",
      "Reichman University, Israel\n",
      "Fig\n"
     ]
    }
   ],
   "source": [
    "doc_summary(sm_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fa39e1b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T08:45:06.156528700Z",
     "start_time": "2023-10-09T08:45:06.142151800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 28 document(s)\n",
      "You have roughly 7985 words in your docs\n",
      "\n",
      "Preview: \n",
      "Word-As-Image for Semantic Typography\n",
      "Shir Iluz∗\n",
      "Tel-Aviv University, IsraelYael Vinker∗\n",
      "Tel-Aviv University, IsraelAmir Hertz\n",
      "Tel-Aviv University, Israel\n",
      "Daniel Berio\n",
      "Goldsmiths University, LondonDaniel Cohen-Or\n",
      "Tel-Aviv University, IsraelAriel Shamir\n",
      "Reichman University, Israel\n",
      "Fig\n"
     ]
    }
   ],
   "source": [
    "doc_summary(lg_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d922dfa",
   "metadata": {},
   "source": [
    "### Load Your LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "daf7e272",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T08:45:08.682893800Z",
     "start_time": "2023-10-09T08:45:08.669924100Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e6b576c6",
   "metadata": {
    "hide_input": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T08:45:09.130884700Z",
     "start_time": "2023-10-09T08:45:09.096660Z"
    }
   },
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "182a2951",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T08:45:09.613942800Z",
     "start_time": "2023-10-09T08:45:09.584510200Z"
    }
   },
   "outputs": [],
   "source": [
    "llm = OpenAI(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6515044",
   "metadata": {},
   "source": [
    "### Summarize: Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "020b276d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T08:45:12.525462900Z",
     "start_time": "2023-10-09T08:45:12.510993300Z"
    }
   },
   "outputs": [],
   "source": [
    "chain = load_summarize_chain(llm, chain_type=\"stuff\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1ee5d17f",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-09T08:40:27.222028400Z",
     "start_time": "2023-10-09T08:40:24.436144100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new StuffDocumentsChain chain...\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"Word-As-Image for Semantic Typography\n",
      "Shir Iluz∗\n",
      "Tel-Aviv University, IsraelYael Vinker∗\n",
      "Tel-Aviv University, IsraelAmir Hertz\n",
      "Tel-Aviv University, Israel\n",
      "Daniel Berio\n",
      "Goldsmiths University, LondonDaniel Cohen-Or\n",
      "Tel-Aviv University, IsraelAriel Shamir\n",
      "Reichman University, Israel\n",
      "Fig. 1. A few examples of our word-as-image illustrations in various fonts and for different textual concept. The semantically adjusted letters are created\n",
      "completely automatically using our method, and can then be used for further creative design as we illustrate here.\n",
      "A word-as-image is a semantic typography technique where a word illus-\n",
      "tration presents a visualization of the meaning of the word, while also\n",
      "preserving its readability. We present a method to create word-as-image\n",
      "illustrations automatically. This task is highly challenging as it requires\n",
      "semantic understanding of the word and a creative idea of where and how to\n",
      "depict these semantics in a visually pleasing and legible manner. We rely on\n",
      "the remarkable ability of recent large pretrained language-vision models to\n",
      "distill textual concepts visually. We target simple, concise, black-and-white\n",
      "designs that convey the semantics clearly. We deliberately do not change the\n",
      "color or texture of the letters and do not use embellishments. Our method\n",
      "optimizes the outline of each letter to convey the desired concept, guided by\n",
      "a pretrained Stable Diffusion model. We incorporate additional loss terms\n",
      "to ensure the legibility of the text and the preservation of the style of the\n",
      "font. We show high quality and engaging results on numerous examples\n",
      "and compare to alternative techniques.\n",
      "Code will be available at our project page.\n",
      "1 INTRODUCTION\n",
      "Semantic typography is the practice of using typography to visually\n",
      "reinforce the meaning of text. This can be achieved through the\n",
      "choice of typefaces, font sizes, font styles, and other typographic\n",
      "elements. A more elaborate and engaging technique for semantic\n",
      "typography is presented by word-as-image illustrations, where the\n",
      "semantics of a given word are illustrated using only the graphical\n",
      "elements of its letters. Such illustrations provide a visual repre-\n",
      "sentation of the meaning of the word, while also preserving the\n",
      "readability of the word as a whole.\n",
      "The task of creating a word-as-image is highly challenging, as it\n",
      "requires the ability to understand and depict the visual characteris-\n",
      "tics of the given concept, and to convey them in a concise, aesthetic,\n",
      "and comprehensible manner without harming legibility. It requires\n",
      "∗Denotes equal contribution.a great deal of creativity and design skills to integrate the chosen\n",
      "visual concept into the letter’s shape [Lee 2011]. In Figure 2 we show\n",
      "some word-as-image examples created manually. For example, to\n",
      "create the “jazz” depiction, the designer had to first choose the visual\n",
      "concept that would best fit the semantics of the text (a saxophone),\n",
      "consider the desired font characteristics, and then choose the most\n",
      "suitable letter to be replaced. Finding the right visual element to\n",
      "illustrate a concept is ill-defined as there are countless ways to il-\n",
      "lustrate any given concept. In addition, one cannot simply copy a\n",
      "selected visual element onto the word – there is a need to find subtle\n",
      "modifications of the letters shape.\n",
      "Because of these complexities, the task of automatic creation of\n",
      "word-as-image illustrations was practically impossible to achieve\n",
      "using computers until recently. In this paper, we define an algo-\n",
      "rithm for automatic creation of word-as-image illustrations based\n",
      "on recent advances in deep-learning and the availability of huge\n",
      "foundational models that combine language and visual understand-\n",
      "ing. Our resulting illustrations (see Figure 1) could be used for logo\n",
      "design, for signs, in greeting cards and invitations, and simply for\n",
      "fun. They can be used as-is, or as inspiration for further refinement\n",
      "of the design.\n",
      "Existing methods in the field of text stylization often rely on raster\n",
      "textures [Yang et al .2018], place a manually created style on top\n",
      "of the strokes segmentation [Berio et al .2022], or deform the text\n",
      "into a pre-defined target shape [Zou et al .2016] (see Figure 3). Only\n",
      "a few works [Tendulkar et al .2019; Zhang et al .2017] deal with\n",
      "semantic typography, and they often operate in the raster domain\n",
      "and use existing icons for replacement (see Figure 3E).\n",
      "Our word-as-image illustrations concentrate on changing only\n",
      "thegeometry of the letters to convey the meaning. We deliberately\n",
      "do not change color or texture and do not use embellishments. ThisarXiv:2303.01818v2  [cs.CV]  6 Mar 2023\n",
      "\n",
      "2•Shir Iluz, Yael Vinker, Amir Hertz, Daniel Berio, Daniel Cohen-Or, and Ariel Shamir\n",
      "Fig. 2. Manually created word-as-image illustrations.\n",
      "allows simple, concise, black-and-white designs that convey the\n",
      "semantics clearly. In addition, since we preserve the vector-based\n",
      "representation of the letters, this allows smooth rasterization in\n",
      "any size, as well as applying additional style manipulations to the\n",
      "illustration using colors and texture, if desired.\n",
      "Given an input word, our method is applied separately for each\n",
      "letter, allowing the user to later choose the most likeable combina-\n",
      "tion for replacement. We represent each letter as a closed vectorized\n",
      "shape, and optimize its parameters to reflect the meaning of the\n",
      "word, while still preserving its original style and design.\n",
      "We rely on the prior of a pretrained Stable Diffusion model [Rom-\n",
      "bach et al .2021] to connect between text and images, and utilize\n",
      "the Score Distillation Sampling approach [Poole et al .2022] (see\n",
      "Section 3) to encourage the appearance of the letter to reflect the\n",
      "provided textual concept. Since the Stable Diffusion model is trained\n",
      "on raster images, we use a differentiable rasterizer [Li et al .2020]\n",
      "that allows to backpropagate gradients from a raster-based loss to\n",
      "the shape’s parameters.\n",
      "To preserve the shape of the original letter and ensure legibility\n",
      "of the word, we utilize two additional loss functions. The first loss\n",
      "regulates the shape modification by constraining the deformation\n",
      "to be as-conformal-as-possible over a triangulation of the letter’s\n",
      "shape. The second loss preserves the local tone and structure of the\n",
      "letter by comparing the low-pass filter of the resulting rasterized\n",
      "letter to the original one.\n",
      "We compare to several baselines, and present many results using\n",
      "various typefaces and a large number of concepts. Our word-as-\n",
      "image illustrations convey the intended concept while maintaining\n",
      "legibility and preserving the appearance of the font, demonstrating\n",
      "visual creativity.\n",
      "2 RELATED WORK\n",
      "Text Stylization. One approach to text stylization is artistic text\n",
      "style transfer, where the style from a given source image is migrated\n",
      "into the desired text (such as in Figure 3A). To tackle this task,\n",
      "existing works incorporate patch-based texture synthesis [Fish et al .\n",
      "2020; Yang et al .2017] as well as variants of GANs [Azadi et al .\n",
      "2018; Jiang et al .2019; Mao et al .2022; Wang et al .2019; Yang et al .\n",
      "2022]. These works operate within the raster domain, a format that\n",
      "is undesirable for typographers since fonts must be scalable. In\n",
      "contrast, we operate on the parametric outlines of the letters, and\n",
      "our glyph manipulation is guided by the semantic meaning of the\n",
      "word, rather than a pre-defined style image.\n",
      "A number of works [Ha and Eck 2018; Lopes et al .2019; Wang\n",
      "and Lian 2021] tackle the task of font generation and stylization\n",
      "in the vector domain. Commonly, a latent feature space of font’s\n",
      "outlines is constructed, represented as outline samples [Balashova\n",
      "et al.2019; Campbell and Kautz 2014] or parametric curve segments\n",
      "[Ha and Eck 2018; Lopes et al .2019; Wang and Lian 2021]. These\n",
      "Fig. 3. Examples of previous text stylization works – (A) Yang et al. [2018],\n",
      "(B) Berio et al. [2022], (C) Zhang et al. [2017], (D) Zou et al. [2016], and (E)\n",
      "Tendulkar et al. [2019]. Most use color and texture or copy icons onto the\n",
      "letters. Our work concentrates on subtle geometric shape deformations of\n",
      "the letters to convey the semantic meaning without color or texture (that\n",
      "can be added later).\n",
      "approaches are often limited to mild deviations from the input data.\n",
      "Other methods rely on templates [Lian et al .2018; Suveeranont and\n",
      "Igarashi 2010] or on user guided [Phan et al .2015] and automatic\n",
      "[Berio et al .2022] stroke segmentation to produce letter stylization\n",
      "(such as in Figure 3B). However, they rely on a manually defined\n",
      "style, while we rely on the expressiveness of Stable Diffusion to\n",
      "guide the modification of the letters’ shape, to convey the meaning\n",
      "of the provided word. In the task of calligram generation [Xu and\n",
      "Kaplan 2007; Zou et al .2016] the entire word is deformed into a\n",
      "given target shape. This task prioritises shape over the readability\n",
      "of the word (see Figure 3D), and is inherently different from ours,\n",
      "as we use the semantics of the word to derive the deformation of\n",
      "individual letters.\n",
      "Most related to our goal, are works that perform semantic styl-\n",
      "ization of text. Tendulkar et al .[2019] replace letters in a given\n",
      "word with clip-art icons describing a given theme (see Figure 3E).\n",
      "To choose the most suitable icon for replacement, an autoencoder\n",
      "is used to measure the distance between the letter and icons from\n",
      "the desired class. Similarly, Zhang et al .[2017] replace stroke-like\n",
      "parts of one or more letters with instances of clip art to generate\n",
      "ornamental stylizations. An example is shown in Figure 3C. These\n",
      "approaches operate in the raster domain, and replace letters with\n",
      "existing icons, which limits them to a predefined set of classes\n",
      "present in the dataset. Our method, however, operates in the vector\n",
      "domain, and incorporates the expressiveness of large pretrained\n",
      "image-language models to create a new illustration that conveys\n",
      "the desired concept.\n",
      "Large Language-Vision Models. With the recent advancement of\n",
      "language-vision models [Radford et al .2021] and diffusion mod-\n",
      "els [Nichol et al .2021; Ramesh et al .2022; Rombach et al .2021], the\n",
      "field of image generation and editing has undergone unprecedented\n",
      "evolution. Having been trained on millions of images and text pairs,\n",
      "these models have proven effective for performing challenging vi-\n",
      "sion related tasks such as image segmentation [Amit et al .2021],\n",
      "domain adaptation [Song et al .2022], image editing [Avrahami et al .\n",
      "2022; Hertz et al .2022; Tumanyan et al .2022a], personalization [Gal\n",
      "\n",
      "Word-As-Image for Semantic Typography •3\n",
      "Fig. 4. More word-as-images produced by our method. Note how styles of\n",
      "different fonts are preserved by the semantic modification.\n",
      "et al.2022, 2023; Ruiz et al .2022], and explainability [Chefer et al .\n",
      "2021]. Despite being trained on raster images, their strong visual\n",
      "and semantic priors have also been shown to be successfully applied\n",
      "to other domains, such as motion [Tevet et al .2022], meshes [Michel\n",
      "et al.2021], point cloud [Zhang et al .2021], and vector graphics.\n",
      "CLIPDraw [Frans et al .2021] uses a differentiable rasterizer [Li\n",
      "et al.2020] to optimize a set of colorful curves w.r.t. a given text\n",
      "prompt, guided by CLIP’s image-text similarity metric. Tian and Ha\n",
      "[2021] use evolutionary algorithms combined with CLIP guidance to\n",
      "create abstract visual concepts based on text. Other works [Vinker\n",
      "et al.2022a,b] utilize the image encoder of CLIP to generate abstract\n",
      "vector sketches from images.\n",
      "Diffusion models have been used for the task of text guided image-\n",
      "to-image translation [Choi et al .2021; Tumanyan et al .2022b]. In\n",
      "SDEdit [Meng et al .2022], an adequate amount of noise is added\n",
      "to a reference image, such that its overall structure is preserved,\n",
      "and then the image is denoised in a reverse process with a guiding\n",
      "text. Pretrained diffusion models have also been used to generate\n",
      "3D objects [Metzer et al .2022; Poole et al .2022], or vector art [Jain\n",
      "et al. 2022] conditioned on text.\n",
      "In our work we also utilize the strong visual and semantic prior\n",
      "induced by a pretrained Stable Diffusion model [Rombach et al .\n",
      "2021], however, for the task of semantic typography . For that purpose\n",
      "we add new components to the optimization process to preserve\n",
      "the font’s style and text legibility.\n",
      "3 BACKGROUND\n",
      "3.1 Fonts and Vector Representation\n",
      "Modern typeface formats such as TrueType [Penney 1996] and\n",
      "PostScript [Inc. 1990] represent glyphs using a vectorized graphic\n",
      "representation of their outlines. Specifically, the outline contours are\n",
      "typically represented by a collection of lines and Bézier or B-Spline\n",
      "curves. This representation allows to scale the letters and rasterize\n",
      "them in any desired size similar to other vector representations.\n",
      "This property is preserved by our method as our output preserves\n",
      "the vectorized representations of the letters.3.2 Latent Diffusion Models\n",
      "Diffusion models are generative models that are trained to learn\n",
      "a data distribution by the gradual denoising of a variable sampled\n",
      "from a Gaussian distribution.\n",
      "In our work, we use the publicly available text-to-image Stable\n",
      "Diffusion model [Rombach et al .2021]. Stable Diffusion is a type of\n",
      "a latent diffusion model (LDM), where the diffusion process is done\n",
      "over the latent space of a pretrained image autoencoder. The encoder\n",
      "Eis tasked with mapping an input image 𝑥into a latent vector 𝑧,\n",
      "and the decoderDis trained to decode 𝑧such thatD(𝑧)≈𝑥.\n",
      "As a second stage, a denoising diffusion probabilistic model (DDPM)\n",
      "[Ho et al .2020] is trained to generate codes within the learned latent\n",
      "space. At each step during training, a scalar 𝑡∈{1,2,...𝑇}is uni-\n",
      "formly sampled and used to define a noised latent code 𝑧𝑡=𝛼𝑡𝑧+𝜎𝑡𝜖,\n",
      "where𝜖∼N( 0,𝐼)and𝛼𝑡,𝜎𝑡are terms that control the noise sched-\n",
      "ule, and are functions of the diffusion process time 𝑡.\n",
      "The denoising network 𝜖𝜃which is based on a UNet architecture\n",
      "[Ronneberger et al .2015], receives as input the noised code 𝑧𝑡, the\n",
      "timestep𝑡and an optional condition vector 𝑐(𝑦), and is tasked with\n",
      "predicting the added noise 𝜖. The LDM loss is defined by:\n",
      "L𝐿𝐷𝑀=E𝑧∼E(𝑥),𝑦,𝜖∼N( 0,1),𝑡\u0002\n",
      "||𝜖−𝜖𝜃(𝑧𝑡,𝑡,𝑐(𝑦))||2\n",
      "2\u0003\n",
      ".(1)\n",
      "In Stable Diffusion, for text-to-image generation, the condition\n",
      "vector is the text embedding produced by a pre-trained CLIP text\n",
      "encoder [Radford et al .2021]. At inference time, a random latent\n",
      "code𝑧𝑇∼N( 0,𝐼)is sampled, and iteratively denoised by the trained\n",
      "𝜖𝜃until producing a clean 𝑧0latent code, which is passed through\n",
      "the decoder 𝐷to produce the image 𝑥.\n",
      "3.3 Score Distillation\n",
      "It is desirable to utilize the strong prior of pretrained large text-\n",
      "image models for the generation of modalities beyond rasterized\n",
      "images. In Stable Diffusion, text conditioning is performed via the\n",
      "cross-attention layers defined at different resolutions in the UNet\n",
      "network. Thus, it is not trivial to guide an optimization process\n",
      "using the conditioned diffusion model.\n",
      "DreamFusion [Poole et al .2022] proposed a way to use the diffu-\n",
      "sion loss to optimize the parameters of a NeRF model for text-to-3D\n",
      "generation. At each iteration, the radiance field is rendered from a\n",
      "random angle, forming the image 𝑥, which is then noised to form\n",
      "𝑥𝑡=𝛼𝑡𝑥+𝜎𝑡𝜖. The noised image is then passed to the pretrained\n",
      "UNet model of Imagen [Saharia et al .2022], that outputs the pre-\n",
      "diction of the noise 𝜖. The score distillation loss is defined by the\n",
      "gradients of the original diffusion loss:\n",
      "∇𝜙L𝑆𝐷𝑆=\u0014\n",
      "𝑤(𝑡)(𝜖𝜃(𝑥𝑡,𝑡,𝑦)−𝜖)𝜕𝑥\n",
      "𝜕𝜙\u0015\n",
      "(2)\n",
      "where𝑦is the condition text prompt, 𝜙are the NeRF’s parameters\n",
      "and𝑤(𝑡)is a constant multiplier that depends on 𝛼𝑡. During train-\n",
      "ing, the gradients are back-propagated to the NeRF parameters to\n",
      "gradually change the 3D object to fit the text prompt. Note that the\n",
      "gradients of the UNet are skipped, and the gradients to modify the\n",
      "Nerf’s parameters are derived directly from the LDM loss.\n",
      "\n",
      "4•Shir Iluz, Yael Vinker, Amir Hertz, Daniel Berio, Daniel Cohen-Or, and Ariel Shamir\n",
      "zt~[50,950]z!“Surfing * “\n",
      "CLIPAugment..Encoder\n",
      "zUNet\n",
      "DiffVG𝑝!𝑝\"𝑝#!𝑝!𝑝\"𝑝#!\n",
      "LPF\n",
      "LPF\n",
      "13\n",
      "2\n",
      "𝑃=𝑃\"=\n",
      "𝑙!𝑙!$\n",
      "𝒟\n",
      "𝒟\n",
      "Fig. 5. An overview of our method. Given an input letter 𝑙𝑖represented by a set of control points 𝑃, and a concept (shown in purple), we optimize the new\n",
      "positions ˆ𝑃of the deformed letter ˆ𝑙𝑖iteratively. At each iteration, the set ˆ𝑃is fed into a differentiable rasterizer (DiffVG marked in blue) that outputs the\n",
      "rasterized deformed letter ˆ𝑙𝑖.ˆ𝑙𝑖is then augmented and passed into a pretrained frozen Stable Diffusion model, that drives the letter shape to convey the\n",
      "semantic concept using the ∇ˆ𝑃LLSDS loss (1).𝑙𝑖and ˆ𝑙𝑖are also passed through a low pass filter (LPF marked in yellow) to compute L𝑡𝑜𝑛𝑒 (2) which encourages\n",
      "the preservation of the overall tone of the font style and also the local letter shape. Additionally, the sets 𝑃and ˆ𝑃are passed through a Delaunay triangulation\n",
      "operator (Dmarked in green), defining L𝑎𝑐𝑎𝑝 (3) which encourages the preservation of the initial shape.\n",
      "3.4 VectorFusion\n",
      "Recently, VectorFusion [Jain et al .2022] utilized the SDS loss for the\n",
      "task of text-to-SVG generation. The proposed generation pipeline\n",
      "involves two stages. Given a text prompt, first, an image is generated\n",
      "using Stable Diffusion (with an added suffix to the prompt), and\n",
      "is then vectorized automatically using LIVE [Ma et al .2022]. This\n",
      "defines an initial set of parameters to be optimized in the second\n",
      "stage using the SDS loss. At each iteration, a differentiable rasterizer\n",
      "[Li et al. 2020] is used to produce a 600×600image, which is then\n",
      "augmented as suggested in CLIPDraw [Frans et al .2021] to get a\n",
      "512×512image𝑥𝑎𝑢𝑔. Then𝑥𝑎𝑢𝑔is fed into the pretrained encoder\n",
      "Eof Stable Diffusion to produce the corresponding latent code\n",
      "𝑧=E(𝑥𝑎𝑢𝑔). The SDS loss is then applied in this latent space, in a\n",
      "similar way to the one defined in DreamFusion:\n",
      "∇𝜃LLSDS=E𝑡,𝜖\u0014\n",
      "𝑤(𝑡)\u0010\n",
      "ˆ𝜖𝜙(𝛼𝑡𝑧𝑡+𝜎𝑡𝜖,𝑦)−𝜖\u0011𝜕𝑧\n",
      "𝜕𝑧𝑎𝑢𝑔𝜕𝑥𝑎𝑢𝑔\n",
      "𝜕𝜃\u0015\n",
      "(3)\n",
      "We find the SDS approach useful for our task of producing se-\n",
      "mantic glyphs, and we follow the technical steps proposed in Vec-\n",
      "torFusion (e.g. augmentations and the added suffix).\n",
      "4 METHOD\n",
      "Given a word 𝑊represented as a string with 𝑛letters{𝑙1,...𝑙𝑛}, our\n",
      "method is applied to every letter 𝑙𝑖separately to produce a semantic\n",
      "visual depiction of the letter. The user can then choose which letters\n",
      "to replace and which to keep in their original form.\n",
      "4.1 Letter Representation\n",
      "We begin by defining the parametric representation of the letters\n",
      "in𝑊. We use the FreeType font library [FreeType 2009] to extract\n",
      "the outline of each letter. We then translate each outline into a set\n",
      "of cubic Bézier curves, to have a consistent representation across\n",
      "different fonts and letters, and to facilitate the use of diffvg [Li et al .\n",
      "2020] for differentiable rasterization.\n",
      "Fig. 6. Illustration of the letter’s outline and control points before (left) and\n",
      "after (right) the subdivision process. The orange dots are the initial Bézier\n",
      "curve segment endpoints. The blue dots are the remaining control points\n",
      "respectively before and after subdivision.\n",
      "Depending on the letter’s complexity and the style of the font,\n",
      "the extracted outlines are defined by a different number of control\n",
      "points. We have found that the initial number of control points\n",
      "affects the final appearance significantly: as the number of control\n",
      "points increases, there is more freedom for visual changes to occur.\n",
      "Therefore, we additionally apply a subdivision procedure to letters\n",
      "containing a small number of control points. We define a desired\n",
      "number of control points for each letter of the alphabet (shared\n",
      "across different fonts), and then iteratively subdivide the Bézier\n",
      "segments until reaching this target number. At each iteration, we\n",
      "compute the maximum arc length among all Bézier segments and\n",
      "split each segment with this length into two (see Figure 6). We\n",
      "analyse the effect of the number of control points in Section 5.3.\n",
      "This procedure defines a set of 𝑘𝑖control points 𝑃𝑖={𝑝𝑗}𝑘𝑖\n",
      "𝑗=1\n",
      "representing the shape of the letter 𝑙𝑖.\n",
      "4.2 Optimization\n",
      "The pipeline of our method is provided in Figure 5. Since we are\n",
      "optimizing each letter 𝑙𝑖separately, for brevity, we will omit the\n",
      "letter index𝑖in the following text and define the set of control points\n",
      "for the input letter as 𝑃.\n",
      "Given𝑃and the desired textual concept 𝑐(both marked in purple\n",
      "in Figure 5), our goal is to produce a new set of control points, ˆ𝑃,\n",
      "\n",
      "Word-As-Image for Semantic Typography •5\n",
      "Fig. 7. Visual illustration of the constraint Delaunay triangulation applied\n",
      "to the initial shapes (left) and the resulting ones (right), for the word “pants”.\n",
      "The ACAP loss maintains the structure of the letter after the deformation.\n",
      "The zoomed rectangle shows the angles for a given control point 𝑝𝑗.\n",
      "defining an adjusted letter ˆ𝑙that conveys the given concept, while\n",
      "maintaining the overall structure and characteristics of the initial\n",
      "letter𝑙.\n",
      "We initialize the learned set of control points ˆ𝑃with𝑃, and pass\n",
      "it through a differentiable rasterizer R[Li et al .2020] (marked in\n",
      "blue), which outputs the rasterized letter R(ˆ𝑃). The rasterized letter\n",
      "is then randomly augmented and passed into a pretrained Stable\n",
      "Diffusion [Rombach et al .2021] model, conditioned on the CLIP’s\n",
      "embedding of the given text 𝑐. The SDS loss∇ˆ𝑃LLSDS is then used\n",
      "as described in Section 3 to encourage R(ˆ𝑃)to convey the given\n",
      "text prompt.\n",
      "To preserve the shape of each individual letter and ensure the\n",
      "legibility of the word as a whole, we use two additional loss functions\n",
      "to guide the optimization process. The first loss limits the overall\n",
      "shape change by defining as-conformal-as-possible constraint on\n",
      "the shape deformation. The second loss preserves the overall shape\n",
      "and style of the font by constraining the tone (i.e. amount of dark\n",
      "vs. light areas in local parts of the shape) of the modified letter not\n",
      "to diverge too much from the original letter (see Section 4.3).\n",
      "The gradients obtained from all the losses are then backpropa-\n",
      "gated, to update the parameters ˆ𝑃. We repeat this process for 500\n",
      "steps, which takes∼5minutes to produce a single letter illustration\n",
      "on RTX2080 GPU.\n",
      "4.3 Loss Functions\n",
      "Our primary objective of encouraging the resulting shape to con-\n",
      "vey the intended semantic concept, is utilized by ∇ˆ𝑃LLSDS loss\n",
      "(described in Section 3). We observe that using ∇ˆ𝑃LLSDS solely can\n",
      "cause large deviations from the initial letter appearance, which is\n",
      "undesired. Hence, our additional goal is to maintain the shape and\n",
      "legibility of the letter R(ˆ𝑃), as well as to keep the original font’s\n",
      "characteristics. For that purpose we use two additional losses.\n",
      "As-Conformal-As-Possible Deformation Loss. To prevent the final\n",
      "letter shape from diverging too much from the initial shape, we\n",
      "triangulate the inner part of the letter and constrain the deformation\n",
      "of the letter to be as conformal as possible (ACAP) [Hormann and\n",
      "Greiner 2000]. We use constrained Delaunay triangulation [Barber\n",
      "and Huhdanpaa 1995; Delaunay et al .1934] on the set of control\n",
      "points defining the glyph. It is known that Delaunay triangulation\n",
      "can be used to produce the skeleton of an outline [Prasad 1997; Zou\n",
      "et al.2001], so the ACAP loss also implicitly captures a skeletal\n",
      "representation of the letter form.\n",
      "Fig. 8. Our tone-preserving loss preserves the local tone of the font by\n",
      "comparing the low-pass filter of the letters images before (left) and after\n",
      "deformation (right). It constrains the adjusted letter not to deviate too much\n",
      "from the original. This example is of the letter B and the word “Bear”.\n",
      "The Delaunay triangulation D(𝑃)splits the glyph represented by\n",
      "𝑃into a set of triangles. This defines a set of size 𝑚𝑗of corresponding\n",
      "angles for each control point 𝑝𝑗(see Figure 7). We denote this set of\n",
      "angles as{𝛼𝑖\n",
      "𝑗}𝑚𝑗\n",
      "𝑖=1. The ACAP loss encourages the induced angles\n",
      "of the optimized shape ˆ𝑃not to deviate much from the angles of\n",
      "the original shape 𝑃, and is defined as the L2 distance between the\n",
      "corresponding angles:\n",
      "L𝑎𝑐𝑎𝑝(𝑃,ˆ𝑃)=1\n",
      "𝑘𝑘∑︁\n",
      "𝑗=1 𝑚𝑗∑︁\n",
      "𝑖=1\u0000𝛼𝑖\n",
      "𝑗−ˆ𝛼𝑖\n",
      "𝑗\u00012!\n",
      "(4)\n",
      "where𝑘=|𝑃|and ˆ𝛼are the angles induced by D(ˆ𝑃).\n",
      "Tone Preservation Loss. To preserve the style of the font as well\n",
      "as the structure of the letter we add a local-tone preservation loss\n",
      "term. This term constrains the tone (amount of black vs. white in\n",
      "all regions of the shape) of the adjusted letter not to deviate too\n",
      "much from tone of the original font’s letter. Towards this end, we\n",
      "apply a low pass filter (LPF) to the rasterized letter (before and after\n",
      "deformation) and compute the L2 distance between the resulting\n",
      "blurred letters:\n",
      "2?𝑃𝐹(R(𝑃))−𝐿𝑃𝐹(R(ˆ𝑃))\n",
      "2(5)\n",
      "An example of the blurred letters is shown in Figure 8, as can be\n",
      "seen, we use a high value of standard deviation 𝜎in the blurring\n",
      "kernel to blur out small details such as the ears of bear.\n",
      "Our final objective is then defined by the weighted average of the\n",
      "three terms:\n",
      "min\n",
      "ˆ𝑃∇ˆ𝑃LLSDS(R(ˆ𝑃),𝑐)+𝛼·L𝑎𝑐𝑎𝑝(𝑃,ˆ𝑃)\n",
      "+𝛽𝑡·L𝑡𝑜𝑛𝑒(R(𝑃),R(ˆ𝑃))(6)\n",
      "where𝛼=0.5and𝛽𝑡depends on the step 𝑡as described next.\n",
      "4.4 Weighting\n",
      "Choosing the relative weights of the three losses presented above\n",
      "is crucial to the appearance of the final letter. While the ∇ˆ𝑃LLSDS\n",
      "loss encourages the shape to deviate from its original appearance to\n",
      "better fit the semantic concept, the two terms L𝑡𝑜𝑛𝑒 andL𝑎𝑐𝑎𝑝 are\n",
      "responsible for maintaining the original shape. Hence, we have two\n",
      "competing parts in the formula, and would like to find a balance\n",
      "between them to maintain the legibility of the letter while allowing\n",
      "the desired semantic shape to change.\n",
      "We find thatL𝑡𝑜𝑛𝑒 can be very dominant. In some cases, if it is\n",
      "used from the beginning, no semantic deformation is performed.\n",
      "\n",
      "6•Shir Iluz, Yael Vinker, Amir Hertz, Daniel Berio, Daniel Cohen-Or, and Ariel Shamir\n",
      "Fig. 9. Word-as-images produced by our method for the word “YOGA”,\n",
      "using eight different fonts.\n",
      "Therefore, we adjust the weight of L𝑡𝑜𝑛𝑒 to kick-in only after some\n",
      "semantic deformation has occurred. We define 𝛽𝑡as follows:\n",
      "𝛽𝑡=𝑎·exp\u0000−(𝑡−𝑏)2\n",
      "2𝑐2\u0001(7)\n",
      "with𝑎=100,𝑏=300,𝑐=30. We analyse the affect of various\n",
      "weighting in Section 5.3. Note that the same hyper-parameter choice\n",
      "works for various words, letters, and fonts.\n",
      "5 RESULTS\n",
      "The robustness of our approach means it should be capable of han-\n",
      "dling a wide range of input concepts as well as supporting different\n",
      "font designs. Figures 1, 4, 33, 17, and more results in the supplemen-\n",
      "tal file demonstrate that our approach can handle inputs from many\n",
      "different categories and various fonts, and that the generated results\n",
      "are legible and creative. Figure 9 demonstrate how the illustrations\n",
      "created by our method for the same word follow the characteristics\n",
      "of different fonts. Although the perceived aesthetics of a word-as-\n",
      "image illustration can be subjective, we define three objectives for\n",
      "an effective result: (1) it should visually capture the given semantic\n",
      "concept, (2) it should maintain readability, and (3) it should preserve\n",
      "the original font’s characteristics.\n",
      "We evaluate the performance of our method on a randomly se-\n",
      "lected set of inputs. We select five common concept classes - animals,\n",
      "fruits, plants, sports, and professions. Using ChatGPT, we sample ten\n",
      "random instances for each class, resulting in 50 words in total. Next,\n",
      "we select four fonts that have distinct visual characteristics, namely\n",
      "Quicksand, Bell MT, Noteworthy-Bold, and HobeauxRococeaux-\n",
      "Sherman. For each word, we randomly sampled one of the four\n",
      "fonts, and applied our method to each letter. For each word with\n",
      "𝑛letters we can generate 2𝑛possible word-as-images, which are\n",
      "all possible combinations of replacements of illustrated letters. A\n",
      "selected subset of these results is presented in Figure 33. The results\n",
      "of all letters and words are presented in the supplementary material.\n",
      "As can be seen, the resulting word-as-image illustrations success-\n",
      "fully convey the given semantic concept in most cases while still\n",
      "remaining legible. In addition, our method successfully captures\n",
      "the font characteristics. For example, in Figure 33, the replacementsTable 1. Perceptual study results. The level of concept recognizability and\n",
      "letter legibility are very high, and style matching of the font is well above\n",
      "random. The “Only SDS” results are created by removing our structure and\n",
      "style preserving losses.\n",
      "Method Semantics Legibility Font\n",
      "Ours 0.8 0.9 0.51\n",
      "Only SDS 0.88 0.53 0.33\n",
      "for the “DRESS” and “LION” are thin and fit well with the rest of\n",
      "the word. In addition, observe the serifs of the letter A used for the\n",
      "fin of the shark in the “SHARK” example. We further use human\n",
      "evaluation to validate this as described below.\n",
      "5.1 Quantitative\n",
      "We conduct a perceptual study to quantitatively assess the three\n",
      "objectives of our resulting word-as-images. We randomly select two\n",
      "instances from each of the resulting word-as-image illustrations\n",
      "for the five classes described above, and visually select one letter\n",
      "from each word, resulting in 10 letters in total. In each question\n",
      "we show an isolated letter illustration, without the context of the\n",
      "word. To evaluate the ability of our method to visually depict the\n",
      "desired concept, we present four label options from the same class,\n",
      "and ask participants to choose the one that describes the letter\n",
      "illustration best. To evaluate the legibility of the results, we ask\n",
      "participants to choose the most suitable letter from a random list of\n",
      "four letters. To asses the preservation of the font style, we present\n",
      "the four fonts and ask participants to choose the most suitable font\n",
      "for the illustration. We gathered answers from 40 participants, and\n",
      "the results are shown in Table 1. As can be seen, the level of concept\n",
      "recognizability and letter legibility are very high, and the 51%of\n",
      "style matching of the letter illustration to the original font is well\n",
      "above random, which is 25%. We also test our algorithm without\n",
      "the two additional structure and style preserving losses ( L𝑎𝑐𝑎𝑝 and\n",
      "L𝑡𝑜𝑛𝑒) on the same words and letters (“Only SDS” in the table).\n",
      "As expected, without the additional constraints, the letter deforms\n",
      "significantly resulting in higher concept recognizability but lower\n",
      "legibility and font style preservation. More details and examples are\n",
      "provided in the supplementary material.\n",
      "5.2 Comparison\n",
      "In the absence of a relevant baseline for comparison, we define base-\n",
      "lines based on large popular text-to-image models. Specifically, we\n",
      "use(1) SD Stable Diffusion [Rombach et al .2021], (2) SDEdit [Meng\n",
      "et al.2022], (3) DallE2 [Ramesh et al .2022] illustrating the word,\n",
      "(4) DallE2+letter illustrating only the letter, and (5) CLIPDraw\n",
      "[Frans et al .2021]. We applied the methods above (details can be\n",
      "found in supplemental material) to three representative words –\n",
      "“bird”, “dress”, and “tulip”, with the fonts Bell MT, Quicksand, and\n",
      "Noteworthy-Bold, respectively. The results can be seen in Figure 10.\n",
      "In some cases Stable Diffusion (SD) did not manage to produce\n",
      "text at all (such as for the bird) and when text is produced, it is\n",
      "often not legible. The results obtained by SDEdit preserve the font’s\n",
      "characteristics and the letter’s legibility, but often fail to reflect\n",
      "the desired concept, such as in the case of the bird and the dress.\n",
      "\n",
      "Word-As-Image for Semantic Typography •7\n",
      "The word\n",
      "BIRD and\n",
      "the letter R\n",
      "The word\n",
      "DRESS and\n",
      "the letter E\n",
      "The word\n",
      "TULIP and\n",
      "the letter U\n",
      "Input SD SDEdit DallE2 DallE2+letter CLIPDraw Ours\n",
      "Fig. 10. Comparison to alternative methods based on large scale text-to-image models. On the left are the letters used as input (only for SDEdit, CLIPDraw, and\n",
      "ours), as well as the desired object of interest. The results from left to right obtained using Stable Diffusion [Rombach et al .2021], SDEdit [Meng et al .2022],\n",
      "DallE2 [Ramesh et al .2022], DallE2 with a letter specific prompt, CLIPDraw [Frans et al .2021], and our single-letter results, as well as the final word-as-image.\n",
      "Additionally, it operates in the raster domain and tends to adddetails\n",
      "on top of the letter, while our method operates directly on the vector\n",
      "representation of the letters with the objective of modifying their\n",
      "shape . DallE2 manages to reflect the visual concept, however it often\n",
      "fails to produce legible text. When applied with a dedicated prompt\n",
      "to produce the word-as-image of only one letter (fifth column), it\n",
      "manages to produce a legible letter, but there is less control over\n",
      "the output – it is impossible to specify the desired font or to control\n",
      "the size, position, and shape of the generated letter. Therefore, it is\n",
      "not clear how to combine these output illustrations into the entire\n",
      "word to create a word-as-image.\n",
      "CLIPDraw produces reasonable results conveying the semantics\n",
      "of the input word. However, the results are non-smooth and the\n",
      "characteristics of the font are not preserved (for example observe\n",
      "how the letter \"E\" differs from the input letter). We further examine\n",
      "CLIPDraw with our shape preservation losses in the next Section.\n",
      "5.3 Ablation\n",
      "Figure 11 illustrates the impact of the letter’s initial number of\n",
      "control points. When less control points are used ( 𝑃𝑜is the original\n",
      "number of control points), we may get insufficient variations, such\n",
      "as for the gorilla. However, this can also result in more abstract\n",
      "depictions, such as the ballerina. As we add control points, we get\n",
      "more graphic results, with the tradeoff that it often deviate from the\n",
      "original letter. In Figure 15 we show the results of using only the\n",
      "∇ˆ𝑃LLSDS loss. As can be seen, in that case the illustrations strongly\n",
      "convey the semantic concept, however at the cost of legibility. In\n",
      "Figure 16 we analyze the effect of the weight 𝛼applied toL𝑎𝑐𝑎𝑝.\n",
      "Ranging from 1to0. WhenL𝑎𝑐𝑎𝑝 is too dominant, the results may\n",
      "not enough reflect the semantic concept, while the opposite case\n",
      "harms legibility. Figure 13 illustrates a change in the 𝜎parameter of\n",
      "the low pass filter. When 𝜎=1almost no blur is applied, resulting\n",
      "in a shape constraint that is too strong.\n",
      "In Figure 14 we show the results of replacing the ∇ˆ𝑃LLSDS loss\n",
      "with a CLIP based loss, while using our proposed shape preservation\n",
      "terms. Although the results obtained with CLIP often depict the\n",
      "desired visual concept, we find that using Stable Diffusion leads\n",
      "to smoother illustrations, that capture a wider range of semantic\n",
      "concepts.By using the hyperparameters described in the paper, we are able\n",
      "to achieve a reasonable balance between semantics and legibility.\n",
      "The parameters were determined manually based on visual assess-\n",
      "ments, but can be adjusted as needed based on the user’s personal\n",
      "taste and goals.\n",
      "\"Ballet\"\n",
      "\"Gorilla\"\n",
      "\"Gym\"\n",
      "Input 𝑃𝑜𝑃 2×𝑃\n",
      "Fig. 11. The effect of the initial number of control points on outputs. On the\n",
      "left are the input letters and the target concepts used to generate the results\n",
      "on the right. 𝑃𝑜indicates the original number of control points as extracted\n",
      "from the font, 𝑃is the input letter with our chosen hyperparameters, and\n",
      "for2×𝑃we increase the number of control points in 𝑃by two.\n",
      "6 CONCLUSIONS\n",
      "We presented a method for the automatic creation of vector-format\n",
      "word-as-image illustrations. Our method can handle a large variety\n",
      "of semantic concepts and use any font, while preserving the legibility\n",
      "of the text and the font’s style.\n",
      "There are limitations to our method. First, our method works\n",
      "letter by letter, and therefore, it cannot deform the shape of the\n",
      "entire word. In the future we can try to optimize the shape of several\n",
      "letters. Second, the approach works best on concrete visual concepts,\n",
      "and may fail with more abstract ones. This can be alleviated by\n",
      "optimizing the shape of letters using different concepts than the\n",
      "word itself. Third, the layout of letters can also be automated for\n",
      "example, using methods such as [Wang et al. 2022].\n",
      "Our word-as-image illustrations demonstrate visual creativity\n",
      "and open the possibility for the use of large vision-language models\n",
      "for semantic typography, possibly also adding human-in-the-loop\n",
      "to arrive at more synergistic design methods of ML models and\n",
      "humans.\n",
      "\n",
      "8•Shir Iluz, Yael Vinker, Amir Hertz, Daniel Berio, Daniel Cohen-Or, and Ariel Shamir\n",
      "\"Bear\"\n",
      "\"Singer\"\n",
      "\"Giraffe\"\n",
      "Input 1 5 30 200Without\n",
      "L𝑡𝑜𝑛𝑒\n",
      "Fig. 13. Altering the 𝜎parameter of the low pass filter using in the L𝑡𝑜𝑛𝑒\n",
      "loss. On the leftmost column are the original letters and concepts used, then\n",
      "from left to right are the results obtained when using 𝜎∈{1,5,30,200},\n",
      "and withoutL𝑡𝑜𝑛𝑒.\n",
      "Input\n",
      "Letter\n",
      "CLIP\n",
      "loss\n",
      "SDS\n",
      "loss\n",
      "\"Snail\" \"Skirt\" \"Socks\" \"Queen\" \"Strawberry\"\n",
      "Fig. 14. Replacing the SDS loss with a CLIP-based loss.Input\n",
      "Letter\n",
      "Ours\n",
      "Only\n",
      "SDS\n",
      "\"Cat\" \"Music\" \"Robot\" \"Cup\" \"Hands\"\n",
      "Fig. 15. The effect of using only the SDS loss: note how the third row simply\n",
      "looks like icon illustrations, while the second row still resembles legible\n",
      "letters.\n",
      "\"Bear\"\n",
      "\"Singer\"\n",
      "\"Giraffe\"\n",
      "Input 1 0.75 0.5 0.25Without\n",
      "L𝑎𝑐𝑎𝑝\n",
      "Fig. 16. Altering the weight 𝛼of theL𝑎𝑐𝑎𝑝 loss. On the leftmost column\n",
      "are the original letters and concepts used, then from left to right are the\n",
      "results obtained when using 𝛼∈{1,0.75,0.5,0.25,0}.\n",
      "Fig. 12. Word-as-images produced by our method. This subset was chosen from the random set of words.\n",
      "\n",
      "Word-As-Image for Semantic Typography •9\n",
      "Fig. 17. Additional results produced by our method.\n",
      "\n",
      "10 •Shir Iluz, Yael Vinker, Amir Hertz, Daniel Berio, Daniel Cohen-Or, and Ariel Shamir\n",
      "7 ACKNOWLEDGMENTS\n",
      "We are grateful to Richard Hao Zhang for the early discussion of\n",
      "the text-as-image problem. Ali Mahdavi-Amiri and Oren Katzir for\n",
      "reviewing earlier versions of the manuscript and to Anran Qi for\n",
      "assisting in evaluating the Chinese words. This research was sup-\n",
      "ported in part by the Israel Science Foundation (grants no. 2492/20\n",
      "and 3441/21), Len Blavatnik and the Blavatnik family foundation,\n",
      "and the Tel Aviv University Innovation Laboratories (TILabs).\n",
      "REFERENCES\n",
      "Tomer Amit, Tal Shaharbany, Eliya Nachmani, and Lior Wolf. 2021. SegDiff: Image\n",
      "Segmentation with Diffusion Probabilistic Models. https://doi.org/10.48550/ARXIV.\n",
      "2112.00390\n",
      "Omri Avrahami, Dani Lischinski, and Ohad Fried. 2022. Blended Diffusion for Text-\n",
      "Driven Editing of Natural Images. In Proceedings of the IEEE/CVF Conference on\n",
      "Computer Vision and Pattern Recognition (CVPR) . 18208–18218.\n",
      "Samaneh Azadi, Matthew Fisher, Vladimir G. Kim, Zhaowen Wang, Eli Shechtman,\n",
      "and Trevor Darrell. 2018. Multi-Content GAN for Few-Shot Font Style Transfer.\n",
      "InProceedings of the IEEE Conference on Computer Vision and Pattern Recognition\n",
      "(CVPR) . IEEE, Salt Lake City, UT, USA, 7564–7573.\n",
      "Elena Balashova, Amit H. Bermano, Vladimir G. Kim, Stephen DiVerdi, Aaron Hertz-\n",
      "mann, and Thomas Funkhouser. 2019. Learning a Stroke-Based Representation for\n",
      "Fonts. Computer Graphics Forum 38, 1 (2019), 429–442.\n",
      "Brad Barber and Hannu Huhdanpaa. 1995. QHull. The Geometry Center, University of\n",
      "Minnesota, http://www. geom. umn. edu/software/qhull (1995).\n",
      "Daniel Berio, Frederic Fol Leymarie, Paul Asente, and Jose Echevarria. 2022. StrokeStyles:\n",
      "Stroke-Based Segmentation and Stylization of Fonts. ACM Trans. Graph. 41, 3, Article\n",
      "28 (apr 2022), 21 pages. https://doi.org/10.1145/3505246\n",
      "Neill DF Campbell and Jan Kautz. 2014. Learning a Manifold of Fonts. ACM Transactions\n",
      "on Graphics (TOG) 33, 4 (2014). https://doi.org/10.1145/2601097.2601212 Article no.\n",
      "91.\n",
      "Hila Chefer, Shir Gur, and Lior Wolf. 2021. Transformer Interpretability Beyond Atten-\n",
      "tion Visualization. In Proceedings of the IEEE/CVF Conference on Computer Vision\n",
      "and Pattern Recognition (CVPR) . 782–791.\n",
      "Jooyoung Choi, Sungwon Kim, Yonghyun Jeong, Youngjune Gwon, and Sungroh Yoon.\n",
      "2021. ILVR: Conditioning Method for Denoising Diffusion Probabilistic Models.\n",
      "CoRR abs/2108.02938 (2021). arXiv:2108.02938 https://arxiv.org/abs/2108.02938\n",
      "Boris Delaunay et al .1934. Sur la sphere vide. Izv. Akad. Nauk SSSR, Otdelenie Matem-\n",
      "aticheskii i Estestvennyka Nauk 7, 793-800 (1934), 1–2.\n",
      "Noa Fish, Lilach Perry, Amit Bermano, and Daniel Cohen-Or. 2020. SketchPatch: Sketch\n",
      "Stylization via Seamless Patch-Level Synthesis. ACM Trans. Graph. 39, 6, Article\n",
      "227 (nov 2020), 14 pages. https://doi.org/10.1145/3414685.3417816\n",
      "Kevin Frans, Lisa B Soros, and Olaf Witkowski. 2021. Clipdraw: Exploring\n",
      "text-to-drawing synthesis through language-image encoders. arXiv preprint\n",
      "arXiv:2106.14843 (2021).\n",
      "FreeType. 2009. FreeType library. https://freetype.org/\n",
      "Rinon Gal, Yuval Alaluf, Yuval Atzmon, Or Patashnik, Amit H. Bermano, Gal Chechik,\n",
      "and Daniel Cohen-Or. 2022. An Image is Worth One Word: Personalizing Text-to-\n",
      "Image Generation using Textual Inversion. https://doi.org/10.48550/ARXIV.2208.\n",
      "01618\n",
      "Rinon Gal, Moab Arar, Yuval Atzmon, Amit H. Bermano, Gal Chechik, and Daniel\n",
      "Cohen-Or. 2023. Designing an Encoder for Fast Personalization of Text-to-Image\n",
      "Models. https://doi.org/10.48550/ARXIV.2302.12228\n",
      "David Ha and Douglas Eck. 2018. A Neural Representation of Sketch Draw-\n",
      "ings. In Sixth International Conference on Learning Representations (ICLR) .\n",
      "https://arxiv.org/abs/1704.03477.\n",
      "Amir Hertz, Ron Mokady, Jay Tenenbaum, Kfir Aberman, Yael Pritch, and Daniel\n",
      "Cohen-Or. 2022. Prompt-to-prompt image editing with cross attention control.\n",
      "(2022).\n",
      "Jonathan Ho, Ajay Jain, and Pieter Abbeel. 2020. Denoising Diffusion Probabilistic\n",
      "Models. CoRR abs/2006.11239 (2020). arXiv:2006.11239 https://arxiv.org/abs/2006.\n",
      "11239\n",
      "Kai Hormann and Günther Greiner. 2000. MIPS: An efficient global parametrization\n",
      "method . Technical Report. Erlangen-Nuernberg Univ (Germany) Computer Graphics\n",
      "Group.\n",
      "Adobe Systems Inc. 1990. Adobe Type 1 Font Format . Addison Wesley Publishing\n",
      "Company.\n",
      "Ajay Jain, Amber Xie, and Pieter Abbeel. 2022. VectorFusion: Text-to-SVG by Abstract-\n",
      "ing Pixel-Based Diffusion Models. arXiv preprint arXiv:2211.11319 (2022).\n",
      "Yue Jiang, Zhouhui Lian, Yingmin Tang, and Jianguo Xiao. 2019. SCFont: Structure-\n",
      "Guided Chinese Font Generation via Deep Stacked Networks. Proceedings of the\n",
      "AAAI Conference on Artificial Intelligence 33, 01 (Jul. 2019), 4015–4022. https://doi.org/10.1609/aaai.v33i01.33014015\n",
      "Ji Lee. 2011. Word As Image . Adams Media, London.\n",
      "Tzu-Mao Li, Michal Lukáč, Gharbi Michaël, and Jonathan Ragan-Kelley. 2020. Differen-\n",
      "tiable Vector Graphics Rasterization for Editing and Learning. ACM Trans. Graph.\n",
      "(Proc. SIGGRAPH Asia) 39, 6 (2020), 193:1–193:15.\n",
      "Zhouhui Lian, Bo Zhao, Xudong Chen, and Jianguo Xiao. 2018. EasyFont: A style\n",
      "learning-based system to easily build your large-scale handwriting fonts. ACM\n",
      "Transactions on Graphics (TOG) 38, 1 (2018), 1–18.\n",
      "Raphael Gontijo Lopes, David Ha, Douglas Eck, and Jonathon Shlens. 2019. A Learned\n",
      "Representation for Scalable Vector Graphics. In Proceedings of the IEEE/CVF Interna-\n",
      "tional Conference on Computer Vision (ICCV) .\n",
      "Xu Ma, Yuqian Zhou, Xingqian Xu, Bin Sun, Valerii Filev, Nikita Orlov, Yun Fu, and\n",
      "Humphrey Shi. 2022. Towards Layer-wise Image Vectorization. https://doi.org/10.\n",
      "48550/ARXIV.2206.04655\n",
      "Wendong Mao, Shuai Yang, Huihong Shi, Jiaying Liu, and Zhongfeng Wang. 2022. Intel-\n",
      "ligent Typography: Artistic Text Style Transfer for Complex Texture and Structure.\n",
      "IEEE Transactions on Multimedia (2022), 1–15. https://doi.org/10.1109/TMM.2022.\n",
      "3209870\n",
      "Chenlin Meng, Yutong He, Yang Song, Jiaming Song, Jiajun Wu, Jun-Yan Zhu, and\n",
      "Stefano Ermon. 2022. SDEdit: Guided Image Synthesis and Editing with Stochastic\n",
      "Differential Equations. In International Conference on Learning Representations .\n",
      "Gal Metzer, Elad Richardson, Or Patashnik, Raja Giryes, and Daniel Cohen-Or. 2022.\n",
      "Latent-NeRF for Shape-Guided Generation of 3D Shapes and Textures. https:\n",
      "//doi.org/10.48550/ARXIV.2211.07600\n",
      "Oscar Michel, Roi Bar-On, Richard Liu, Sagie Benaim, and Rana Hanocka.\n",
      "2021. Text2Mesh: Text-Driven Neural Stylization for Meshes. arXiv preprint\n",
      "arXiv:2112.03221 (2021).\n",
      "Alex Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam, Pamela Mishkin, Bob\n",
      "McGrew, Ilya Sutskever, and Mark Chen. 2021. Glide: Towards photorealistic\n",
      "image generation and editing with text-guided diffusion models. arXiv preprint\n",
      "arXiv:2112.10741 (2021).\n",
      "Laurence Penney. 1996. A History of TrueType. https://www.truetype-\n",
      "typography.com/.\n",
      "Huy Quoc Phan, Hongbo Fu, and Antoni B Chan. 2015. Flexyfont: Learning Transferring\n",
      "Rules for Flexible Typeface Synthesis. Computer Graphics Forum 34, 7 (2015), 245–\n",
      "256.\n",
      "Ben Poole, Ajay Jain, Jonathan T Barron, and Ben Mildenhall. 2022. Dreamfusion:\n",
      "Text-to-3d using 2d diffusion. arXiv preprint arXiv:2209.14988 (2022).\n",
      "Lakshman Prasad. 1997. Morphological analysis of shapes. CNLS newsletter 139, 1\n",
      "(1997), 1997–07.\n",
      "Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini\n",
      "Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen\n",
      "Krueger, and Ilya Sutskever. 2021. Learning Transferable Visual Models From\n",
      "Natural Language Supervision. CoRR abs/2103.00020 (2021). arXiv:2103.00020\n",
      "https://arxiv.org/abs/2103.00020\n",
      "Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen. 2022.\n",
      "Hierarchical text-conditional image generation with clip latents. arXiv preprint\n",
      "arXiv:2204.06125 (2022).\n",
      "Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn\n",
      "Ommer. 2021. High-Resolution Image Synthesis with Latent Diffusion Models.\n",
      "arXiv:2112.10752 [cs.CV]\n",
      "Olaf Ronneberger, Philipp Fischer, and Thomas Brox. 2015. U-net: Convolutional\n",
      "networks for biomedical image segmentation. In International Conference on Medical\n",
      "image computing and computer-assisted intervention . Springer, 234–241.\n",
      "Nataniel Ruiz, Yuanzhen Li, Varun Jampani, Yael Pritch, Michael Rubinstein, and Kfir\n",
      "Aberman. 2022. DreamBooth: Fine Tuning Text-to-image Diffusion Models for\n",
      "Subject-Driven Generation. (2022).\n",
      "Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily Den-\n",
      "ton, Seyed Kamyar Seyed Ghasemipour, Burcu Karagol Ayan, S. Sara Mahdavi,\n",
      "Rapha Gontijo Lopes, Tim Salimans, Jonathan Ho, David J Fleet, and Mohammad\n",
      "Norouzi. 2022. Photorealistic Text-to-Image Diffusion Models with Deep Language\n",
      "Understanding. https://doi.org/10.48550/ARXIV.2205.11487\n",
      "Kunpeng Song, Ligong Han, Bingchen Liu, Dimitris Metaxas, and Ahmed Elgammal.\n",
      "2022. Diffusion Guided Domain Adaptation of Image Generators. https://doi.org/\n",
      "10.48550/ARXIV.2212.04473\n",
      "Rapee Suveeranont and Takeo Igarashi. 2010. Example-Based Automatic Font Genera-\n",
      "tion. In Smart Graphics . Number LNCS 6133 in Lecture Notes in Computer Science.\n",
      "127–138.\n",
      "Purva Tendulkar, Kalpesh Krishna, Ramprasaath R. Selvaraju, and Devi Parikh. 2019.\n",
      "Trick or TReAT: Thematic Reinforcement for Artistic Typography. https://doi.org/\n",
      "10.48550/ARXIV.1903.07820\n",
      "Guy Tevet, Brian Gordon, Amir Hertz, Amit H Bermano, and Daniel Cohen-Or. 2022.\n",
      "Motionclip: Exposing human motion generation to clip space. In Computer Vision–\n",
      "ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23–27, 2022, Proceedings,\n",
      "Part XXII . Springer, 358–374.\n",
      "\n",
      "Word-As-Image for Semantic Typography •11\n",
      "Yingtao Tian and David Ha. 2021. Modern Evolution Strategies for Creativity: Fitting\n",
      "Concrete Images and Abstract Conceptst. arXiv:2109.08857 [cs.NE]\n",
      "Narek Tumanyan, Michal Geyer, Shai Bagon, and Tali Dekel. 2022a. Plug-and-Play\n",
      "Diffusion Features for Text-Driven Image-to-Image Translation. https://doi.org/10.\n",
      "48550/ARXIV.2211.12572\n",
      "Narek Tumanyan, Michal Geyer, Shai Bagon, and Tali Dekel. 2022b. Plug-and-Play\n",
      "Diffusion Features for Text-Driven Image-to-Image Translation. https://doi.org/10.\n",
      "48550/ARXIV.2211.12572\n",
      "Yael Vinker, Yuval Alaluf, Daniel Cohen-Or, and Ariel Shamir. 2022a. CLIPascene: Scene\n",
      "Sketching with Different Types and Levels of Abstraction. https://doi.org/10.48550/\n",
      "ARXIV.2211.17256\n",
      "Yael Vinker, Ehsan Pajouheshgar, Jessica Y. Bo, Roman Christian Bachmann, Amit Haim\n",
      "Bermano, Daniel Cohen-Or, Amir Zamir, and Ariel Shamir. 2022b. CLIPasso:\n",
      "Semantically-Aware Object Sketching. ACM Trans. Graph. 41, 4, Article 86 (jul\n",
      "2022), 11 pages. https://doi.org/10.1145/3528223.3530068\n",
      "Patrick von Platen, Suraj Patil, Anton Lozhkov, Pedro Cuenca, Nathan Lambert, Kashif\n",
      "Rasul, Mishig Davaadorj, and Thomas Wolf. 2022. Diffusers: State-of-the-art diffu-\n",
      "sion models. https://github.com/huggingface/diffusers.\n",
      "Wenjing Wang, Jiaying Liu, Shuai Yang, and Zongming Guo. 2019. Typography With\n",
      "Decor: Intelligent Text Style Transfer. In Proceedings of the IEEE/CVF Conference on\n",
      "Computer Vision and Pattern Recognition (CVPR) .\n",
      "Yizhi Wang and Zhouhui Lian. 2021. DeepVecFont: Synthesizing High-Quality Vector\n",
      "Fonts via Dual-Modality Learning. ACM Transactions on Graphics 40, 6 (Dec. 2021),\n",
      "1–15. https://doi.org/10.1145/3478513.3480488\n",
      "Yizhi Wang, Guo Pu, Wenhan Luo, Yexin Wang, Pengfei Xiong, Hongwen Kang, and\n",
      "Zhouhui Lian. 2022. Aesthetic Text Logo Synthesis via Content-Aware Layout\n",
      "Inferring. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern\n",
      "Recognition (CVPR) . 2436–2445.\n",
      "Jie Xu and Craig S. Kaplan. 2007. Calligraphic Packing. In Proceedings of Graphics\n",
      "Interface 2007 on - GI ’07 . ACM Press, Montreal, Canada, 43. https://doi.org/10.1145/\n",
      "1268517.1268527\n",
      "Shuai Yang, Jiaying Liu, Zhouhui Lian, and Zongming Guo. 2017. Awesome Typography:\n",
      "Statistics-Based Text Effects Transfer. In Proceedings of the IEEE Conference on\n",
      "Computer Vision and Pattern Recognition (CVPR) .\n",
      "Shuai Yang, Jiaying Liu, Wenhan Yang, and Zongming Guo. 2018. Context-Aware Un-\n",
      "supervised Text Stylization. In Proceedings of the 26th ACM International Conference\n",
      "on Multimedia (Seoul, Republic of Korea) (MM ’18) . Association for Computing Ma-\n",
      "chinery, New York, NY, USA, 1688–1696. https://doi.org/10.1145/3240508.3240580\n",
      "Shuai Yang, Zhangyang Wang, and Jiaying Liu. 2022. Shape-Matching GAN++: Scale\n",
      "Controllable Dynamic Artistic Text Style Transfer. IEEE Transactions on Pattern\n",
      "Analysis and Machine Intelligence 44, 7 (2022), 3807–3820. https://doi.org/10.1109/\n",
      "TPAMI.2021.3055211\n",
      "Junsong Zhang, Yu Wang, Weiyi Xiao, and Zhenshan Luo. 2017. Synthesizing Orna-\n",
      "mental Typefaces: Synthesizing Ornamental Typefaces. Computer Graphics Forum\n",
      "36, 1 (Jan. 2017), 64–75. https://doi.org/10.1111/cgf.12785\n",
      "Renrui Zhang, Ziyu Guo, Wei Zhang, Kunchang Li, Xupeng Miao, Bin Cui, Yu Qiao,\n",
      "Peng Gao, and Hongsheng Li. 2021. PointCLIP: Point Cloud Understanding by CLIP.\n",
      "https://doi.org/10.48550/ARXIV.2112.02413\n",
      "Changqing Zou, Junjie Cao, Warunika Ranaweera, Ibraheem Alhashim, Ping Tan, Alla\n",
      "Sheffer, and Hao Zhang. 2016. Legible Compact Calligrams. ACM Transactions on\n",
      "Graphics 35, 4 (July 2016), 1–12. https://doi.org/10.1145/2897824.2925887\n",
      "Ju Jia Zou, Hung-Hsin Chang, and Hong Yan. 2001. Shape skeletonization by identifying\n",
      "discrete local symmetries. Pattern Recognition 34, 10 (2001), 1895–1905.\n",
      "\n",
      "12 •Shir Iluz, Yael Vinker, Amir Hertz, Daniel Berio, Daniel Cohen-Or, and Ariel Shamir\n",
      "SUPPLEMENTARY MATERIAL\n",
      "A IMPLEMENTATION DETAILS\n",
      "In this section we provide further implementation details. We intend\n",
      "to release the code to promote future research in this domain.\n",
      "Our method is based on the pre-trained 𝑣1−5Stable Diffusion\n",
      "model [Rombach et al .2021], which we use through the diffusers\n",
      "[von Platen et al .2022] Python package. We optimize only the\n",
      "control points’ coordinates (i.e. we do not modify the color, width,\n",
      "and other parameters of the shape). We use the Adam optimizer with\n",
      "𝛽1=0.9,𝛽2=0.9,𝜖=10−6. We use learning rate warm-up from\n",
      "0.1to0.8over 100iterations and exponential decay from 0.8to0.4\n",
      "over the rest 400iterations, 500iteration in total. The optimization\n",
      "process requires at least 10GB memory and approximately 5 minutes\n",
      "to produce a single letter illustration on RTX2080 GPU.\n",
      "Before we feed the rasterized 600𝑥600letter image into the Stable\n",
      "Diffusion model, we apply random augmentations as proposed in\n",
      "CLIPDraw [Frans et al .2021]. Specifically, perspective transform\n",
      "with a distortion scale of 0.5, with probability 0.7, and a random\n",
      "512𝑥512crop. We add the suffix \"a [ word ]. minimal flat 2d vector.\n",
      "lineal color. trending on artstation.\" to the target word 𝑊, before\n",
      "feeding it into the text encoder of a pretrained CLIP model.\n",
      "B COMPARISONS\n",
      "As described in Section 5.2 we define five baselines to compare with.\n",
      "In this section we provide more details about the evaluation and\n",
      "more qualitative results. For (1) SD , we run Stable Diffusion [Rom-\n",
      "bach et al .2021] with the default hyper parameters of 50inference\n",
      "steps and a guidance scale of 7.5. We use the prompt “Word as image\n",
      "of the word [ word ]. [font] font. minimal flat 2d vector. lineal color.\n",
      "black and white style”.\n",
      "For(2) SDEdit [Meng et al .2022], we utilized the diffusers [von\n",
      "Platen et al .2022] implementation, using the prompt “A [ word ].\n",
      "minimal flat 2d vector. lineal color. black and white style”, and the\n",
      "rasterized input letter as the reference image. We use the default\n",
      "values of 50inference steps and a guidance scale of 7.5. We use a\n",
      "strength value of 0.85. The strength value determines the quantity\n",
      "of noise added to the input image – a value close to 1.0results in\n",
      "higher degree of variation in the output, and vice versa.\n",
      "We use the official website of OpenAI to run (3) DallE2 [Ramesh\n",
      "et al.2022], using the prompt “Word as image of the word [ word ].\n",
      "Where the letter [ letter ] looks like a [ word ]. [font] font. minimal\n",
      "flat 2d vector. lineal color. black and white style”. To encourage\n",
      "the manipulation of a specific letter, for (4) DallE2+letter we use\n",
      "the prompt “The letter [ letter ] in the shape of a [ word ]. [font] font.\n",
      "minimal flat 2d vector. lineal color. black and white style”. For (5)\n",
      "CLIPDraw [Frans et al .2021], we use the author’s official imple-\n",
      "mentation with the recommended hyper-parameters. Instead of\n",
      "using randomly initialized strokes, we use our vectorized letter as\n",
      "input, along with the prompt “A [ word ]. [font] font. minimal flat\n",
      "2d vector. lineal color. black and white style”. We provide more\n",
      "comparisons to the methods described above in Figure 20.\n",
      "Fig. 18. Some additional examples of word-as-image applied on Chinese\n",
      "characters. In Chinese, a whole word can be represented by one character.\n",
      "Here we show from left: bird, rabbit, cat and surfing (two last characters\n",
      "together). The complexity of characters imposes an additional challenge for\n",
      "our method. This could be alleviated in the future for example by dividing\n",
      "the characters to radicals and applying the method only on parts of the\n",
      "character.\n",
      "C PERCEPTUAL STUDY\n",
      "In this section, we provide more details about the perceptual study\n",
      "described in Section 5.1. The randomly chosen objects, fonts, and\n",
      "letters are shown in Table 2. A few visual examples are shown in\n",
      "Figure 19.\n",
      "Ours Only SDS\n",
      "\"Coat\"\n",
      "\"Soccer\"\n",
      "\"Shirt\"\n",
      "\"Rugby\"\n",
      "Font\n",
      "Rec.\n",
      "Fig. 19. Examples of illustrations presented in the perceptual study. Each\n",
      "pair in the top part shows illustrations obtained using our proposed method\n",
      "(left) and using only SDS loss (right). On the bottom is an example of an\n",
      "illustration presented for the font recognition questions.\n",
      "D ADDITIONAL RESULTS\n",
      "We provide additional results of our generated word-as-images. In\n",
      "Figures 21-32 we show results of selected words and unique fonts.\n",
      "\n",
      "Word-As-Image for Semantic Typography •13\n",
      "\"Muffin\"\n",
      "\"Tiger\"\n",
      "\"Octopus\"\n",
      "\"Plant\"\n",
      "\"Astronaut\"\n",
      "\"Robot\"\n",
      "\"Bunny\"\n",
      "\"Flamingo\"\n",
      "\"Paris\"\n",
      "\"Owl\"\n",
      "\"Swan\"\n",
      "\"Mermaid\"\n",
      "Input SD SDEdit DallE2 DallE2+letter CLIPDraw Ours\n",
      "Fig. 20. Comparison to alternative methods based on large scale text-to-image models. On the left are the letters used as input (only for SDEdit, CLIPDraw,\n",
      "and ours), as well as the desired object of interest. The results from left to right obtained using Stable Diffusion [Rombach et al .2021], SDEdit [Meng et al .\n",
      "2022], DallE2 [Ramesh et al. 2022], DallE2 with a letter specific prompt, CLIPDraw [Frans et al. 2021], and our single-letter results.\n",
      "In Figures 33-48 we show the results obtained for the random set of\n",
      "words.\n",
      "\n",
      "14 •Shir Iluz, Yael Vinker, Amir Hertz, Daniel Berio, Daniel Cohen-Or, and Ariel Shamir\n",
      "Table 2. Randomly chosen objects, letters, and fonts for the perceptual\n",
      "study.\n",
      "Object Letter Font\n",
      "Pineapple P Noteworthy-Bold\n",
      "Orange O Quicksand\n",
      "Rugby Y Noteworthy-Bold\n",
      "Soccer S Noteworthy-Bold\n",
      "Bear B Bell MT\n",
      "Lion O Quicksand\n",
      "Singer N Noteworthy-Bold\n",
      "Pilot P Noteworthy-Bold\n",
      "Coat O HobeauxRococeaux-Sherman\n",
      "Shirt S Bell MT\n",
      "Fig. 21. Word-as-image illustrations created by our method.\n",
      "\n",
      "Word-As-Image for Semantic Typography •15\n",
      "Fig. 22. Word-as-image illustrations created by our method.\n",
      "Fig. 23. Word-as-image illustrations created by our method.\n",
      "Fig. 24. Word-as-image illustrations created by our method.\n",
      "\n",
      "16 •Shir Iluz, Yael Vinker, Amir Hertz, Daniel Berio, Daniel Cohen-Or, and Ariel Shamir\n",
      "Fig. 25. Word-as-image illustrations created by our method.\n",
      "Fig. 26. Word-as-image illustrations created by our method.\n",
      "\n",
      "Word-As-Image for Semantic Typography •17\n",
      "Fig. 27. Word-as-image illustrations created by our method.\n",
      "Fig. 28. Word-as-image illustrations created by our method.\n",
      "\n",
      "18 •Shir Iluz, Yael Vinker, Amir Hertz, Daniel Berio, Daniel Cohen-Or, and Ariel Shamir\n",
      "Fig. 29. Word-as-image illustrations created by our method.\n",
      "Fig. 30. Word-as-image illustrations created by our method.\n",
      "\n",
      "Word-As-Image for Semantic Typography •19\n",
      "Fig. 31. Word-as-image illustrations created by our method.\n",
      "Fig. 32. Word-as-image illustrations created by our method.\n",
      "\n",
      "20 •Shir Iluz, Yael Vinker, Amir Hertz, Daniel Berio, Daniel Cohen-Or, and Ariel Shamir\n",
      "Fig. 33. Word-as-image illustrations created by our method for randomly chosen words.\n",
      "Fig. 34. Word-as-image illustrations created by our method for randomly chosen words.\n",
      "\n",
      "Word-As-Image for Semantic Typography •21\n",
      "Fig. 35. Word-as-image illustrations created by our method for randomly chosen words.\n",
      "Fig. 36. Word-as-image illustrations created by our method for randomly chosen words.\n",
      "\n",
      "22 •Shir Iluz, Yael Vinker, Amir Hertz, Daniel Berio, Daniel Cohen-Or, and Ariel Shamir\n",
      "Fig. 37. Word-as-image illustrations created by our method for randomly chosen words.\n",
      "Fig. 38. Word-as-image illustrations created by our method for randomly chosen words.\n",
      "\n",
      "Word-As-Image for Semantic Typography •23\n",
      "Fig. 39. Word-as-image illustrations created by our method for randomly chosen words.\n",
      "Fig. 40. Word-as-image illustrations created by our method for randomly chosen words.\n",
      "\n",
      "24 •Shir Iluz, Yael Vinker, Amir Hertz, Daniel Berio, Daniel Cohen-Or, and Ariel Shamir\n",
      "Fig. 41. Word-as-image illustrations created by our method for randomly chosen words.\n",
      "Fig. 42. Word-as-image illustrations created by our method for randomly chosen words.\n",
      "\n",
      "Word-As-Image for Semantic Typography •25\n",
      "Fig. 43. Word-as-image illustrations created by our method for randomly chosen words.\n",
      "Fig. 44. Word-as-image illustrations created by our method for randomly chosen words.\n",
      "\n",
      "26 •Shir Iluz, Yael Vinker, Amir Hertz, Daniel Berio, Daniel Cohen-Or, and Ariel Shamir\n",
      "Fig. 45. Word-as-image illustrations created by our method for randomly chosen words.\n",
      "Fig. 46. Word-as-image illustrations created by our method for randomly chosen words.\n",
      "\n",
      "Word-As-Image for Semantic Typography •27\n",
      "Fig. 47. Word-as-image illustrations created by our method for randomly chosen words.\n",
      "\n",
      "28 •Shir Iluz, Yael Vinker, Amir Hertz, Daniel Berio, Daniel Cohen-Or, and Ariel Shamir\n",
      "Fig. 48. Word-as-image illustrations created by our method for randomly chosen words.\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001B[0m\n"
     ]
    },
    {
     "ename": "InvalidRequestError",
     "evalue": "This model's maximum context length is 4097 tokens, however you requested 17468 tokens (17212 in your prompt; 256 for the completion). Please reduce your prompt; or completion length.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInvalidRequestError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[38], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mchain\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43msm_doc\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\base.py:213\u001B[0m, in \u001B[0;36mChain.run\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    211\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    212\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`run` supports only one positional argument.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 213\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_keys[\u001B[38;5;241m0\u001B[39m]]\n\u001B[0;32m    215\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m args:\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m(kwargs)[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_keys[\u001B[38;5;241m0\u001B[39m]]\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\base.py:116\u001B[0m, in \u001B[0;36mChain.__call__\u001B[1;34m(self, inputs, return_only_outputs)\u001B[0m\n\u001B[0;32m    114\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m, \u001B[38;5;167;01mException\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    115\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_manager\u001B[38;5;241m.\u001B[39mon_chain_error(e, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose)\n\u001B[1;32m--> 116\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[0;32m    117\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_manager\u001B[38;5;241m.\u001B[39mon_chain_end(outputs, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose)\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\base.py:113\u001B[0m, in \u001B[0;36mChain.__call__\u001B[1;34m(self, inputs, return_only_outputs)\u001B[0m\n\u001B[0;32m    107\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_manager\u001B[38;5;241m.\u001B[39mon_chain_start(\n\u001B[0;32m    108\u001B[0m     {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m},\n\u001B[0;32m    109\u001B[0m     inputs,\n\u001B[0;32m    110\u001B[0m     verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose,\n\u001B[0;32m    111\u001B[0m )\n\u001B[0;32m    112\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 113\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    114\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m, \u001B[38;5;167;01mException\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    115\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_manager\u001B[38;5;241m.\u001B[39mon_chain_error(e, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\combine_documents\\base.py:56\u001B[0m, in \u001B[0;36mBaseCombineDocumentsChain._call\u001B[1;34m(self, inputs)\u001B[0m\n\u001B[0;32m     54\u001B[0m \u001B[38;5;66;03m# Other keys are assumed to be needed for LLM prediction\u001B[39;00m\n\u001B[0;32m     55\u001B[0m other_keys \u001B[38;5;241m=\u001B[39m {k: v \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m inputs\u001B[38;5;241m.\u001B[39mitems() \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_key}\n\u001B[1;32m---> 56\u001B[0m output, extra_return_dict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcombine_docs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdocs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mother_keys\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     57\u001B[0m extra_return_dict[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_key] \u001B[38;5;241m=\u001B[39m output\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m extra_return_dict\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\combine_documents\\stuff.py:89\u001B[0m, in \u001B[0;36mStuffDocumentsChain.combine_docs\u001B[1;34m(self, docs, **kwargs)\u001B[0m\n\u001B[0;32m     87\u001B[0m inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_inputs(docs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     88\u001B[0m \u001B[38;5;66;03m# Call predict on the LLM.\u001B[39;00m\n\u001B[1;32m---> 89\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mllm_chain\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m, {}\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\llm.py:151\u001B[0m, in \u001B[0;36mLLMChain.predict\u001B[1;34m(self, **kwargs)\u001B[0m\n\u001B[0;32m    137\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mstr\u001B[39m:\n\u001B[0;32m    138\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Format prompt with kwargs and pass to LLM.\u001B[39;00m\n\u001B[0;32m    139\u001B[0m \n\u001B[0;32m    140\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;124;03m            completion = llm.predict(adjective=\"funny\")\u001B[39;00m\n\u001B[0;32m    150\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 151\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_key]\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\base.py:116\u001B[0m, in \u001B[0;36mChain.__call__\u001B[1;34m(self, inputs, return_only_outputs)\u001B[0m\n\u001B[0;32m    114\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m, \u001B[38;5;167;01mException\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    115\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_manager\u001B[38;5;241m.\u001B[39mon_chain_error(e, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose)\n\u001B[1;32m--> 116\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[0;32m    117\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_manager\u001B[38;5;241m.\u001B[39mon_chain_end(outputs, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose)\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\base.py:113\u001B[0m, in \u001B[0;36mChain.__call__\u001B[1;34m(self, inputs, return_only_outputs)\u001B[0m\n\u001B[0;32m    107\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_manager\u001B[38;5;241m.\u001B[39mon_chain_start(\n\u001B[0;32m    108\u001B[0m     {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m},\n\u001B[0;32m    109\u001B[0m     inputs,\n\u001B[0;32m    110\u001B[0m     verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose,\n\u001B[0;32m    111\u001B[0m )\n\u001B[0;32m    112\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 113\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    114\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m, \u001B[38;5;167;01mException\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    115\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_manager\u001B[38;5;241m.\u001B[39mon_chain_error(e, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\llm.py:57\u001B[0m, in \u001B[0;36mLLMChain._call\u001B[1;34m(self, inputs)\u001B[0m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_call\u001B[39m(\u001B[38;5;28mself\u001B[39m, inputs: Dict[\u001B[38;5;28mstr\u001B[39m, Any]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Dict[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mstr\u001B[39m]:\n\u001B[1;32m---> 57\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\llm.py:118\u001B[0m, in \u001B[0;36mLLMChain.apply\u001B[1;34m(self, input_list)\u001B[0m\n\u001B[0;32m    116\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply\u001B[39m(\u001B[38;5;28mself\u001B[39m, input_list: List[Dict[\u001B[38;5;28mstr\u001B[39m, Any]]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m List[Dict[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mstr\u001B[39m]]:\n\u001B[0;32m    117\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Utilize the LLM generate method for speed gains.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 118\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_list\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    119\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcreate_outputs(response)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\llm.py:62\u001B[0m, in \u001B[0;36mLLMChain.generate\u001B[1;34m(self, input_list)\u001B[0m\n\u001B[0;32m     60\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Generate LLM result from inputs.\"\"\"\u001B[39;00m\n\u001B[0;32m     61\u001B[0m prompts, stop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprep_prompts(input_list)\n\u001B[1;32m---> 62\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mllm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate_prompt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\llms\\base.py:107\u001B[0m, in \u001B[0;36mBaseLLM.generate_prompt\u001B[1;34m(self, prompts, stop)\u001B[0m\n\u001B[0;32m    103\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgenerate_prompt\u001B[39m(\n\u001B[0;32m    104\u001B[0m     \u001B[38;5;28mself\u001B[39m, prompts: List[PromptValue], stop: Optional[List[\u001B[38;5;28mstr\u001B[39m]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    105\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m LLMResult:\n\u001B[0;32m    106\u001B[0m     prompt_strings \u001B[38;5;241m=\u001B[39m [p\u001B[38;5;241m.\u001B[39mto_string() \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m prompts]\n\u001B[1;32m--> 107\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt_strings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\llms\\base.py:140\u001B[0m, in \u001B[0;36mBaseLLM.generate\u001B[1;34m(self, prompts, stop)\u001B[0m\n\u001B[0;32m    138\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m, \u001B[38;5;167;01mException\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    139\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_manager\u001B[38;5;241m.\u001B[39mon_llm_error(e, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose)\n\u001B[1;32m--> 140\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[0;32m    141\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_manager\u001B[38;5;241m.\u001B[39mon_llm_end(output, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose)\n\u001B[0;32m    142\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\llms\\base.py:137\u001B[0m, in \u001B[0;36mBaseLLM.generate\u001B[1;34m(self, prompts, stop)\u001B[0m\n\u001B[0;32m    133\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_manager\u001B[38;5;241m.\u001B[39mon_llm_start(\n\u001B[0;32m    134\u001B[0m     {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m}, prompts, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose\n\u001B[0;32m    135\u001B[0m )\n\u001B[0;32m    136\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 137\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_generate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    138\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m, \u001B[38;5;167;01mException\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    139\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_manager\u001B[38;5;241m.\u001B[39mon_llm_error(e, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\llms\\openai.py:281\u001B[0m, in \u001B[0;36mBaseOpenAI._generate\u001B[1;34m(self, prompts, stop)\u001B[0m\n\u001B[0;32m    279\u001B[0m     choices\u001B[38;5;241m.\u001B[39mextend(response[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mchoices\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m    280\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 281\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mcompletion_with_retry\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprompt\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_prompts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    282\u001B[0m     choices\u001B[38;5;241m.\u001B[39mextend(response[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mchoices\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m    283\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstreaming:\n\u001B[0;32m    284\u001B[0m     \u001B[38;5;66;03m# Can't update token usage if streaming\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\llms\\openai.py:99\u001B[0m, in \u001B[0;36mcompletion_with_retry\u001B[1;34m(llm, **kwargs)\u001B[0m\n\u001B[0;32m     95\u001B[0m \u001B[38;5;129m@retry_decorator\u001B[39m\n\u001B[0;32m     96\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_completion_with_retry\u001B[39m(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[0;32m     97\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m llm\u001B[38;5;241m.\u001B[39mclient\u001B[38;5;241m.\u001B[39mcreate(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m---> 99\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_completion_with_retry\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\ProgramData\\anaconda3\\envs\\langchain\\Lib\\site-packages\\tenacity\\__init__.py:289\u001B[0m, in \u001B[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001B[1;34m(*args, **kw)\u001B[0m\n\u001B[0;32m    287\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(f)\n\u001B[0;32m    288\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped_f\u001B[39m(\u001B[38;5;241m*\u001B[39margs: t\u001B[38;5;241m.\u001B[39mAny, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw: t\u001B[38;5;241m.\u001B[39mAny) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m t\u001B[38;5;241m.\u001B[39mAny:\n\u001B[1;32m--> 289\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\ProgramData\\anaconda3\\envs\\langchain\\Lib\\site-packages\\tenacity\\__init__.py:379\u001B[0m, in \u001B[0;36mRetrying.__call__\u001B[1;34m(self, fn, *args, **kwargs)\u001B[0m\n\u001B[0;32m    377\u001B[0m retry_state \u001B[38;5;241m=\u001B[39m RetryCallState(retry_object\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m, fn\u001B[38;5;241m=\u001B[39mfn, args\u001B[38;5;241m=\u001B[39margs, kwargs\u001B[38;5;241m=\u001B[39mkwargs)\n\u001B[0;32m    378\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m--> 379\u001B[0m     do \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mretry_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretry_state\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    380\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(do, DoAttempt):\n\u001B[0;32m    381\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32mD:\\ProgramData\\anaconda3\\envs\\langchain\\Lib\\site-packages\\tenacity\\__init__.py:314\u001B[0m, in \u001B[0;36mBaseRetrying.iter\u001B[1;34m(self, retry_state)\u001B[0m\n\u001B[0;32m    312\u001B[0m is_explicit_retry \u001B[38;5;241m=\u001B[39m fut\u001B[38;5;241m.\u001B[39mfailed \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(fut\u001B[38;5;241m.\u001B[39mexception(), TryAgain)\n\u001B[0;32m    313\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (is_explicit_retry \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mretry(retry_state)):\n\u001B[1;32m--> 314\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfut\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    316\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mafter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mafter(retry_state)\n",
      "File \u001B[1;32mD:\\ProgramData\\anaconda3\\envs\\langchain\\Lib\\concurrent\\futures\\_base.py:449\u001B[0m, in \u001B[0;36mFuture.result\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    447\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n\u001B[0;32m    448\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m==\u001B[39m FINISHED:\n\u001B[1;32m--> 449\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__get_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    451\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_condition\u001B[38;5;241m.\u001B[39mwait(timeout)\n\u001B[0;32m    453\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;129;01min\u001B[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001B[1;32mD:\\ProgramData\\anaconda3\\envs\\langchain\\Lib\\concurrent\\futures\\_base.py:401\u001B[0m, in \u001B[0;36mFuture.__get_result\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    399\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception:\n\u001B[0;32m    400\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 401\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception\n\u001B[0;32m    402\u001B[0m     \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    403\u001B[0m         \u001B[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001B[39;00m\n\u001B[0;32m    404\u001B[0m         \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mD:\\ProgramData\\anaconda3\\envs\\langchain\\Lib\\site-packages\\tenacity\\__init__.py:382\u001B[0m, in \u001B[0;36mRetrying.__call__\u001B[1;34m(self, fn, *args, **kwargs)\u001B[0m\n\u001B[0;32m    380\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(do, DoAttempt):\n\u001B[0;32m    381\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 382\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    383\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m:  \u001B[38;5;66;03m# noqa: B902\u001B[39;00m\n\u001B[0;32m    384\u001B[0m         retry_state\u001B[38;5;241m.\u001B[39mset_exception(sys\u001B[38;5;241m.\u001B[39mexc_info())  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\llms\\openai.py:97\u001B[0m, in \u001B[0;36mcompletion_with_retry.<locals>._completion_with_retry\u001B[1;34m(**kwargs)\u001B[0m\n\u001B[0;32m     95\u001B[0m \u001B[38;5;129m@retry_decorator\u001B[39m\n\u001B[0;32m     96\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_completion_with_retry\u001B[39m(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m---> 97\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mllm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\api_resources\\completion.py:25\u001B[0m, in \u001B[0;36mCompletion.create\u001B[1;34m(cls, *args, **kwargs)\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m     24\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 25\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     26\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m TryAgain \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     27\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m>\u001B[39m start \u001B[38;5;241m+\u001B[39m timeout:\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:155\u001B[0m, in \u001B[0;36mEngineAPIResource.create\u001B[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001B[0m\n\u001B[0;32m    129\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[0;32m    130\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate\u001B[39m(\n\u001B[0;32m    131\u001B[0m     \u001B[38;5;28mcls\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    138\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams,\n\u001B[0;32m    139\u001B[0m ):\n\u001B[0;32m    140\u001B[0m     (\n\u001B[0;32m    141\u001B[0m         deployment_id,\n\u001B[0;32m    142\u001B[0m         engine,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    152\u001B[0m         api_key, api_base, api_type, api_version, organization, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams\n\u001B[0;32m    153\u001B[0m     )\n\u001B[1;32m--> 155\u001B[0m     response, _, api_key \u001B[38;5;241m=\u001B[39m \u001B[43mrequestor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    156\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpost\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    157\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    158\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    159\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    160\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    161\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    162\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest_timeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    163\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    165\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m stream:\n\u001B[0;32m    166\u001B[0m         \u001B[38;5;66;03m# must be an iterator\u001B[39;00m\n\u001B[0;32m    167\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response, OpenAIResponse)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\api_requestor.py:299\u001B[0m, in \u001B[0;36mAPIRequestor.request\u001B[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001B[0m\n\u001B[0;32m    278\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrequest\u001B[39m(\n\u001B[0;32m    279\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    280\u001B[0m     method,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    287\u001B[0m     request_timeout: Optional[Union[\u001B[38;5;28mfloat\u001B[39m, Tuple[\u001B[38;5;28mfloat\u001B[39m, \u001B[38;5;28mfloat\u001B[39m]]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    288\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001B[38;5;28mbool\u001B[39m, \u001B[38;5;28mstr\u001B[39m]:\n\u001B[0;32m    289\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrequest_raw(\n\u001B[0;32m    290\u001B[0m         method\u001B[38;5;241m.\u001B[39mlower(),\n\u001B[0;32m    291\u001B[0m         url,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    297\u001B[0m         request_timeout\u001B[38;5;241m=\u001B[39mrequest_timeout,\n\u001B[0;32m    298\u001B[0m     )\n\u001B[1;32m--> 299\u001B[0m     resp, got_stream \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_interpret_response\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresult\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    300\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m resp, got_stream, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapi_key\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\api_requestor.py:710\u001B[0m, in \u001B[0;36mAPIRequestor._interpret_response\u001B[1;34m(self, result, stream)\u001B[0m\n\u001B[0;32m    702\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[0;32m    703\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_interpret_response_line(\n\u001B[0;32m    704\u001B[0m             line, result\u001B[38;5;241m.\u001B[39mstatus_code, result\u001B[38;5;241m.\u001B[39mheaders, stream\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    705\u001B[0m         )\n\u001B[0;32m    706\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m parse_stream(result\u001B[38;5;241m.\u001B[39miter_lines())\n\u001B[0;32m    707\u001B[0m     ), \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    708\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    709\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[1;32m--> 710\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_interpret_response_line\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    711\u001B[0m \u001B[43m            \u001B[49m\u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    712\u001B[0m \u001B[43m            \u001B[49m\u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstatus_code\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    713\u001B[0m \u001B[43m            \u001B[49m\u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    714\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    715\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m,\n\u001B[0;32m    716\u001B[0m         \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    717\u001B[0m     )\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\api_requestor.py:775\u001B[0m, in \u001B[0;36mAPIRequestor._interpret_response_line\u001B[1;34m(self, rbody, rcode, rheaders, stream)\u001B[0m\n\u001B[0;32m    773\u001B[0m stream_error \u001B[38;5;241m=\u001B[39m stream \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124merror\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m resp\u001B[38;5;241m.\u001B[39mdata\n\u001B[0;32m    774\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m stream_error \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;241m200\u001B[39m \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m rcode \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m300\u001B[39m:\n\u001B[1;32m--> 775\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle_error_response(\n\u001B[0;32m    776\u001B[0m         rbody, rcode, resp\u001B[38;5;241m.\u001B[39mdata, rheaders, stream_error\u001B[38;5;241m=\u001B[39mstream_error\n\u001B[0;32m    777\u001B[0m     )\n\u001B[0;32m    778\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "\u001B[1;31mInvalidRequestError\u001B[0m: This model's maximum context length is 4097 tokens, however you requested 17468 tokens (17212 in your prompt; 256 for the completion). Please reduce your prompt; or completion length."
     ]
    }
   ],
   "source": [
    "chain.run(sm_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3e3add98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T08:45:17.257840700Z",
     "start_time": "2023-10-09T08:45:16.057897400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new StuffDocumentsChain chain...\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"Word-As-Image for Semantic Typography\n",
      "Shir Iluz∗\n",
      "Tel-Aviv University, IsraelYael Vinker∗\n",
      "Tel-Aviv University, IsraelAmir Hertz\n",
      "Tel-Aviv University, Israel\n",
      "Daniel Berio\n",
      "Goldsmiths University, LondonDaniel Cohen-Or\n",
      "Tel-Aviv University, IsraelAriel Shamir\n",
      "Reichman University, Israel\n",
      "Fig. 1. A few examples of our word-as-image illustrations in various fonts and for different textual concept. The semantically adjusted letters are created\n",
      "completely automatically using our method, and can then be used for further creative design as we illustrate here.\n",
      "A word-as-image is a semantic typography technique where a word illus-\n",
      "tration presents a visualization of the meaning of the word, while also\n",
      "preserving its readability. We present a method to create word-as-image\n",
      "illustrations automatically. This task is highly challenging as it requires\n",
      "semantic understanding of the word and a creative idea of where and how to\n",
      "depict these semantics in a visually pleasing and legible manner. We rely on\n",
      "the remarkable ability of recent large pretrained language-vision models to\n",
      "distill textual concepts visually. We target simple, concise, black-and-white\n",
      "designs that convey the semantics clearly. We deliberately do not change the\n",
      "color or texture of the letters and do not use embellishments. Our method\n",
      "optimizes the outline of each letter to convey the desired concept, guided by\n",
      "a pretrained Stable Diffusion model. We incorporate additional loss terms\n",
      "to ensure the legibility of the text and the preservation of the style of the\n",
      "font. We show high quality and engaging results on numerous examples\n",
      "and compare to alternative techniques.\n",
      "Code will be available at our project page.\n",
      "1 INTRODUCTION\n",
      "Semantic typography is the practice of using typography to visually\n",
      "reinforce the meaning of text. This can be achieved through the\n",
      "choice of typefaces, font sizes, font styles, and other typographic\n",
      "elements. A more elaborate and engaging technique for semantic\n",
      "typography is presented by word-as-image illustrations, where the\n",
      "semantics of a given word are illustrated using only the graphical\n",
      "elements of its letters. Such illustrations provide a visual repre-\n",
      "sentation of the meaning of the word, while also preserving the\n",
      "readability of the word as a whole.\n",
      "The task of creating a word-as-image is highly challenging, as it\n",
      "requires the ability to understand and depict the visual characteris-\n",
      "tics of the given concept, and to convey them in a concise, aesthetic,\n",
      "and comprehensible manner without harming legibility. It requires\n",
      "∗Denotes equal contribution.a great deal of creativity and design skills to integrate the chosen\n",
      "visual concept into the letter’s shape [Lee 2011]. In Figure 2 we show\n",
      "some word-as-image examples created manually. For example, to\n",
      "create the “jazz” depiction, the designer had to first choose the visual\n",
      "concept that would best fit the semantics of the text (a saxophone),\n",
      "consider the desired font characteristics, and then choose the most\n",
      "suitable letter to be replaced. Finding the right visual element to\n",
      "illustrate a concept is ill-defined as there are countless ways to il-\n",
      "lustrate any given concept. In addition, one cannot simply copy a\n",
      "selected visual element onto the word – there is a need to find subtle\n",
      "modifications of the letters shape.\n",
      "Because of these complexities, the task of automatic creation of\n",
      "word-as-image illustrations was practically impossible to achieve\n",
      "using computers until recently. In this paper, we define an algo-\n",
      "rithm for automatic creation of word-as-image illustrations based\n",
      "on recent advances in deep-learning and the availability of huge\n",
      "foundational models that combine language and visual understand-\n",
      "ing. Our resulting illustrations (see Figure 1) could be used for logo\n",
      "design, for signs, in greeting cards and invitations, and simply for\n",
      "fun. They can be used as-is, or as inspiration for further refinement\n",
      "of the design.\n",
      "Existing methods in the field of text stylization often rely on raster\n",
      "textures [Yang et al .2018], place a manually created style on top\n",
      "of the strokes segmentation [Berio et al .2022], or deform the text\n",
      "into a pre-defined target shape [Zou et al .2016] (see Figure 3). Only\n",
      "a few works [Tendulkar et al .2019; Zhang et al .2017] deal with\n",
      "semantic typography, and they often operate in the raster domain\n",
      "and use existing icons for replacement (see Figure 3E).\n",
      "Our word-as-image illustrations concentrate on changing only\n",
      "thegeometry of the letters to convey the meaning. We deliberately\n",
      "do not change color or texture and do not use embellishments. ThisarXiv:2303.01818v2  [cs.CV]  6 Mar 2023\n",
      "\n",
      "2•Shir Iluz, Yael Vinker, Amir Hertz, Daniel Berio, Daniel Cohen-Or, and Ariel Shamir\n",
      "Fig. 2. Manually created word-as-image illustrations.\n",
      "allows simple, concise, black-and-white designs that convey the\n",
      "semantics clearly. In addition, since we preserve the vector-based\n",
      "representation of the letters, this allows smooth rasterization in\n",
      "any size, as well as applying additional style manipulations to the\n",
      "illustration using colors and texture, if desired.\n",
      "Given an input word, our method is applied separately for each\n",
      "letter, allowing the user to later choose the most likeable combina-\n",
      "tion for replacement. We represent each letter as a closed vectorized\n",
      "shape, and optimize its parameters to reflect the meaning of the\n",
      "word, while still preserving its original style and design.\n",
      "We rely on the prior of a pretrained Stable Diffusion model [Rom-\n",
      "bach et al .2021] to connect between text and images, and utilize\n",
      "the Score Distillation Sampling approach [Poole et al .2022] (see\n",
      "Section 3) to encourage the appearance of the letter to reflect the\n",
      "provided textual concept. Since the Stable Diffusion model is trained\n",
      "on raster images, we use a differentiable rasterizer [Li et al .2020]\n",
      "that allows to backpropagate gradients from a raster-based loss to\n",
      "the shape’s parameters.\n",
      "To preserve the shape of the original letter and ensure legibility\n",
      "of the word, we utilize two additional loss functions. The first loss\n",
      "regulates the shape modification by constraining the deformation\n",
      "to be as-conformal-as-possible over a triangulation of the letter’s\n",
      "shape. The second loss preserves the local tone and structure of the\n",
      "letter by comparing the low-pass filter of the resulting rasterized\n",
      "letter to the original one.\n",
      "We compare to several baselines, and present many results using\n",
      "various typefaces and a large number of concepts. Our word-as-\n",
      "image illustrations convey the intended concept while maintaining\n",
      "legibility and preserving the appearance of the font, demonstrating\n",
      "visual creativity.\n",
      "2 RELATED WORK\n",
      "Text Stylization. One approach to text stylization is artistic text\n",
      "style transfer, where the style from a given source image is migrated\n",
      "into the desired text (such as in Figure 3A). To tackle this task,\n",
      "existing works incorporate patch-based texture synthesis [Fish et al .\n",
      "2020; Yang et al .2017] as well as variants of GANs [Azadi et al .\n",
      "2018; Jiang et al .2019; Mao et al .2022; Wang et al .2019; Yang et al .\n",
      "2022]. These works operate within the raster domain, a format that\n",
      "is undesirable for typographers since fonts must be scalable. In\n",
      "contrast, we operate on the parametric outlines of the letters, and\n",
      "our glyph manipulation is guided by the semantic meaning of the\n",
      "word, rather than a pre-defined style image.\n",
      "A number of works [Ha and Eck 2018; Lopes et al .2019; Wang\n",
      "and Lian 2021] tackle the task of font generation and stylization\n",
      "in the vector domain. Commonly, a latent feature space of font’s\n",
      "outlines is constructed, represented as outline samples [Balashova\n",
      "et al.2019; Campbell and Kautz 2014] or parametric curve segments\n",
      "[Ha and Eck 2018; Lopes et al .2019; Wang and Lian 2021]. These\n",
      "Fig. 3. Examples of previous text stylization works – (A) Yang et al. [2018],\n",
      "(B) Berio et al. [2022], (C) Zhang et al. [2017], (D) Zou et al. [2016], and (E)\n",
      "Tendulkar et al. [2019]. Most use color and texture or copy icons onto the\n",
      "letters. Our work concentrates on subtle geometric shape deformations of\n",
      "the letters to convey the semantic meaning without color or texture (that\n",
      "can be added later).\n",
      "approaches are often limited to mild deviations from the input data.\n",
      "Other methods rely on templates [Lian et al .2018; Suveeranont and\n",
      "Igarashi 2010] or on user guided [Phan et al .2015] and automatic\n",
      "[Berio et al .2022] stroke segmentation to produce letter stylization\n",
      "(such as in Figure 3B). However, they rely on a manually defined\n",
      "style, while we rely on the expressiveness of Stable Diffusion to\n",
      "guide the modification of the letters’ shape, to convey the meaning\n",
      "of the provided word. In the task of calligram generation [Xu and\n",
      "Kaplan 2007; Zou et al .2016] the entire word is deformed into a\n",
      "given target shape. This task prioritises shape over the readability\n",
      "of the word (see Figure 3D), and is inherently different from ours,\n",
      "as we use the semantics of the word to derive the deformation of\n",
      "individual letters.\n",
      "Most related to our goal, are works that perform semantic styl-\n",
      "ization of text. Tendulkar et al .[2019] replace letters in a given\n",
      "word with clip-art icons describing a given theme (see Figure 3E).\n",
      "To choose the most suitable icon for replacement, an autoencoder\n",
      "is used to measure the distance between the letter and icons from\n",
      "the desired class. Similarly, Zhang et al .[2017] replace stroke-like\n",
      "parts of one or more letters with instances of clip art to generate\n",
      "ornamental stylizations. An example is shown in Figure 3C. These\n",
      "approaches operate in the raster domain, and replace letters with\n",
      "existing icons, which limits them to a predefined set of classes\n",
      "present in the dataset. Our method, however, operates in the vector\n",
      "domain, and incorporates the expressiveness of large pretrained\n",
      "image-language models to create a new illustration that conveys\n",
      "the desired concept.\n",
      "Large Language-Vision Models. With the recent advancement of\n",
      "language-vision models [Radford et al .2021] and diffusion mod-\n",
      "els [Nichol et al .2021; Ramesh et al .2022; Rombach et al .2021], the\n",
      "field of image generation and editing has undergone unprecedented\n",
      "evolution. Having been trained on millions of images and text pairs,\n",
      "these models have proven effective for performing challenging vi-\n",
      "sion related tasks such as image segmentation [Amit et al .2021],\n",
      "domain adaptation [Song et al .2022], image editing [Avrahami et al .\n",
      "2022; Hertz et al .2022; Tumanyan et al .2022a], personalization [Gal\n",
      "\n",
      "Word-As-Image for Semantic Typography •3\n",
      "Fig. 4. More word-as-images produced by our method. Note how styles of\n",
      "different fonts are preserved by the semantic modification.\n",
      "et al.2022, 2023; Ruiz et al .2022], and explainability [Chefer et al .\n",
      "2021]. Despite being trained on raster images, their strong visual\n",
      "and semantic priors have also been shown to be successfully applied\n",
      "to other domains, such as motion [Tevet et al .2022], meshes [Michel\n",
      "et al.2021], point cloud [Zhang et al .2021], and vector graphics.\n",
      "CLIPDraw [Frans et al .2021] uses a differentiable rasterizer [Li\n",
      "et al.2020] to optimize a set of colorful curves w.r.t. a given text\n",
      "prompt, guided by CLIP’s image-text similarity metric. Tian and Ha\n",
      "[2021] use evolutionary algorithms combined with CLIP guidance to\n",
      "create abstract visual concepts based on text. Other works [Vinker\n",
      "et al.2022a,b] utilize the image encoder of CLIP to generate abstract\n",
      "vector sketches from images.\n",
      "Diffusion models have been used for the task of text guided image-\n",
      "to-image translation [Choi et al .2021; Tumanyan et al .2022b]. In\n",
      "SDEdit [Meng et al .2022], an adequate amount of noise is added\n",
      "to a reference image, such that its overall structure is preserved,\n",
      "and then the image is denoised in a reverse process with a guiding\n",
      "text. Pretrained diffusion models have also been used to generate\n",
      "3D objects [Metzer et al .2022; Poole et al .2022], or vector art [Jain\n",
      "et al. 2022] conditioned on text.\n",
      "In our work we also utilize the strong visual and semantic prior\n",
      "induced by a pretrained Stable Diffusion model [Rombach et al .\n",
      "2021], however, for the task of semantic typography . For that purpose\n",
      "we add new components to the optimization process to preserve\n",
      "the font’s style and text legibility.\n",
      "3 BACKGROUND\n",
      "3.1 Fonts and Vector Representation\n",
      "Modern typeface formats such as TrueType [Penney 1996] and\n",
      "PostScript [Inc. 1990] represent glyphs using a vectorized graphic\n",
      "representation of their outlines. Specifically, the outline contours are\n",
      "typically represented by a collection of lines and Bézier or B-Spline\n",
      "curves. This representation allows to scale the letters and rasterize\n",
      "them in any desired size similar to other vector representations.\n",
      "This property is preserved by our method as our output preserves\n",
      "the vectorized representations of the letters.3.2 Latent Diffusion Models\n",
      "Diffusion models are generative models that are trained to learn\n",
      "a data distribution by the gradual denoising of a variable sampled\n",
      "from a Gaussian distribution.\n",
      "In our work, we use the publicly available text-to-image Stable\n",
      "Diffusion model [Rombach et al .2021]. Stable Diffusion is a type of\n",
      "a latent diffusion model (LDM), where the diffusion process is done\n",
      "over the latent space of a pretrained image autoencoder. The encoder\n",
      "Eis tasked with mapping an input image 𝑥into a latent vector 𝑧,\n",
      "and the decoderDis trained to decode 𝑧such thatD(𝑧)≈𝑥.\n",
      "As a second stage, a denoising diffusion probabilistic model (DDPM)\n",
      "[Ho et al .2020] is trained to generate codes within the learned latent\n",
      "space. At each step during training, a scalar 𝑡∈{1,2,...𝑇}is uni-\n",
      "formly sampled and used to define a noised latent code 𝑧𝑡=𝛼𝑡𝑧+𝜎𝑡𝜖,\n",
      "where𝜖∼N( 0,𝐼)and𝛼𝑡,𝜎𝑡are terms that control the noise sched-\n",
      "ule, and are functions of the diffusion process time 𝑡.\n",
      "The denoising network 𝜖𝜃which is based on a UNet architecture\n",
      "[Ronneberger et al .2015], receives as input the noised code 𝑧𝑡, the\n",
      "timestep𝑡and an optional condition vector 𝑐(𝑦), and is tasked with\n",
      "predicting the added noise 𝜖. The LDM loss is defined by:\n",
      "L𝐿𝐷𝑀=E𝑧∼E(𝑥),𝑦,𝜖∼N( 0,1),𝑡\u0002\n",
      "||𝜖−𝜖𝜃(𝑧𝑡,𝑡,𝑐(𝑦))||2\n",
      "2\u0003\n",
      ".(1)\n",
      "In Stable Diffusion, for text-to-image generation, the condition\n",
      "vector is the text embedding produced by a pre-trained CLIP text\n",
      "encoder [Radford et al .2021]. At inference time, a random latent\n",
      "code𝑧𝑇∼N( 0,𝐼)is sampled, and iteratively denoised by the trained\n",
      "𝜖𝜃until producing a clean 𝑧0latent code, which is passed through\n",
      "the decoder 𝐷to produce the image 𝑥.\n",
      "3.3 Score Distillation\n",
      "It is desirable to utilize the strong prior of pretrained large text-\n",
      "image models for the generation of modalities beyond rasterized\n",
      "images. In Stable Diffusion, text conditioning is performed via the\n",
      "cross-attention layers defined at different resolutions in the UNet\n",
      "network. Thus, it is not trivial to guide an optimization process\n",
      "using the conditioned diffusion model.\n",
      "DreamFusion [Poole et al .2022] proposed a way to use the diffu-\n",
      "sion loss to optimize the parameters of a NeRF model for text-to-3D\n",
      "generation. At each iteration, the radiance field is rendered from a\n",
      "random angle, forming the image 𝑥, which is then noised to form\n",
      "𝑥𝑡=𝛼𝑡𝑥+𝜎𝑡𝜖. The noised image is then passed to the pretrained\n",
      "UNet model of Imagen [Saharia et al .2022], that outputs the pre-\n",
      "diction of the noise 𝜖. The score distillation loss is defined by the\n",
      "gradients of the original diffusion loss:\n",
      "∇𝜙L𝑆𝐷𝑆=\u0014\n",
      "𝑤(𝑡)(𝜖𝜃(𝑥𝑡,𝑡,𝑦)−𝜖)𝜕𝑥\n",
      "𝜕𝜙\u0015\n",
      "(2)\n",
      "where𝑦is the condition text prompt, 𝜙are the NeRF’s parameters\n",
      "and𝑤(𝑡)is a constant multiplier that depends on 𝛼𝑡. During train-\n",
      "ing, the gradients are back-propagated to the NeRF parameters to\n",
      "gradually change the 3D object to fit the text prompt. Note that the\n",
      "gradients of the UNet are skipped, and the gradients to modify the\n",
      "Nerf’s parameters are derived directly from the LDM loss.\n",
      "\n",
      "4•Shir Iluz, Yael Vinker, Amir Hertz, Daniel Berio, Daniel Cohen-Or, and Ariel Shamir\n",
      "zt~[50,950]z!“Surfing * “\n",
      "CLIPAugment..Encoder\n",
      "zUNet\n",
      "DiffVG𝑝!𝑝\"𝑝#!𝑝!𝑝\"𝑝#!\n",
      "LPF\n",
      "LPF\n",
      "13\n",
      "2\n",
      "𝑃=𝑃\"=\n",
      "𝑙!𝑙!$\n",
      "𝒟\n",
      "𝒟\n",
      "Fig. 5. An overview of our method. Given an input letter 𝑙𝑖represented by a set of control points 𝑃, and a concept (shown in purple), we optimize the new\n",
      "positions ˆ𝑃of the deformed letter ˆ𝑙𝑖iteratively. At each iteration, the set ˆ𝑃is fed into a differentiable rasterizer (DiffVG marked in blue) that outputs the\n",
      "rasterized deformed letter ˆ𝑙𝑖.ˆ𝑙𝑖is then augmented and passed into a pretrained frozen Stable Diffusion model, that drives the letter shape to convey the\n",
      "semantic concept using the ∇ˆ𝑃LLSDS loss (1).𝑙𝑖and ˆ𝑙𝑖are also passed through a low pass filter (LPF marked in yellow) to compute L𝑡𝑜𝑛𝑒 (2) which encourages\n",
      "the preservation of the overall tone of the font style and also the local letter shape. Additionally, the sets 𝑃and ˆ𝑃are passed through a Delaunay triangulation\n",
      "operator (Dmarked in green), defining L𝑎𝑐𝑎𝑝 (3) which encourages the preservation of the initial shape.\n",
      "3.4 VectorFusion\n",
      "Recently, VectorFusion [Jain et al .2022] utilized the SDS loss for the\n",
      "task of text-to-SVG generation. The proposed generation pipeline\n",
      "involves two stages. Given a text prompt, first, an image is generated\n",
      "using Stable Diffusion (with an added suffix to the prompt), and\n",
      "is then vectorized automatically using LIVE [Ma et al .2022]. This\n",
      "defines an initial set of parameters to be optimized in the second\n",
      "stage using the SDS loss. At each iteration, a differentiable rasterizer\n",
      "[Li et al. 2020] is used to produce a 600×600image, which is then\n",
      "augmented as suggested in CLIPDraw [Frans et al .2021] to get a\n",
      "512×512image𝑥𝑎𝑢𝑔. Then𝑥𝑎𝑢𝑔is fed into the pretrained encoder\n",
      "Eof Stable Diffusion to produce the corresponding latent code\n",
      "𝑧=E(𝑥𝑎𝑢𝑔). The SDS loss is then applied in this latent space, in a\n",
      "similar way to the one defined in DreamFusion:\n",
      "∇𝜃LLSDS=E𝑡,𝜖\u0014\n",
      "𝑤(𝑡)\u0010\n",
      "ˆ𝜖𝜙(𝛼𝑡𝑧𝑡+𝜎𝑡𝜖,𝑦)−𝜖\u0011𝜕𝑧\n",
      "𝜕𝑧𝑎𝑢𝑔𝜕𝑥𝑎𝑢𝑔\n",
      "𝜕𝜃\u0015\n",
      "(3)\n",
      "We find the SDS approach useful for our task of producing se-\n",
      "mantic glyphs, and we follow the technical steps proposed in Vec-\n",
      "torFusion (e.g. augmentations and the added suffix).\n",
      "4 METHOD\n",
      "Given a word 𝑊represented as a string with 𝑛letters{𝑙1,...𝑙𝑛}, our\n",
      "method is applied to every letter 𝑙𝑖separately to produce a semantic\n",
      "visual depiction of the letter. The user can then choose which letters\n",
      "to replace and which to keep in their original form.\n",
      "4.1 Letter Representation\n",
      "We begin by defining the parametric representation of the letters\n",
      "in𝑊. We use the FreeType font library [FreeType 2009] to extract\n",
      "the outline of each letter. We then translate each outline into a set\n",
      "of cubic Bézier curves, to have a consistent representation across\n",
      "different fonts and letters, and to facilitate the use of diffvg [Li et al .\n",
      "2020] for differentiable rasterization.\n",
      "Fig. 6. Illustration of the letter’s outline and control points before (left) and\n",
      "after (right) the subdivision process. The orange dots are the initial Bézier\n",
      "curve segment endpoints. The blue dots are the remaining control points\n",
      "respectively before and after subdivision.\n",
      "Depending on the letter’s complexity and the style of the font,\n",
      "the extracted outlines are defined by a different number of control\n",
      "points. We have found that the initial number of control points\n",
      "affects the final appearance significantly: as the number of control\n",
      "points increases, there is more freedom for visual changes to occur.\n",
      "Therefore, we additionally apply a subdivision procedure to letters\n",
      "containing a small number of control points. We define a desired\n",
      "number of control points for each letter of the alphabet (shared\n",
      "across different fonts), and then iteratively subdivide the Bézier\n",
      "segments until reaching this target number. At each iteration, we\n",
      "compute the maximum arc length among all Bézier segments and\n",
      "split each segment with this length into two (see Figure 6). We\n",
      "analyse the effect of the number of control points in Section 5.3.\n",
      "This procedure defines a set of 𝑘𝑖control points 𝑃𝑖={𝑝𝑗}𝑘𝑖\n",
      "𝑗=1\n",
      "representing the shape of the letter 𝑙𝑖.\n",
      "4.2 Optimization\n",
      "The pipeline of our method is provided in Figure 5. Since we are\n",
      "optimizing each letter 𝑙𝑖separately, for brevity, we will omit the\n",
      "letter index𝑖in the following text and define the set of control points\n",
      "for the input letter as 𝑃.\n",
      "Given𝑃and the desired textual concept 𝑐(both marked in purple\n",
      "in Figure 5), our goal is to produce a new set of control points, ˆ𝑃,\n",
      "\n",
      "Word-As-Image for Semantic Typography •5\n",
      "Fig. 7. Visual illustration of the constraint Delaunay triangulation applied\n",
      "to the initial shapes (left) and the resulting ones (right), for the word “pants”.\n",
      "The ACAP loss maintains the structure of the letter after the deformation.\n",
      "The zoomed rectangle shows the angles for a given control point 𝑝𝑗.\n",
      "defining an adjusted letter ˆ𝑙that conveys the given concept, while\n",
      "maintaining the overall structure and characteristics of the initial\n",
      "letter𝑙.\n",
      "We initialize the learned set of control points ˆ𝑃with𝑃, and pass\n",
      "it through a differentiable rasterizer R[Li et al .2020] (marked in\n",
      "blue), which outputs the rasterized letter R(ˆ𝑃). The rasterized letter\n",
      "is then randomly augmented and passed into a pretrained Stable\n",
      "Diffusion [Rombach et al .2021] model, conditioned on the CLIP’s\n",
      "embedding of the given text 𝑐. The SDS loss∇ˆ𝑃LLSDS is then used\n",
      "as described in Section 3 to encourage R(ˆ𝑃)to convey the given\n",
      "text prompt.\n",
      "To preserve the shape of each individual letter and ensure the\n",
      "legibility of the word as a whole, we use two additional loss functions\n",
      "to guide the optimization process. The first loss limits the overall\n",
      "shape change by defining as-conformal-as-possible constraint on\n",
      "the shape deformation. The second loss preserves the overall shape\n",
      "and style of the font by constraining the tone (i.e. amount of dark\n",
      "vs. light areas in local parts of the shape) of the modified letter not\n",
      "to diverge too much from the original letter (see Section 4.3).\n",
      "The gradients obtained from all the losses are then backpropa-\n",
      "gated, to update the parameters ˆ𝑃. We repeat this process for 500\n",
      "steps, which takes∼5minutes to produce a single letter illustration\n",
      "on RTX2080 GPU.\n",
      "4.3 Loss Functions\n",
      "Our primary objective of encouraging the resulting shape to con-\n",
      "vey the intended semantic concept, is utilized by ∇ˆ𝑃LLSDS loss\n",
      "(described in Section 3). We observe that using ∇ˆ𝑃LLSDS solely can\n",
      "cause large deviations from the initial letter appearance, which is\n",
      "undesired. Hence, our additional goal is to maintain the shape and\n",
      "legibility of the letter R(ˆ𝑃), as well as to keep the original font’s\n",
      "characteristics. For that purpose we use two additional losses.\n",
      "As-Conformal-As-Possible Deformation Loss. To prevent the final\n",
      "letter shape from diverging too much from the initial shape, we\n",
      "triangulate the inner part of the letter and constrain the deformation\n",
      "of the letter to be as conformal as possible (ACAP) [Hormann and\n",
      "Greiner 2000]. We use constrained Delaunay triangulation [Barber\n",
      "and Huhdanpaa 1995; Delaunay et al .1934] on the set of control\n",
      "points defining the glyph. It is known that Delaunay triangulation\n",
      "can be used to produce the skeleton of an outline [Prasad 1997; Zou\n",
      "et al.2001], so the ACAP loss also implicitly captures a skeletal\n",
      "representation of the letter form.\n",
      "Fig. 8. Our tone-preserving loss preserves the local tone of the font by\n",
      "comparing the low-pass filter of the letters images before (left) and after\n",
      "deformation (right). It constrains the adjusted letter not to deviate too much\n",
      "from the original. This example is of the letter B and the word “Bear”.\n",
      "The Delaunay triangulation D(𝑃)splits the glyph represented by\n",
      "𝑃into a set of triangles. This defines a set of size 𝑚𝑗of corresponding\n",
      "angles for each control point 𝑝𝑗(see Figure 7). We denote this set of\n",
      "angles as{𝛼𝑖\n",
      "𝑗}𝑚𝑗\n",
      "𝑖=1. The ACAP loss encourages the induced angles\n",
      "of the optimized shape ˆ𝑃not to deviate much from the angles of\n",
      "the original shape 𝑃, and is defined as the L2 distance between the\n",
      "corresponding angles:\n",
      "L𝑎𝑐𝑎𝑝(𝑃,ˆ𝑃)=1\n",
      "𝑘𝑘∑︁\n",
      "𝑗=1 𝑚𝑗∑︁\n",
      "𝑖=1\u0000𝛼𝑖\n",
      "𝑗−ˆ𝛼𝑖\n",
      "𝑗\u00012!\n",
      "(4)\n",
      "where𝑘=|𝑃|and ˆ𝛼are the angles induced by D(ˆ𝑃).\n",
      "Tone Preservation Loss. To preserve the style of the font as well\n",
      "as the structure of the letter we add a local-tone preservation loss\n",
      "term. This term constrains the tone (amount of black vs. white in\n",
      "all regions of the shape) of the adjusted letter not to deviate too\n",
      "much from tone of the original font’s letter. Towards this end, we\n",
      "apply a low pass filter (LPF) to the rasterized letter (before and after\n",
      "deformation) and compute the L2 distance between the resulting\n",
      "blurred letters:\n",
      "2?𝑃𝐹(R(𝑃))−𝐿𝑃𝐹(R(ˆ𝑃))\n",
      "2(5)\n",
      "An example of the blurred letters is shown in Figure 8, as can be\n",
      "seen, we use a high value of standard deviation 𝜎in the blurring\n",
      "kernel to blur out small details such as the ears of bear.\n",
      "Our final objective is then defined by the weighted average of the\n",
      "three terms:\n",
      "min\n",
      "ˆ𝑃∇ˆ𝑃LLSDS(R(ˆ𝑃),𝑐)+𝛼·L𝑎𝑐𝑎𝑝(𝑃,ˆ𝑃)\n",
      "+𝛽𝑡·L𝑡𝑜𝑛𝑒(R(𝑃),R(ˆ𝑃))(6)\n",
      "where𝛼=0.5and𝛽𝑡depends on the step 𝑡as described next.\n",
      "4.4 Weighting\n",
      "Choosing the relative weights of the three losses presented above\n",
      "is crucial to the appearance of the final letter. While the ∇ˆ𝑃LLSDS\n",
      "loss encourages the shape to deviate from its original appearance to\n",
      "better fit the semantic concept, the two terms L𝑡𝑜𝑛𝑒 andL𝑎𝑐𝑎𝑝 are\n",
      "responsible for maintaining the original shape. Hence, we have two\n",
      "competing parts in the formula, and would like to find a balance\n",
      "between them to maintain the legibility of the letter while allowing\n",
      "the desired semantic shape to change.\n",
      "We find thatL𝑡𝑜𝑛𝑒 can be very dominant. In some cases, if it is\n",
      "used from the beginning, no semantic deformation is performed.\n",
      "\n",
      "6•Shir Iluz, Yael Vinker, Amir Hertz, Daniel Berio, Daniel Cohen-Or, and Ariel Shamir\n",
      "Fig. 9. Word-as-images produced by our method for the word “YOGA”,\n",
      "using eight different fonts.\n",
      "Therefore, we adjust the weight of L𝑡𝑜𝑛𝑒 to kick-in only after some\n",
      "semantic deformation has occurred. We define 𝛽𝑡as follows:\n",
      "𝛽𝑡=𝑎·exp\u0000−(𝑡−𝑏)2\n",
      "2𝑐2\u0001(7)\n",
      "with𝑎=100,𝑏=300,𝑐=30. We analyse the affect of various\n",
      "weighting in Section 5.3. Note that the same hyper-parameter choice\n",
      "works for various words, letters, and fonts.\n",
      "5 RESULTS\n",
      "The robustness of our approach means it should be capable of han-\n",
      "dling a wide range of input concepts as well as supporting different\n",
      "font designs. Figures 1, 4, 33, 17, and more results in the supplemen-\n",
      "tal file demonstrate that our approach can handle inputs from many\n",
      "different categories and various fonts, and that the generated results\n",
      "are legible and creative. Figure 9 demonstrate how the illustrations\n",
      "created by our method for the same word follow the characteristics\n",
      "of different fonts. Although the perceived aesthetics of a word-as-\n",
      "image illustration can be subjective, we define three objectives for\n",
      "an effective result: (1) it should visually capture the given semantic\n",
      "concept, (2) it should maintain readability, and (3) it should preserve\n",
      "the original font’s characteristics.\n",
      "We evaluate the performance of our method on a randomly se-\n",
      "lected set of inputs. We select five common concept classes - animals,\n",
      "fruits, plants, sports, and professions. Using ChatGPT, we sample ten\n",
      "random instances for each class, resulting in 50 words in total. Next,\n",
      "we select four fonts that have distinct visual characteristics, namely\n",
      "Quicksand, Bell MT, Noteworthy-Bold, and HobeauxRococeaux-\n",
      "Sherman. For each word, we randomly sampled one of the four\n",
      "fonts, and applied our method to each letter. For each word with\n",
      "𝑛letters we can generate 2𝑛possible word-as-images, which are\n",
      "all possible combinations of replacements of illustrated letters. A\n",
      "selected subset of these results is presented in Figure 33. The results\n",
      "of all letters and words are presented in the supplementary material.\n",
      "As can be seen, the resulting word-as-image illustrations success-\n",
      "fully convey the given semantic concept in most cases while still\n",
      "remaining legible. In addition, our method successfully captures\n",
      "the font characteristics. For example, in Figure 33, the replacementsTable 1. Perceptual study results. The level of concept recognizability and\n",
      "letter legibility are very high, and style matching of the font is well above\n",
      "random. The “Only SDS” results are created by removing our structure and\n",
      "style preserving losses.\n",
      "Method Semantics Legibility Font\n",
      "Ours 0.8 0.9 0.51\n",
      "Only SDS 0.88 0.53 0.33\n",
      "for the “DRESS” and “LION” are thin and fit well with the rest of\n",
      "the word. In addition, observe the serifs of the letter A used for the\n",
      "fin of the shark in the “SHARK” example. We further use human\n",
      "evaluation to validate this as described below.\n",
      "5.1 Quantitative\n",
      "We conduct a perceptual study to quantitatively assess the three\n",
      "objectives of our resulting word-as-images. We randomly select two\n",
      "instances from each of the resulting word-as-image illustrations\n",
      "for the five classes described above, and visually select one letter\n",
      "from each word, resulting in 10 letters in total. In each question\n",
      "we show an isolated letter illustration, without the context of the\n",
      "word. To evaluate the ability of our method to visually depict the\n",
      "desired concept, we present four label options from the same class,\n",
      "and ask participants to choose the one that describes the letter\n",
      "illustration best. To evaluate the legibility of the results, we ask\n",
      "participants to choose the most suitable letter from a random list of\n",
      "four letters. To asses the preservation of the font style, we present\n",
      "the four fonts and ask participants to choose the most suitable font\n",
      "for the illustration. We gathered answers from 40 participants, and\n",
      "the results are shown in Table 1. As can be seen, the level of concept\n",
      "recognizability and letter legibility are very high, and the 51%of\n",
      "style matching of the letter illustration to the original font is well\n",
      "above random, which is 25%. We also test our algorithm without\n",
      "the two additional structure and style preserving losses ( L𝑎𝑐𝑎𝑝 and\n",
      "L𝑡𝑜𝑛𝑒) on the same words and letters (“Only SDS” in the table).\n",
      "As expected, without the additional constraints, the letter deforms\n",
      "significantly resulting in higher concept recognizability but lower\n",
      "legibility and font style preservation. More details and examples are\n",
      "provided in the supplementary material.\n",
      "5.2 Comparison\n",
      "In the absence of a relevant baseline for comparison, we define base-\n",
      "lines based on large popular text-to-image models. Specifically, we\n",
      "use(1) SD Stable Diffusion [Rombach et al .2021], (2) SDEdit [Meng\n",
      "et al.2022], (3) DallE2 [Ramesh et al .2022] illustrating the word,\n",
      "(4) DallE2+letter illustrating only the letter, and (5) CLIPDraw\n",
      "[Frans et al .2021]. We applied the methods above (details can be\n",
      "found in supplemental material) to three representative words –\n",
      "“bird”, “dress”, and “tulip”, with the fonts Bell MT, Quicksand, and\n",
      "Noteworthy-Bold, respectively. The results can be seen in Figure 10.\n",
      "In some cases Stable Diffusion (SD) did not manage to produce\n",
      "text at all (such as for the bird) and when text is produced, it is\n",
      "often not legible. The results obtained by SDEdit preserve the font’s\n",
      "characteristics and the letter’s legibility, but often fail to reflect\n",
      "the desired concept, such as in the case of the bird and the dress.\n",
      "\n",
      "Word-As-Image for Semantic Typography •7\n",
      "The word\n",
      "BIRD and\n",
      "the letter R\n",
      "The word\n",
      "DRESS and\n",
      "the letter E\n",
      "The word\n",
      "TULIP and\n",
      "the letter U\n",
      "Input SD SDEdit DallE2 DallE2+letter CLIPDraw Ours\n",
      "Fig. 10. Comparison to alternative methods based on large scale text-to-image models. On the left are the letters used as input (only for SDEdit, CLIPDraw, and\n",
      "ours), as well as the desired object of interest. The results from left to right obtained using Stable Diffusion [Rombach et al .2021], SDEdit [Meng et al .2022],\n",
      "DallE2 [Ramesh et al .2022], DallE2 with a letter specific prompt, CLIPDraw [Frans et al .2021], and our single-letter results, as well as the final word-as-image.\n",
      "Additionally, it operates in the raster domain and tends to adddetails\n",
      "on top of the letter, while our method operates directly on the vector\n",
      "representation of the letters with the objective of modifying their\n",
      "shape . DallE2 manages to reflect the visual concept, however it often\n",
      "fails to produce legible text. When applied with a dedicated prompt\n",
      "to produce the word-as-image of only one letter (fifth column), it\n",
      "manages to produce a legible letter, but there is less control over\n",
      "the output – it is impossible to specify the desired font or to control\n",
      "the size, position, and shape of the generated letter. Therefore, it is\n",
      "not clear how to combine these output illustrations into the entire\n",
      "word to create a word-as-image.\n",
      "CLIPDraw produces reasonable results conveying the semantics\n",
      "of the input word. However, the results are non-smooth and the\n",
      "characteristics of the font are not preserved (for example observe\n",
      "how the letter \"E\" differs from the input letter). We further examine\n",
      "CLIPDraw with our shape preservation losses in the next Section.\n",
      "5.3 Ablation\n",
      "Figure 11 illustrates the impact of the letter’s initial number of\n",
      "control points. When less control points are used ( 𝑃𝑜is the original\n",
      "number of control points), we may get insufficient variations, such\n",
      "as for the gorilla. However, this can also result in more abstract\n",
      "depictions, such as the ballerina. As we add control points, we get\n",
      "more graphic results, with the tradeoff that it often deviate from the\n",
      "original letter. In Figure 15 we show the results of using only the\n",
      "∇ˆ𝑃LLSDS loss. As can be seen, in that case the illustrations strongly\n",
      "convey the semantic concept, however at the cost of legibility. In\n",
      "Figure 16 we analyze the effect of the weight 𝛼applied toL𝑎𝑐𝑎𝑝.\n",
      "Ranging from 1to0. WhenL𝑎𝑐𝑎𝑝 is too dominant, the results may\n",
      "not enough reflect the semantic concept, while the opposite case\n",
      "harms legibility. Figure 13 illustrates a change in the 𝜎parameter of\n",
      "the low pass filter. When 𝜎=1almost no blur is applied, resulting\n",
      "in a shape constraint that is too strong.\n",
      "In Figure 14 we show the results of replacing the ∇ˆ𝑃LLSDS loss\n",
      "with a CLIP based loss, while using our proposed shape preservation\n",
      "terms. Although the results obtained with CLIP often depict the\n",
      "desired visual concept, we find that using Stable Diffusion leads\n",
      "to smoother illustrations, that capture a wider range of semantic\n",
      "concepts.By using the hyperparameters described in the paper, we are able\n",
      "to achieve a reasonable balance between semantics and legibility.\n",
      "The parameters were determined manually based on visual assess-\n",
      "ments, but can be adjusted as needed based on the user’s personal\n",
      "taste and goals.\n",
      "\"Ballet\"\n",
      "\"Gorilla\"\n",
      "\"Gym\"\n",
      "Input 𝑃𝑜𝑃 2×𝑃\n",
      "Fig. 11. The effect of the initial number of control points on outputs. On the\n",
      "left are the input letters and the target concepts used to generate the results\n",
      "on the right. 𝑃𝑜indicates the original number of control points as extracted\n",
      "from the font, 𝑃is the input letter with our chosen hyperparameters, and\n",
      "for2×𝑃we increase the number of control points in 𝑃by two.\n",
      "6 CONCLUSIONS\n",
      "We presented a method for the automatic creation of vector-format\n",
      "word-as-image illustrations. Our method can handle a large variety\n",
      "of semantic concepts and use any font, while preserving the legibility\n",
      "of the text and the font’s style.\n",
      "There are limitations to our method. First, our method works\n",
      "letter by letter, and therefore, it cannot deform the shape of the\n",
      "entire word. In the future we can try to optimize the shape of several\n",
      "letters. Second, the approach works best on concrete visual concepts,\n",
      "and may fail with more abstract ones. This can be alleviated by\n",
      "optimizing the shape of letters using different concepts than the\n",
      "word itself. Third, the layout of letters can also be automated for\n",
      "example, using methods such as [Wang et al. 2022].\n",
      "Our word-as-image illustrations demonstrate visual creativity\n",
      "and open the possibility for the use of large vision-language models\n",
      "for semantic typography, possibly also adding human-in-the-loop\n",
      "to arrive at more synergistic design methods of ML models and\n",
      "humans.\n",
      "\n",
      "8•Shir Iluz, Yael Vinker, Amir Hertz, Daniel Berio, Daniel Cohen-Or, and Ariel Shamir\n",
      "\"Bear\"\n",
      "\"Singer\"\n",
      "\"Giraffe\"\n",
      "Input 1 5 30 200Without\n",
      "L𝑡𝑜𝑛𝑒\n",
      "Fig. 13. Altering the 𝜎parameter of the low pass filter using in the L𝑡𝑜𝑛𝑒\n",
      "loss. On the leftmost column are the original letters and concepts used, then\n",
      "from left to right are the results obtained when using 𝜎∈{1,5,30,200},\n",
      "and withoutL𝑡𝑜𝑛𝑒.\n",
      "Input\n",
      "Letter\n",
      "CLIP\n",
      "loss\n",
      "SDS\n",
      "loss\n",
      "\"Snail\" \"Skirt\" \"Socks\" \"Queen\" \"Strawberry\"\n",
      "Fig. 14. Replacing the SDS loss with a CLIP-based loss.Input\n",
      "Letter\n",
      "Ours\n",
      "Only\n",
      "SDS\n",
      "\"Cat\" \"Music\" \"Robot\" \"Cup\" \"Hands\"\n",
      "Fig. 15. The effect of using only the SDS loss: note how the third row simply\n",
      "looks like icon illustrations, while the second row still resembles legible\n",
      "letters.\n",
      "\"Bear\"\n",
      "\"Singer\"\n",
      "\"Giraffe\"\n",
      "Input 1 0.75 0.5 0.25Without\n",
      "L𝑎𝑐𝑎𝑝\n",
      "Fig. 16. Altering the weight 𝛼of theL𝑎𝑐𝑎𝑝 loss. On the leftmost column\n",
      "are the original letters and concepts used, then from left to right are the\n",
      "results obtained when using 𝛼∈{1,0.75,0.5,0.25,0}.\n",
      "Fig. 12. Word-as-images produced by our method. This subset was chosen from the random set of words.\n",
      "\n",
      "Word-As-Image for Semantic Typography •9\n",
      "Fig. 17. Additional results produced by our method.\n",
      "\n",
      "10 •Shir Iluz, Yael Vinker, Amir Hertz, Daniel Berio, Daniel Cohen-Or, and Ariel Shamir\n",
      "7 ACKNOWLEDGMENTS\n",
      "We are grateful to Richard Hao Zhang for the early discussion of\n",
      "the text-as-image problem. Ali Mahdavi-Amiri and Oren Katzir for\n",
      "reviewing earlier versions of the manuscript and to Anran Qi for\n",
      "assisting in evaluating the Chinese words. This research was sup-\n",
      "ported in part by the Israel Science Foundation (grants no. 2492/20\n",
      "and 3441/21), Len Blavatnik and the Blavatnik family foundation,\n",
      "and the Tel Aviv University Innovation Laboratories (TILabs).\n",
      "REFERENCES\n",
      "Tomer Amit, Tal Shaharbany, Eliya Nachmani, and Lior Wolf. 2021. SegDiff: Image\n",
      "Segmentation with Diffusion Probabilistic Models. https://doi.org/10.48550/ARXIV.\n",
      "2112.00390\n",
      "Omri Avrahami, Dani Lischinski, and Ohad Fried. 2022. Blended Diffusion for Text-\n",
      "Driven Editing of Natural Images. In Proceedings of the IEEE/CVF Conference on\n",
      "Computer Vision and Pattern Recognition (CVPR) . 18208–18218.\n",
      "Samaneh Azadi, Matthew Fisher, Vladimir G. Kim, Zhaowen Wang, Eli Shechtman,\n",
      "and Trevor Darrell. 2018. Multi-Content GAN for Few-Shot Font Style Transfer.\n",
      "InProceedings of the IEEE Conference on Computer Vision and Pattern Recognition\n",
      "(CVPR) . IEEE, Salt Lake City, UT, USA, 7564–7573.\n",
      "Elena Balashova, Amit H. Bermano, Vladimir G. Kim, Stephen DiVerdi, Aaron Hertz-\n",
      "mann, and Thomas Funkhouser. 2019. Learning a Stroke-Based Representation for\n",
      "Fonts. Computer Graphics Forum 38, 1 (2019), 429–442.\n",
      "Brad Barber and Hannu Huhdanpaa. 1995. QHull. The Geometry Center, University of\n",
      "Minnesota, http://www. geom. umn. edu/software/qhull (1995).\n",
      "Daniel Berio, Frederic Fol Leymarie, Paul Asente, and Jose Echevarria. 2022. StrokeStyles:\n",
      "Stroke-Based Segmentation and Stylization of Fonts. ACM Trans. Graph. 41, 3, Article\n",
      "28 (apr 2022), 21 pages. https://doi.org/10.1145/3505246\n",
      "Neill DF Campbell and Jan Kautz. 2014. Learning a Manifold of Fonts. ACM Transactions\n",
      "on Graphics (TOG) 33, 4 (2014). https://doi.org/10.1145/2601097.2601212 Article no.\n",
      "91.\n",
      "Hila Chefer, Shir Gur, and Lior Wolf. 2021. Transformer Interpretability Beyond Atten-\n",
      "tion Visualization. In Proceedings of the IEEE/CVF Conference on Computer Vision\n",
      "and Pattern Recognition (CVPR) . 782–791.\n",
      "Jooyoung Choi, Sungwon Kim, Yonghyun Jeong, Youngjune Gwon, and Sungroh Yoon.\n",
      "2021. ILVR: Conditioning Method for Denoising Diffusion Probabilistic Models.\n",
      "CoRR abs/2108.02938 (2021). arXiv:2108.02938 https://arxiv.org/abs/2108.02938\n",
      "Boris Delaunay et al .1934. Sur la sphere vide. Izv. Akad. Nauk SSSR, Otdelenie Matem-\n",
      "aticheskii i Estestvennyka Nauk 7, 793-800 (1934), 1–2.\n",
      "Noa Fish, Lilach Perry, Amit Bermano, and Daniel Cohen-Or. 2020. SketchPatch: Sketch\n",
      "Stylization via Seamless Patch-Level Synthesis. ACM Trans. Graph. 39, 6, Article\n",
      "227 (nov 2020), 14 pages. https://doi.org/10.1145/3414685.3417816\n",
      "Kevin Frans, Lisa B Soros, and Olaf Witkowski. 2021. Clipdraw: Exploring\n",
      "text-to-drawing synthesis through language-image encoders. arXiv preprint\n",
      "arXiv:2106.14843 (2021).\n",
      "FreeType. 2009. FreeType library. https://freetype.org/\n",
      "Rinon Gal, Yuval Alaluf, Yuval Atzmon, Or Patashnik, Amit H. Bermano, Gal Chechik,\n",
      "and Daniel Cohen-Or. 2022. An Image is Worth One Word: Personalizing Text-to-\n",
      "Image Generation using Textual Inversion. https://doi.org/10.48550/ARXIV.2208.\n",
      "01618\n",
      "Rinon Gal, Moab Arar, Yuval Atzmon, Amit H. Bermano, Gal Chechik, and Daniel\n",
      "Cohen-Or. 2023. Designing an Encoder for Fast Personalization of Text-to-Image\n",
      "Models. https://doi.org/10.48550/ARXIV.2302.12228\n",
      "David Ha and Douglas Eck. 2018. A Neural Representation of Sketch Draw-\n",
      "ings. In Sixth International Conference on Learning Representations (ICLR) .\n",
      "https://arxiv.org/abs/1704.03477.\n",
      "Amir Hertz, Ron Mokady, Jay Tenenbaum, Kfir Aberman, Yael Pritch, and Daniel\n",
      "Cohen-Or. 2022. Prompt-to-prompt image editing with cross attention control.\n",
      "(2022).\n",
      "Jonathan Ho, Ajay Jain, and Pieter Abbeel. 2020. Denoising Diffusion Probabilistic\n",
      "Models. CoRR abs/2006.11239 (2020). arXiv:2006.11239 https://arxiv.org/abs/2006.\n",
      "11239\n",
      "Kai Hormann and Günther Greiner. 2000. MIPS: An efficient global parametrization\n",
      "method . Technical Report. Erlangen-Nuernberg Univ (Germany) Computer Graphics\n",
      "Group.\n",
      "Adobe Systems Inc. 1990. Adobe Type 1 Font Format . Addison Wesley Publishing\n",
      "Company.\n",
      "Ajay Jain, Amber Xie, and Pieter Abbeel. 2022. VectorFusion: Text-to-SVG by Abstract-\n",
      "ing Pixel-Based Diffusion Models. arXiv preprint arXiv:2211.11319 (2022).\n",
      "Yue Jiang, Zhouhui Lian, Yingmin Tang, and Jianguo Xiao. 2019. SCFont: Structure-\n",
      "Guided Chinese Font Generation via Deep Stacked Networks. Proceedings of the\n",
      "AAAI Conference on Artificial Intelligence 33, 01 (Jul. 2019), 4015–4022. https://doi.org/10.1609/aaai.v33i01.33014015\n",
      "Ji Lee. 2011. Word As Image . Adams Media, London.\n",
      "Tzu-Mao Li, Michal Lukáč, Gharbi Michaël, and Jonathan Ragan-Kelley. 2020. Differen-\n",
      "tiable Vector Graphics Rasterization for Editing and Learning. ACM Trans. Graph.\n",
      "(Proc. SIGGRAPH Asia) 39, 6 (2020), 193:1–193:15.\n",
      "Zhouhui Lian, Bo Zhao, Xudong Chen, and Jianguo Xiao. 2018. EasyFont: A style\n",
      "learning-based system to easily build your large-scale handwriting fonts. ACM\n",
      "Transactions on Graphics (TOG) 38, 1 (2018), 1–18.\n",
      "Raphael Gontijo Lopes, David Ha, Douglas Eck, and Jonathon Shlens. 2019. A Learned\n",
      "Representation for Scalable Vector Graphics. In Proceedings of the IEEE/CVF Interna-\n",
      "tional Conference on Computer Vision (ICCV) .\n",
      "Xu Ma, Yuqian Zhou, Xingqian Xu, Bin Sun, Valerii Filev, Nikita Orlov, Yun Fu, and\n",
      "Humphrey Shi. 2022. Towards Layer-wise Image Vectorization. https://doi.org/10.\n",
      "48550/ARXIV.2206.04655\n",
      "Wendong Mao, Shuai Yang, Huihong Shi, Jiaying Liu, and Zhongfeng Wang. 2022. Intel-\n",
      "ligent Typography: Artistic Text Style Transfer for Complex Texture and Structure.\n",
      "IEEE Transactions on Multimedia (2022), 1–15. https://doi.org/10.1109/TMM.2022.\n",
      "3209870\n",
      "Chenlin Meng, Yutong He, Yang Song, Jiaming Song, Jiajun Wu, Jun-Yan Zhu, and\n",
      "Stefano Ermon. 2022. SDEdit: Guided Image Synthesis and Editing with Stochastic\n",
      "Differential Equations. In International Conference on Learning Representations .\n",
      "Gal Metzer, Elad Richardson, Or Patashnik, Raja Giryes, and Daniel Cohen-Or. 2022.\n",
      "Latent-NeRF for Shape-Guided Generation of 3D Shapes and Textures. https:\n",
      "//doi.org/10.48550/ARXIV.2211.07600\n",
      "Oscar Michel, Roi Bar-On, Richard Liu, Sagie Benaim, and Rana Hanocka.\n",
      "2021. Text2Mesh: Text-Driven Neural Stylization for Meshes. arXiv preprint\n",
      "arXiv:2112.03221 (2021).\n",
      "Alex Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam, Pamela Mishkin, Bob\n",
      "McGrew, Ilya Sutskever, and Mark Chen. 2021. Glide: Towards photorealistic\n",
      "image generation and editing with text-guided diffusion models. arXiv preprint\n",
      "arXiv:2112.10741 (2021).\n",
      "Laurence Penney. 1996. A History of TrueType. https://www.truetype-\n",
      "typography.com/.\n",
      "Huy Quoc Phan, Hongbo Fu, and Antoni B Chan. 2015. Flexyfont: Learning Transferring\n",
      "Rules for Flexible Typeface Synthesis. Computer Graphics Forum 34, 7 (2015), 245–\n",
      "256.\n",
      "Ben Poole, Ajay Jain, Jonathan T Barron, and Ben Mildenhall. 2022. Dreamfusion:\n",
      "Text-to-3d using 2d diffusion. arXiv preprint arXiv:2209.14988 (2022).\n",
      "Lakshman Prasad. 1997. Morphological analysis of shapes. CNLS newsletter 139, 1\n",
      "(1997), 1997–07.\n",
      "Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini\n",
      "Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen\n",
      "Krueger, and Ilya Sutskever. 2021. Learning Transferable Visual Models From\n",
      "Natural Language Supervision. CoRR abs/2103.00020 (2021). arXiv:2103.00020\n",
      "https://arxiv.org/abs/2103.00020\n",
      "Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen. 2022.\n",
      "Hierarchical text-conditional image generation with clip latents. arXiv preprint\n",
      "arXiv:2204.06125 (2022).\n",
      "Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn\n",
      "Ommer. 2021. High-Resolution Image Synthesis with Latent Diffusion Models.\n",
      "arXiv:2112.10752 [cs.CV]\n",
      "Olaf Ronneberger, Philipp Fischer, and Thomas Brox. 2015. U-net: Convolutional\n",
      "networks for biomedical image segmentation. In International Conference on Medical\n",
      "image computing and computer-assisted intervention . Springer, 234–241.\n",
      "Nataniel Ruiz, Yuanzhen Li, Varun Jampani, Yael Pritch, Michael Rubinstein, and Kfir\n",
      "Aberman. 2022. DreamBooth: Fine Tuning Text-to-image Diffusion Models for\n",
      "Subject-Driven Generation. (2022).\n",
      "Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily Den-\n",
      "ton, Seyed Kamyar Seyed Ghasemipour, Burcu Karagol Ayan, S. Sara Mahdavi,\n",
      "Rapha Gontijo Lopes, Tim Salimans, Jonathan Ho, David J Fleet, and Mohammad\n",
      "Norouzi. 2022. Photorealistic Text-to-Image Diffusion Models with Deep Language\n",
      "Understanding. https://doi.org/10.48550/ARXIV.2205.11487\n",
      "Kunpeng Song, Ligong Han, Bingchen Liu, Dimitris Metaxas, and Ahmed Elgammal.\n",
      "2022. Diffusion Guided Domain Adaptation of Image Generators. https://doi.org/\n",
      "10.48550/ARXIV.2212.04473\n",
      "Rapee Suveeranont and Takeo Igarashi. 2010. Example-Based Automatic Font Genera-\n",
      "tion. In Smart Graphics . Number LNCS 6133 in Lecture Notes in Computer Science.\n",
      "127–138.\n",
      "Purva Tendulkar, Kalpesh Krishna, Ramprasaath R. Selvaraju, and Devi Parikh. 2019.\n",
      "Trick or TReAT: Thematic Reinforcement for Artistic Typography. https://doi.org/\n",
      "10.48550/ARXIV.1903.07820\n",
      "Guy Tevet, Brian Gordon, Amir Hertz, Amit H Bermano, and Daniel Cohen-Or. 2022.\n",
      "Motionclip: Exposing human motion generation to clip space. In Computer Vision–\n",
      "ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23–27, 2022, Proceedings,\n",
      "Part XXII . Springer, 358–374.\n",
      "\n",
      "Word-As-Image for Semantic Typography •11\n",
      "Yingtao Tian and David Ha. 2021. Modern Evolution Strategies for Creativity: Fitting\n",
      "Concrete Images and Abstract Conceptst. arXiv:2109.08857 [cs.NE]\n",
      "Narek Tumanyan, Michal Geyer, Shai Bagon, and Tali Dekel. 2022a. Plug-and-Play\n",
      "Diffusion Features for Text-Driven Image-to-Image Translation. https://doi.org/10.\n",
      "48550/ARXIV.2211.12572\n",
      "Narek Tumanyan, Michal Geyer, Shai Bagon, and Tali Dekel. 2022b. Plug-and-Play\n",
      "Diffusion Features for Text-Driven Image-to-Image Translation. https://doi.org/10.\n",
      "48550/ARXIV.2211.12572\n",
      "Yael Vinker, Yuval Alaluf, Daniel Cohen-Or, and Ariel Shamir. 2022a. CLIPascene: Scene\n",
      "Sketching with Different Types and Levels of Abstraction. https://doi.org/10.48550/\n",
      "ARXIV.2211.17256\n",
      "Yael Vinker, Ehsan Pajouheshgar, Jessica Y. Bo, Roman Christian Bachmann, Amit Haim\n",
      "Bermano, Daniel Cohen-Or, Amir Zamir, and Ariel Shamir. 2022b. CLIPasso:\n",
      "Semantically-Aware Object Sketching. ACM Trans. Graph. 41, 4, Article 86 (jul\n",
      "2022), 11 pages. https://doi.org/10.1145/3528223.3530068\n",
      "Patrick von Platen, Suraj Patil, Anton Lozhkov, Pedro Cuenca, Nathan Lambert, Kashif\n",
      "Rasul, Mishig Davaadorj, and Thomas Wolf. 2022. Diffusers: State-of-the-art diffu-\n",
      "sion models. https://github.com/huggingface/diffusers.\n",
      "Wenjing Wang, Jiaying Liu, Shuai Yang, and Zongming Guo. 2019. Typography With\n",
      "Decor: Intelligent Text Style Transfer. In Proceedings of the IEEE/CVF Conference on\n",
      "Computer Vision and Pattern Recognition (CVPR) .\n",
      "Yizhi Wang and Zhouhui Lian. 2021. DeepVecFont: Synthesizing High-Quality Vector\n",
      "Fonts via Dual-Modality Learning. ACM Transactions on Graphics 40, 6 (Dec. 2021),\n",
      "1–15. https://doi.org/10.1145/3478513.3480488\n",
      "Yizhi Wang, Guo Pu, Wenhan Luo, Yexin Wang, Pengfei Xiong, Hongwen Kang, and\n",
      "Zhouhui Lian. 2022. Aesthetic Text Logo Synthesis via Content-Aware Layout\n",
      "Inferring. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern\n",
      "Recognition (CVPR) . 2436–2445.\n",
      "Jie Xu and Craig S. Kaplan. 2007. Calligraphic Packing. In Proceedings of Graphics\n",
      "Interface 2007 on - GI ’07 . ACM Press, Montreal, Canada, 43. https://doi.org/10.1145/\n",
      "1268517.1268527\n",
      "Shuai Yang, Jiaying Liu, Zhouhui Lian, and Zongming Guo. 2017. Awesome Typography:\n",
      "Statistics-Based Text Effects Transfer. In Proceedings of the IEEE Conference on\n",
      "Computer Vision and Pattern Recognition (CVPR) .\n",
      "Shuai Yang, Jiaying Liu, Wenhan Yang, and Zongming Guo. 2018. Context-Aware Un-\n",
      "supervised Text Stylization. In Proceedings of the 26th ACM International Conference\n",
      "on Multimedia (Seoul, Republic of Korea) (MM ’18) . Association for Computing Ma-\n",
      "chinery, New York, NY, USA, 1688–1696. https://doi.org/10.1145/3240508.3240580\n",
      "Shuai Yang, Zhangyang Wang, and Jiaying Liu. 2022. Shape-Matching GAN++: Scale\n",
      "Controllable Dynamic Artistic Text Style Transfer. IEEE Transactions on Pattern\n",
      "Analysis and Machine Intelligence 44, 7 (2022), 3807–3820. https://doi.org/10.1109/\n",
      "TPAMI.2021.3055211\n",
      "Junsong Zhang, Yu Wang, Weiyi Xiao, and Zhenshan Luo. 2017. Synthesizing Orna-\n",
      "mental Typefaces: Synthesizing Ornamental Typefaces. Computer Graphics Forum\n",
      "36, 1 (Jan. 2017), 64–75. https://doi.org/10.1111/cgf.12785\n",
      "Renrui Zhang, Ziyu Guo, Wei Zhang, Kunchang Li, Xupeng Miao, Bin Cui, Yu Qiao,\n",
      "Peng Gao, and Hongsheng Li. 2021. PointCLIP: Point Cloud Understanding by CLIP.\n",
      "https://doi.org/10.48550/ARXIV.2112.02413\n",
      "Changqing Zou, Junjie Cao, Warunika Ranaweera, Ibraheem Alhashim, Ping Tan, Alla\n",
      "Sheffer, and Hao Zhang. 2016. Legible Compact Calligrams. ACM Transactions on\n",
      "Graphics 35, 4 (July 2016), 1–12. https://doi.org/10.1145/2897824.2925887\n",
      "Ju Jia Zou, Hung-Hsin Chang, and Hong Yan. 2001. Shape skeletonization by identifying\n",
      "discrete local symmetries. Pattern Recognition 34, 10 (2001), 1895–1905.\n",
      "\n",
      "12 •Shir Iluz, Yael Vinker, Amir Hertz, Daniel Berio, Daniel Cohen-Or, and Ariel Shamir\n",
      "SUPPLEMENTARY MATERIAL\n",
      "A IMPLEMENTATION DETAILS\n",
      "In this section we provide further implementation details. We intend\n",
      "to release the code to promote future research in this domain.\n",
      "Our method is based on the pre-trained 𝑣1−5Stable Diffusion\n",
      "model [Rombach et al .2021], which we use through the diffusers\n",
      "[von Platen et al .2022] Python package. We optimize only the\n",
      "control points’ coordinates (i.e. we do not modify the color, width,\n",
      "and other parameters of the shape). We use the Adam optimizer with\n",
      "𝛽1=0.9,𝛽2=0.9,𝜖=10−6. We use learning rate warm-up from\n",
      "0.1to0.8over 100iterations and exponential decay from 0.8to0.4\n",
      "over the rest 400iterations, 500iteration in total. The optimization\n",
      "process requires at least 10GB memory and approximately 5 minutes\n",
      "to produce a single letter illustration on RTX2080 GPU.\n",
      "Before we feed the rasterized 600𝑥600letter image into the Stable\n",
      "Diffusion model, we apply random augmentations as proposed in\n",
      "CLIPDraw [Frans et al .2021]. Specifically, perspective transform\n",
      "with a distortion scale of 0.5, with probability 0.7, and a random\n",
      "512𝑥512crop. We add the suffix \"a [ word ]. minimal flat 2d vector.\n",
      "lineal color. trending on artstation.\" to the target word 𝑊, before\n",
      "feeding it into the text encoder of a pretrained CLIP model.\n",
      "B COMPARISONS\n",
      "As described in Section 5.2 we define five baselines to compare with.\n",
      "In this section we provide more details about the evaluation and\n",
      "more qualitative results. For (1) SD , we run Stable Diffusion [Rom-\n",
      "bach et al .2021] with the default hyper parameters of 50inference\n",
      "steps and a guidance scale of 7.5. We use the prompt “Word as image\n",
      "of the word [ word ]. [font] font. minimal flat 2d vector. lineal color.\n",
      "black and white style”.\n",
      "For(2) SDEdit [Meng et al .2022], we utilized the diffusers [von\n",
      "Platen et al .2022] implementation, using the prompt “A [ word ].\n",
      "minimal flat 2d vector. lineal color. black and white style”, and the\n",
      "rasterized input letter as the reference image. We use the default\n",
      "values of 50inference steps and a guidance scale of 7.5. We use a\n",
      "strength value of 0.85. The strength value determines the quantity\n",
      "of noise added to the input image – a value close to 1.0results in\n",
      "higher degree of variation in the output, and vice versa.\n",
      "We use the official website of OpenAI to run (3) DallE2 [Ramesh\n",
      "et al.2022], using the prompt “Word as image of the word [ word ].\n",
      "Where the letter [ letter ] looks like a [ word ]. [font] font. minimal\n",
      "flat 2d vector. lineal color. black and white style”. To encourage\n",
      "the manipulation of a specific letter, for (4) DallE2+letter we use\n",
      "the prompt “The letter [ letter ] in the shape of a [ word ]. [font] font.\n",
      "minimal flat 2d vector. lineal color. black and white style”. For (5)\n",
      "CLIPDraw [Frans et al .2021], we use the author’s official imple-\n",
      "mentation with the recommended hyper-parameters. Instead of\n",
      "using randomly initialized strokes, we use our vectorized letter as\n",
      "input, along with the prompt “A [ word ]. [font] font. minimal flat\n",
      "2d vector. lineal color. black and white style”. We provide more\n",
      "comparisons to the methods described above in Figure 20.\n",
      "Fig. 18. Some additional examples of word-as-image applied on Chinese\n",
      "characters. In Chinese, a whole word can be represented by one character.\n",
      "Here we show from left: bird, rabbit, cat and surfing (two last characters\n",
      "together). The complexity of characters imposes an additional challenge for\n",
      "our method. This could be alleviated in the future for example by dividing\n",
      "the characters to radicals and applying the method only on parts of the\n",
      "character.\n",
      "C PERCEPTUAL STUDY\n",
      "In this section, we provide more details about the perceptual study\n",
      "described in Section 5.1. The randomly chosen objects, fonts, and\n",
      "letters are shown in Table 2. A few visual examples are shown in\n",
      "Figure 19.\n",
      "Ours Only SDS\n",
      "\"Coat\"\n",
      "\"Soccer\"\n",
      "\"Shirt\"\n",
      "\"Rugby\"\n",
      "Font\n",
      "Rec.\n",
      "Fig. 19. Examples of illustrations presented in the perceptual study. Each\n",
      "pair in the top part shows illustrations obtained using our proposed method\n",
      "(left) and using only SDS loss (right). On the bottom is an example of an\n",
      "illustration presented for the font recognition questions.\n",
      "D ADDITIONAL RESULTS\n",
      "We provide additional results of our generated word-as-images. In\n",
      "Figures 21-32 we show results of selected words and unique fonts.\n",
      "\n",
      "Word-As-Image for Semantic Typography •13\n",
      "\"Muffin\"\n",
      "\"Tiger\"\n",
      "\"Octopus\"\n",
      "\"Plant\"\n",
      "\"Astronaut\"\n",
      "\"Robot\"\n",
      "\"Bunny\"\n",
      "\"Flamingo\"\n",
      "\"Paris\"\n",
      "\"Owl\"\n",
      "\"Swan\"\n",
      "\"Mermaid\"\n",
      "Input SD SDEdit DallE2 DallE2+letter CLIPDraw Ours\n",
      "Fig. 20. Comparison to alternative methods based on large scale text-to-image models. On the left are the letters used as input (only for SDEdit, CLIPDraw,\n",
      "and ours), as well as the desired object of interest. The results from left to right obtained using Stable Diffusion [Rombach et al .2021], SDEdit [Meng et al .\n",
      "2022], DallE2 [Ramesh et al. 2022], DallE2 with a letter specific prompt, CLIPDraw [Frans et al. 2021], and our single-letter results.\n",
      "In Figures 33-48 we show the results obtained for the random set of\n",
      "words.\n",
      "\n",
      "14 •Shir Iluz, Yael Vinker, Amir Hertz, Daniel Berio, Daniel Cohen-Or, and Ariel Shamir\n",
      "Table 2. Randomly chosen objects, letters, and fonts for the perceptual\n",
      "study.\n",
      "Object Letter Font\n",
      "Pineapple P Noteworthy-Bold\n",
      "Orange O Quicksand\n",
      "Rugby Y Noteworthy-Bold\n",
      "Soccer S Noteworthy-Bold\n",
      "Bear B Bell MT\n",
      "Lion O Quicksand\n",
      "Singer N Noteworthy-Bold\n",
      "Pilot P Noteworthy-Bold\n",
      "Coat O HobeauxRococeaux-Sherman\n",
      "Shirt S Bell MT\n",
      "Fig. 21. Word-as-image illustrations created by our method.\n",
      "\n",
      "Word-As-Image for Semantic Typography •15\n",
      "Fig. 22. Word-as-image illustrations created by our method.\n",
      "Fig. 23. Word-as-image illustrations created by our method.\n",
      "Fig. 24. Word-as-image illustrations created by our method.\n",
      "\n",
      "16 •Shir Iluz, Yael Vinker, Amir Hertz, Daniel Berio, Daniel Cohen-Or, and Ariel Shamir\n",
      "Fig. 25. Word-as-image illustrations created by our method.\n",
      "Fig. 26. Word-as-image illustrations created by our method.\n",
      "\n",
      "Word-As-Image for Semantic Typography •17\n",
      "Fig. 27. Word-as-image illustrations created by our method.\n",
      "Fig. 28. Word-as-image illustrations created by our method.\n",
      "\n",
      "18 •Shir Iluz, Yael Vinker, Amir Hertz, Daniel Berio, Daniel Cohen-Or, and Ariel Shamir\n",
      "Fig. 29. Word-as-image illustrations created by our method.\n",
      "Fig. 30. Word-as-image illustrations created by our method.\n",
      "\n",
      "Word-As-Image for Semantic Typography •19\n",
      "Fig. 31. Word-as-image illustrations created by our method.\n",
      "Fig. 32. Word-as-image illustrations created by our method.\n",
      "\n",
      "20 •Shir Iluz, Yael Vinker, Amir Hertz, Daniel Berio, Daniel Cohen-Or, and Ariel Shamir\n",
      "Fig. 33. Word-as-image illustrations created by our method for randomly chosen words.\n",
      "Fig. 34. Word-as-image illustrations created by our method for randomly chosen words.\n",
      "\n",
      "Word-As-Image for Semantic Typography •21\n",
      "Fig. 35. Word-as-image illustrations created by our method for randomly chosen words.\n",
      "Fig. 36. Word-as-image illustrations created by our method for randomly chosen words.\n",
      "\n",
      "22 •Shir Iluz, Yael Vinker, Amir Hertz, Daniel Berio, Daniel Cohen-Or, and Ariel Shamir\n",
      "Fig. 37. Word-as-image illustrations created by our method for randomly chosen words.\n",
      "Fig. 38. Word-as-image illustrations created by our method for randomly chosen words.\n",
      "\n",
      "Word-As-Image for Semantic Typography •23\n",
      "Fig. 39. Word-as-image illustrations created by our method for randomly chosen words.\n",
      "Fig. 40. Word-as-image illustrations created by our method for randomly chosen words.\n",
      "\n",
      "24 •Shir Iluz, Yael Vinker, Amir Hertz, Daniel Berio, Daniel Cohen-Or, and Ariel Shamir\n",
      "Fig. 41. Word-as-image illustrations created by our method for randomly chosen words.\n",
      "Fig. 42. Word-as-image illustrations created by our method for randomly chosen words.\n",
      "\n",
      "Word-As-Image for Semantic Typography •25\n",
      "Fig. 43. Word-as-image illustrations created by our method for randomly chosen words.\n",
      "Fig. 44. Word-as-image illustrations created by our method for randomly chosen words.\n",
      "\n",
      "26 •Shir Iluz, Yael Vinker, Amir Hertz, Daniel Berio, Daniel Cohen-Or, and Ariel Shamir\n",
      "Fig. 45. Word-as-image illustrations created by our method for randomly chosen words.\n",
      "Fig. 46. Word-as-image illustrations created by our method for randomly chosen words.\n",
      "\n",
      "Word-As-Image for Semantic Typography •27\n",
      "Fig. 47. Word-as-image illustrations created by our method for randomly chosen words.\n",
      "\n",
      "28 •Shir Iluz, Yael Vinker, Amir Hertz, Daniel Berio, Daniel Cohen-Or, and Ariel Shamir\n",
      "Fig. 48. Word-as-image illustrations created by our method for randomly chosen words.\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001B[0m\n"
     ]
    },
    {
     "ename": "InvalidRequestError",
     "evalue": "This model's maximum context length is 4097 tokens, however you requested 17468 tokens (17212 in your prompt; 256 for the completion). Please reduce your prompt; or completion length.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInvalidRequestError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[68], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mchain\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlg_doc\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\base.py:213\u001B[0m, in \u001B[0;36mChain.run\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    211\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    212\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`run` supports only one positional argument.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 213\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_keys[\u001B[38;5;241m0\u001B[39m]]\n\u001B[0;32m    215\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m args:\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m(kwargs)[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_keys[\u001B[38;5;241m0\u001B[39m]]\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\base.py:116\u001B[0m, in \u001B[0;36mChain.__call__\u001B[1;34m(self, inputs, return_only_outputs)\u001B[0m\n\u001B[0;32m    114\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m, \u001B[38;5;167;01mException\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    115\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_manager\u001B[38;5;241m.\u001B[39mon_chain_error(e, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose)\n\u001B[1;32m--> 116\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[0;32m    117\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_manager\u001B[38;5;241m.\u001B[39mon_chain_end(outputs, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose)\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\base.py:113\u001B[0m, in \u001B[0;36mChain.__call__\u001B[1;34m(self, inputs, return_only_outputs)\u001B[0m\n\u001B[0;32m    107\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_manager\u001B[38;5;241m.\u001B[39mon_chain_start(\n\u001B[0;32m    108\u001B[0m     {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m},\n\u001B[0;32m    109\u001B[0m     inputs,\n\u001B[0;32m    110\u001B[0m     verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose,\n\u001B[0;32m    111\u001B[0m )\n\u001B[0;32m    112\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 113\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    114\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m, \u001B[38;5;167;01mException\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    115\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_manager\u001B[38;5;241m.\u001B[39mon_chain_error(e, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\combine_documents\\base.py:56\u001B[0m, in \u001B[0;36mBaseCombineDocumentsChain._call\u001B[1;34m(self, inputs)\u001B[0m\n\u001B[0;32m     54\u001B[0m \u001B[38;5;66;03m# Other keys are assumed to be needed for LLM prediction\u001B[39;00m\n\u001B[0;32m     55\u001B[0m other_keys \u001B[38;5;241m=\u001B[39m {k: v \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m inputs\u001B[38;5;241m.\u001B[39mitems() \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_key}\n\u001B[1;32m---> 56\u001B[0m output, extra_return_dict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcombine_docs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdocs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mother_keys\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     57\u001B[0m extra_return_dict[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_key] \u001B[38;5;241m=\u001B[39m output\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m extra_return_dict\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\combine_documents\\stuff.py:89\u001B[0m, in \u001B[0;36mStuffDocumentsChain.combine_docs\u001B[1;34m(self, docs, **kwargs)\u001B[0m\n\u001B[0;32m     87\u001B[0m inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_inputs(docs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     88\u001B[0m \u001B[38;5;66;03m# Call predict on the LLM.\u001B[39;00m\n\u001B[1;32m---> 89\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mllm_chain\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m, {}\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\llm.py:151\u001B[0m, in \u001B[0;36mLLMChain.predict\u001B[1;34m(self, **kwargs)\u001B[0m\n\u001B[0;32m    137\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mstr\u001B[39m:\n\u001B[0;32m    138\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Format prompt with kwargs and pass to LLM.\u001B[39;00m\n\u001B[0;32m    139\u001B[0m \n\u001B[0;32m    140\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;124;03m            completion = llm.predict(adjective=\"funny\")\u001B[39;00m\n\u001B[0;32m    150\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 151\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_key]\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\base.py:116\u001B[0m, in \u001B[0;36mChain.__call__\u001B[1;34m(self, inputs, return_only_outputs)\u001B[0m\n\u001B[0;32m    114\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m, \u001B[38;5;167;01mException\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    115\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_manager\u001B[38;5;241m.\u001B[39mon_chain_error(e, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose)\n\u001B[1;32m--> 116\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[0;32m    117\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_manager\u001B[38;5;241m.\u001B[39mon_chain_end(outputs, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose)\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\base.py:113\u001B[0m, in \u001B[0;36mChain.__call__\u001B[1;34m(self, inputs, return_only_outputs)\u001B[0m\n\u001B[0;32m    107\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_manager\u001B[38;5;241m.\u001B[39mon_chain_start(\n\u001B[0;32m    108\u001B[0m     {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m},\n\u001B[0;32m    109\u001B[0m     inputs,\n\u001B[0;32m    110\u001B[0m     verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose,\n\u001B[0;32m    111\u001B[0m )\n\u001B[0;32m    112\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 113\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    114\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m, \u001B[38;5;167;01mException\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    115\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_manager\u001B[38;5;241m.\u001B[39mon_chain_error(e, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\llm.py:57\u001B[0m, in \u001B[0;36mLLMChain._call\u001B[1;34m(self, inputs)\u001B[0m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_call\u001B[39m(\u001B[38;5;28mself\u001B[39m, inputs: Dict[\u001B[38;5;28mstr\u001B[39m, Any]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Dict[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mstr\u001B[39m]:\n\u001B[1;32m---> 57\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\llm.py:118\u001B[0m, in \u001B[0;36mLLMChain.apply\u001B[1;34m(self, input_list)\u001B[0m\n\u001B[0;32m    116\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply\u001B[39m(\u001B[38;5;28mself\u001B[39m, input_list: List[Dict[\u001B[38;5;28mstr\u001B[39m, Any]]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m List[Dict[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mstr\u001B[39m]]:\n\u001B[0;32m    117\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Utilize the LLM generate method for speed gains.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 118\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_list\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    119\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcreate_outputs(response)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\llm.py:62\u001B[0m, in \u001B[0;36mLLMChain.generate\u001B[1;34m(self, input_list)\u001B[0m\n\u001B[0;32m     60\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Generate LLM result from inputs.\"\"\"\u001B[39;00m\n\u001B[0;32m     61\u001B[0m prompts, stop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprep_prompts(input_list)\n\u001B[1;32m---> 62\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mllm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate_prompt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\llms\\base.py:107\u001B[0m, in \u001B[0;36mBaseLLM.generate_prompt\u001B[1;34m(self, prompts, stop)\u001B[0m\n\u001B[0;32m    103\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgenerate_prompt\u001B[39m(\n\u001B[0;32m    104\u001B[0m     \u001B[38;5;28mself\u001B[39m, prompts: List[PromptValue], stop: Optional[List[\u001B[38;5;28mstr\u001B[39m]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    105\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m LLMResult:\n\u001B[0;32m    106\u001B[0m     prompt_strings \u001B[38;5;241m=\u001B[39m [p\u001B[38;5;241m.\u001B[39mto_string() \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m prompts]\n\u001B[1;32m--> 107\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt_strings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\llms\\base.py:140\u001B[0m, in \u001B[0;36mBaseLLM.generate\u001B[1;34m(self, prompts, stop)\u001B[0m\n\u001B[0;32m    138\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m, \u001B[38;5;167;01mException\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    139\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_manager\u001B[38;5;241m.\u001B[39mon_llm_error(e, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose)\n\u001B[1;32m--> 140\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[0;32m    141\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_manager\u001B[38;5;241m.\u001B[39mon_llm_end(output, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose)\n\u001B[0;32m    142\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\llms\\base.py:137\u001B[0m, in \u001B[0;36mBaseLLM.generate\u001B[1;34m(self, prompts, stop)\u001B[0m\n\u001B[0;32m    133\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_manager\u001B[38;5;241m.\u001B[39mon_llm_start(\n\u001B[0;32m    134\u001B[0m     {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m}, prompts, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose\n\u001B[0;32m    135\u001B[0m )\n\u001B[0;32m    136\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 137\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_generate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    138\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m, \u001B[38;5;167;01mException\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    139\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_manager\u001B[38;5;241m.\u001B[39mon_llm_error(e, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\llms\\openai.py:281\u001B[0m, in \u001B[0;36mBaseOpenAI._generate\u001B[1;34m(self, prompts, stop)\u001B[0m\n\u001B[0;32m    279\u001B[0m     choices\u001B[38;5;241m.\u001B[39mextend(response[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mchoices\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m    280\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 281\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mcompletion_with_retry\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprompt\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_prompts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    282\u001B[0m     choices\u001B[38;5;241m.\u001B[39mextend(response[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mchoices\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m    283\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstreaming:\n\u001B[0;32m    284\u001B[0m     \u001B[38;5;66;03m# Can't update token usage if streaming\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\llms\\openai.py:99\u001B[0m, in \u001B[0;36mcompletion_with_retry\u001B[1;34m(llm, **kwargs)\u001B[0m\n\u001B[0;32m     95\u001B[0m \u001B[38;5;129m@retry_decorator\u001B[39m\n\u001B[0;32m     96\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_completion_with_retry\u001B[39m(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[0;32m     97\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m llm\u001B[38;5;241m.\u001B[39mclient\u001B[38;5;241m.\u001B[39mcreate(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m---> 99\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_completion_with_retry\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\ProgramData\\anaconda3\\envs\\langchain\\Lib\\site-packages\\tenacity\\__init__.py:289\u001B[0m, in \u001B[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001B[1;34m(*args, **kw)\u001B[0m\n\u001B[0;32m    287\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(f)\n\u001B[0;32m    288\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped_f\u001B[39m(\u001B[38;5;241m*\u001B[39margs: t\u001B[38;5;241m.\u001B[39mAny, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw: t\u001B[38;5;241m.\u001B[39mAny) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m t\u001B[38;5;241m.\u001B[39mAny:\n\u001B[1;32m--> 289\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\ProgramData\\anaconda3\\envs\\langchain\\Lib\\site-packages\\tenacity\\__init__.py:379\u001B[0m, in \u001B[0;36mRetrying.__call__\u001B[1;34m(self, fn, *args, **kwargs)\u001B[0m\n\u001B[0;32m    377\u001B[0m retry_state \u001B[38;5;241m=\u001B[39m RetryCallState(retry_object\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m, fn\u001B[38;5;241m=\u001B[39mfn, args\u001B[38;5;241m=\u001B[39margs, kwargs\u001B[38;5;241m=\u001B[39mkwargs)\n\u001B[0;32m    378\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m--> 379\u001B[0m     do \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mretry_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretry_state\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    380\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(do, DoAttempt):\n\u001B[0;32m    381\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32mD:\\ProgramData\\anaconda3\\envs\\langchain\\Lib\\site-packages\\tenacity\\__init__.py:314\u001B[0m, in \u001B[0;36mBaseRetrying.iter\u001B[1;34m(self, retry_state)\u001B[0m\n\u001B[0;32m    312\u001B[0m is_explicit_retry \u001B[38;5;241m=\u001B[39m fut\u001B[38;5;241m.\u001B[39mfailed \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(fut\u001B[38;5;241m.\u001B[39mexception(), TryAgain)\n\u001B[0;32m    313\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (is_explicit_retry \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mretry(retry_state)):\n\u001B[1;32m--> 314\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfut\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    316\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mafter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mafter(retry_state)\n",
      "File \u001B[1;32mD:\\ProgramData\\anaconda3\\envs\\langchain\\Lib\\concurrent\\futures\\_base.py:449\u001B[0m, in \u001B[0;36mFuture.result\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    447\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n\u001B[0;32m    448\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m==\u001B[39m FINISHED:\n\u001B[1;32m--> 449\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__get_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    451\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_condition\u001B[38;5;241m.\u001B[39mwait(timeout)\n\u001B[0;32m    453\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;129;01min\u001B[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001B[1;32mD:\\ProgramData\\anaconda3\\envs\\langchain\\Lib\\concurrent\\futures\\_base.py:401\u001B[0m, in \u001B[0;36mFuture.__get_result\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    399\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception:\n\u001B[0;32m    400\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 401\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception\n\u001B[0;32m    402\u001B[0m     \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    403\u001B[0m         \u001B[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001B[39;00m\n\u001B[0;32m    404\u001B[0m         \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mD:\\ProgramData\\anaconda3\\envs\\langchain\\Lib\\site-packages\\tenacity\\__init__.py:382\u001B[0m, in \u001B[0;36mRetrying.__call__\u001B[1;34m(self, fn, *args, **kwargs)\u001B[0m\n\u001B[0;32m    380\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(do, DoAttempt):\n\u001B[0;32m    381\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 382\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    383\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m:  \u001B[38;5;66;03m# noqa: B902\u001B[39;00m\n\u001B[0;32m    384\u001B[0m         retry_state\u001B[38;5;241m.\u001B[39mset_exception(sys\u001B[38;5;241m.\u001B[39mexc_info())  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\llms\\openai.py:97\u001B[0m, in \u001B[0;36mcompletion_with_retry.<locals>._completion_with_retry\u001B[1;34m(**kwargs)\u001B[0m\n\u001B[0;32m     95\u001B[0m \u001B[38;5;129m@retry_decorator\u001B[39m\n\u001B[0;32m     96\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_completion_with_retry\u001B[39m(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m---> 97\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mllm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\api_resources\\completion.py:25\u001B[0m, in \u001B[0;36mCompletion.create\u001B[1;34m(cls, *args, **kwargs)\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m     24\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 25\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     26\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m TryAgain \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     27\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m>\u001B[39m start \u001B[38;5;241m+\u001B[39m timeout:\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:155\u001B[0m, in \u001B[0;36mEngineAPIResource.create\u001B[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001B[0m\n\u001B[0;32m    129\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[0;32m    130\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate\u001B[39m(\n\u001B[0;32m    131\u001B[0m     \u001B[38;5;28mcls\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    138\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams,\n\u001B[0;32m    139\u001B[0m ):\n\u001B[0;32m    140\u001B[0m     (\n\u001B[0;32m    141\u001B[0m         deployment_id,\n\u001B[0;32m    142\u001B[0m         engine,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    152\u001B[0m         api_key, api_base, api_type, api_version, organization, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams\n\u001B[0;32m    153\u001B[0m     )\n\u001B[1;32m--> 155\u001B[0m     response, _, api_key \u001B[38;5;241m=\u001B[39m \u001B[43mrequestor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    156\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpost\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    157\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    158\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    159\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    160\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    161\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    162\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest_timeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    163\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    165\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m stream:\n\u001B[0;32m    166\u001B[0m         \u001B[38;5;66;03m# must be an iterator\u001B[39;00m\n\u001B[0;32m    167\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response, OpenAIResponse)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\api_requestor.py:299\u001B[0m, in \u001B[0;36mAPIRequestor.request\u001B[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001B[0m\n\u001B[0;32m    278\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrequest\u001B[39m(\n\u001B[0;32m    279\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    280\u001B[0m     method,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    287\u001B[0m     request_timeout: Optional[Union[\u001B[38;5;28mfloat\u001B[39m, Tuple[\u001B[38;5;28mfloat\u001B[39m, \u001B[38;5;28mfloat\u001B[39m]]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    288\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001B[38;5;28mbool\u001B[39m, \u001B[38;5;28mstr\u001B[39m]:\n\u001B[0;32m    289\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrequest_raw(\n\u001B[0;32m    290\u001B[0m         method\u001B[38;5;241m.\u001B[39mlower(),\n\u001B[0;32m    291\u001B[0m         url,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    297\u001B[0m         request_timeout\u001B[38;5;241m=\u001B[39mrequest_timeout,\n\u001B[0;32m    298\u001B[0m     )\n\u001B[1;32m--> 299\u001B[0m     resp, got_stream \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_interpret_response\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresult\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    300\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m resp, got_stream, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapi_key\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\api_requestor.py:710\u001B[0m, in \u001B[0;36mAPIRequestor._interpret_response\u001B[1;34m(self, result, stream)\u001B[0m\n\u001B[0;32m    702\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[0;32m    703\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_interpret_response_line(\n\u001B[0;32m    704\u001B[0m             line, result\u001B[38;5;241m.\u001B[39mstatus_code, result\u001B[38;5;241m.\u001B[39mheaders, stream\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    705\u001B[0m         )\n\u001B[0;32m    706\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m parse_stream(result\u001B[38;5;241m.\u001B[39miter_lines())\n\u001B[0;32m    707\u001B[0m     ), \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    708\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    709\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[1;32m--> 710\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_interpret_response_line\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    711\u001B[0m \u001B[43m            \u001B[49m\u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    712\u001B[0m \u001B[43m            \u001B[49m\u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstatus_code\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    713\u001B[0m \u001B[43m            \u001B[49m\u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    714\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    715\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m,\n\u001B[0;32m    716\u001B[0m         \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    717\u001B[0m     )\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\api_requestor.py:775\u001B[0m, in \u001B[0;36mAPIRequestor._interpret_response_line\u001B[1;34m(self, rbody, rcode, rheaders, stream)\u001B[0m\n\u001B[0;32m    773\u001B[0m stream_error \u001B[38;5;241m=\u001B[39m stream \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124merror\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m resp\u001B[38;5;241m.\u001B[39mdata\n\u001B[0;32m    774\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m stream_error \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;241m200\u001B[39m \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m rcode \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m300\u001B[39m:\n\u001B[1;32m--> 775\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle_error_response(\n\u001B[0;32m    776\u001B[0m         rbody, rcode, resp\u001B[38;5;241m.\u001B[39mdata, rheaders, stream_error\u001B[38;5;241m=\u001B[39mstream_error\n\u001B[0;32m    777\u001B[0m     )\n\u001B[0;32m    778\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "\u001B[1;31mInvalidRequestError\u001B[0m: This model's maximum context length is 4097 tokens, however you requested 17468 tokens (17212 in your prompt; 256 for the completion). Please reduce your prompt; or completion length."
     ]
    }
   ],
   "source": [
    "chain.run(lg_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bc1482",
   "metadata": {},
   "source": [
    "### Summarize: Map Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6819d5c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T08:45:20.370393400Z",
     "start_time": "2023-10-09T08:45:20.346945600Z"
    }
   },
   "outputs": [],
   "source": [
    "chain = load_summarize_chain(llm, chain_type=\"map_reduce\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "57ad190a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T08:45:26.671896200Z",
     "start_time": "2023-10-09T08:45:21.090112100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new MapReduceDocumentsChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"The winter glory of the Sierra ! How little is known of it! Californians admire descriptions of the Swiss Alps, reading with breathless interest how ice and snow load their sublime heights, and booming avalanches sweep in glorious array through their crowded forests, while our own icy, snow-laden mountains, with their unrivaled forests, loom unnoticed along our eastern horizon. True, only mountaineers may penetrate their snow-blocked fastnesses to behold them in all their white wild grandeur, but to every healthy man and woman, and even to children, many of the subalpine valleys and lake-basins, six or seven thousand feet above the sea, remain invitingly open and approachable all winter. With a friend and his two little sons I have just returned from a week of bracing weathering around Lake Tahoe, in which we enjoyed glorious views of winter, fine rolling and sliding in the snow, swimming in the icy lake, and lusty reviving exercise on snow-shoes that kept our pulses dancing right merrily. All the weather was hearty and exhilarating, though varying almost from hour to hour: snowing, blowing, clear and cloudy, but never rigorously cold.\n",
      "\n",
      "This winter has been remarkably mild, the mercury having seldom made a very near approach to zero, even during the coldest nights around the lake, while the average noonday temperature was considerably above the freezing- point. The snow lies deep on the surrounding mountains and about the shores, solid white contrasting with the dark-blue water of the lake, while the forests and canons and the upper glacial fountain hollows are well filled, assuring abundance of summer water for the lakes and streams.\n",
      "\n",
      "According to the record kept by Mr. McKinney, on the west shore of the lake, eight miles above Tahoe City, at an elevation of 6,500 feet above sea-level, the amount of snow, measured as it fell, was twenty-two feet and four inches for the season up to March 20th, with four inches of rain, while an inch or two more of rain and two or three feet of snow will probably fall before the full opening of spring. Last season the snowfall, measured by the same observer, at the same station, was only nine feet and seven inches, while the season before last it was no less than forty seven feet and six inches. The fall about Yosemite Valley, according to my own observations, usually considerably exceeded this. The greater portion of the snow that loads the main summits of the range falls in small crisp flakes and broken crystals; or when accompanied by strong winds at a low temperature, the crystals, instead of being locked together in tufted flakes, are driven against each other and broken into meal and fine dust which darkens the sky like night But down in the forested region, at about the elevation of Lake Tahoe, the greater portion comes gently to the ground, light and feathery, some of the flakes in mild weather being nearly an inch in diameter, and is evenly distributed and kept from drifting to any great extent by Lake Tahoe in Winter. 121 the shelter of the woods. Every tree is loaded with the fairy bloom, bending down the branches, and hushing the singing of the elastic needles.\n",
      "\n",
      "When the storm is over and the sun shines, the dazzling snow at once begins to settle and shift and fall off the trees in miniature avalanches; then the relieved branches spring up and shake themselves dry, and the whole green forest, fed and refreshed, waves and sings again rejoicing. The snow on the ground settles also, and thaws and freezes until it becomes coarsely granulated ice, with all trace of its crystalline snow structure destroyed. This is the present condition of most of the snow on the range. From towards midnight until midday at this time of year a man may walk firmly over the surface, as if on ice, provided the preceding day has been warm and the night frosty.\n",
      "\n",
      "The forested region up to an elevation of about eight thousand feet is generally clear of snow towards the end of May or middle of June; but now (March 28th) the higher canons are still heavily blocked, and the head tributaries of the rivers flow in dark tunnels beneath the icy mass. As warm summer advances, the roof of compacted snow falls in here and there, leaving magnificent arching bridges where it is strongest, over which one may safely ride a horse. All the upper streams are thus buried and bridged every winter, and are seldom completely opened to the light before the end of June or middle of July.\n",
      "\n",
      "Notwithstanding twenty-two feet of snow has fallen here this season, so greatly has it been melted and compacted, the present average depth at a height of 7,500 feet does not exceed seven feet. The drifts in exposed lake hollows and along the lee sides of bald ridges above the timberline are often fifty feet or more in depth, and many of the latter are grandly adorned with overcurling cornices, beneath which pale blue light shimmers with ineffable beauty. But it is in the fountain cirques of the ancient glaciers, beneath the shadows of the highest peaks, that the heaviest and most enduring deposits are stored up. For there the lavish snowfall on the steep converging slopes is shot down in avalanches during or after' every storm, heaping snow on snow to a depth of a hundred feet, or even more at times. These treasured banks are never wholly melted, however hot the summer, but with the few lingering glaciers form perennial fountains for the highest tributaries of the rivers.\n",
      "\n",
      "Few even among Californians have any fair conception of the marvelous abundance of glacier lakes hidden in the fastnesses of our mountains. The snow and some of the glaciers make a telling show, even from the distant lowlands; but not a single stream is visible, nor a hollow where one might hope to find a lake. Nevertheless, wild rivers are falling and sounding in every canon, and all their upper branches are fairly laden with lakes like orchard-trees with fruit. They nestle in rocky nooks and hollows about all the high peaks and in the larger canons, reflecting their stern, rugged beauty and giving charming animation to the bleakest and most forbidding landscapes. From the summit of Red Mountain, a day's journey to the east of Yosemite Valley, forty-two may be seen within a radius of eight or ten miles. The whole number in the Sierra can hardly be less than fifteen hundred, exclusive of the smaller gems, which are innumerable. Perhaps two-thirds of them lie on the west flank of the range, and all are restricted to the alpine and subalpine regions, those which once brightened the lower regions having long since vanished by the filling in of their basins. Lake Tahoe is king of them all, not only in size, but in the surpassing beauty of its shores and waters. It seems a kind of heaven to which the dead lakes of the lowlands had come with their best beauty spiritualized.\n",
      "\n",
      "It lies embosomed in mountains of moderate height near the northern extremity of the high portion of the Lake Tahoe in Winter. 123 range, between the main axis and a spur that puts out on the east side from near the head of the Carson River. Though it is twenty-one miles long by ten wide, and from about five hundred to sixteen hundred feet deep, its basin was once occupied by a glacier which filled it from the bottom to a point high above the present water-level, and being lavishly fed by the snows of the encompassing mountains, crawled slowly, like a mighty river, over the north rim of the basin, crushing and grinding the lower mountains that lay in its way, and it was only at the end of the ice period that this noble lake, at least in anything like its present form, came into existence.\n",
      "\n",
      "Excepting the forests that have sprung up around its shores, the post-glacial changes that have taken place are scarcely appreciable. The sediments carried forward by the inflowing streams at the head of the lake have made a few square miles of meadow-land, and the breaking through of a moraine dam in the canon of the outlet has lowered the lake considerably, leaving shore benches and lines on the rocky promontories to mark the original level. With these comparatively unimportant exceptions, the lake itself and all its grandly sculptured, ice-scored, and moraine-streaked basin exist to-day in just about the condition they presented when first they came to the light towards the close of the Glacial Period.\n",
      "\n",
      "The destructive action of man in clearing away the forests has not as yet effected any very marked change in general views. Perhaps about 150,000,000 feet of lumber for the Comstock mines has thus far been cut from the lake shores. But the business is being pushed so fervently from year to year, almost the entire basin must be stripped ere long of one of its most attractive features. One of the lumber companies at work here has contracted with mine owners to supply 36,000,000 feet of lumber and 60,000 cords of wood this season. It is estimated that the Tahoe basin still contains about 600,000,000 feet of lumber available for the mines.\n",
      "\n",
      "In summer the woods resound with the outlandish noise of loggers and choppers and screaming mills; skiffs and steamboats skim the lovely blue water in work and play; and ever and anon as you thread the groves along shore you come upon groups of gay tourists sauntering about, gathering flowers, or resting luxuriously in the rosiny shade of the pines, some in easy picnic attire, others all ribbons and colors, glaring wildly amid the green leaves and frightening the wondering squirrels and birds. But winter brings rest. At sight of the first snowflake pleasure-seekers flee as from a plague, the ax leaves the woods, and the kind snow heals every scar. Contemplating the basin from any commanding hilltop, only pale curls of smoke seen at wide intervals betoken the existence of human dwellings. Like the bears, the few settlers that remain here are silently \"holed up.\" The snow covers their cabins as if they were bowlders, and when approached only a narrow shoveled-out passage, or tunnel, is found leading to the door. Some of the more enterprising winter dwellers drift about in boats in calm weather, catching trout for the Carson market,â€”for the lake, on account of its great depth, never freezes. They thus earn from thirty to forty dollars a month, and at the same time get rid of lonely dullness. A trapper may also be seen now and then shuffling along the shore on long Norwegian snow-shoes in pursuit of minks, fishers, and otters.\n",
      "\n",
      "In this letter I intended only to say a good word for winter in the mountains, hoping to incite others to come and enjoy it, sketching our excursion to illustrate the ease and comfort with which such snowy winter rambles may be made; but I have written too much I fear about the snow to leave room for more than a thin outline. We went by rail to Lake Tahoe in Winter. 125 Carson, and from there set out by stage for Glenbrook. After ascending on wheels until we reached the snow-line, the driver attached his four horses to a sled, hoping thus to cross the summit, which is less than eight thousand feet high, without much difficulty. But mild weather had softened the snow, and the unfortunate animals, after floundering and wallowing through a mile of it, lay down exhausted with their heels in the air. Then we made our way on foot over to the lake. Next day, on a small steam-tug, we crossed the lake to McKinney's, on the west shore, where we were at home. Here we spent a few health-giving, delightful days, rowing, bathing, racing at lightning speed on snow-shoes down a mountain-side back of the house, and slipping about through the solemn, silent woods. Only the eldest of my companions ventured with me on the steep slopes. This was his first experience on snowshoes, and the several descents he made were the most remarkable specimens of falling locomotion that I ever had the fortune to witness.\n",
      "\n",
      "In shooting down steep declivities the long sled-runner-like shoes have to be kept parallel with firmly braced limbs. My friend, however, heedless of advice, launched himself in wild abandon, bouncing and diving, his limbs and shoes in chaotic entanglement, now in the snow, now in the air, whirling over and over in giddy rolls and somersaults that would shame the most extravagant performances of a circus acrobat. How original and inimitable he was! Wonderfully refreshing and exhilarating his queer capers must have been; for on coming to rest, with his runaway members divorced and lost, he would quietly gather himself, pick out the snow from his neck and ears, and say with preternatural solemnity, \"This, Muir, is the very poetry of motion.\"\n",
      "\n",
      "We also spent some rare evenings by the huge fire in McKinney's old cabin. The log walls are covered with trophies of the chase, for our host has been a great hunter in his day. Two live pet coons were frolicking on the floor while our grand old host smiled benignly and played with them, the firelight gleaming on his weathered face. How big he seems, thus brought into relief, and what a shadow he casts! The fragrant rosiny fire is the very god of the home. No wonder the old nations, with their fresher instincts, had their fireside gods. At last, when a mild snow-storm was blowing, we rowed to the lower end of the lake and completed our excursion by slipping on snow-shoes down the Truckee canon to the railroad.\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"\n",
      "This is a description of a winter excursion to Lake Tahoe in California. The mild winter weather made it possible to enjoy the snow-laden mountains, lake swimming, and snow-shoeing. There is an abundance of snow and glaciers, as well as a large number of glacier lakes. Human activity such as logging and tourist activity is also discussed. The letter concludes with a description of a snow-shoeing adventure and a cozy evening by the fire in an old cabin.\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "' A winter excursion to Lake Tahoe in California is described, featuring activities such as snow-shoeing, lake swimming, and snow-shoeing. The area is abundant in snow, glaciers, and glacier lakes, and is impacted by logging and tourist activity. The letter ends with a description of a snow-shoeing adventure and a cozy evening beside a cabin fire.'"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(sm_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4898d986",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T08:45:26.680658700Z",
     "start_time": "2023-10-09T08:45:26.672893600Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "20a994e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T08:45:26.687723600Z",
     "start_time": "2023-10-09T08:45:26.676669200Z"
    }
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size = 400,\n",
    "    chunk_overlap = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "877728d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T08:45:26.725553200Z",
     "start_time": "2023-10-09T08:45:26.687723600Z"
    }
   },
   "outputs": [],
   "source": [
    "lg_docs = text_splitter.split_documents(lg_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5ad8f7b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T08:45:26.732537300Z",
     "start_time": "2023-10-09T08:45:26.698712200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 172 document(s)\n",
      "You have roughly 8129 words in your docs\n",
      "\n",
      "Preview: \n",
      "Word-As-Image for Semantic Typography\n",
      "Shir Iluz∗\n",
      "Tel-Aviv University, IsraelYael Vinker∗\n",
      "Tel-Aviv University, IsraelAmir Hertz\n",
      "Tel-Aviv University, Israel\n",
      "Daniel Berio\n",
      "Goldsmiths University, LondonDaniel Cohen-Or\n",
      "Tel-Aviv University, IsraelAriel Shamir\n",
      "Reichman University, Israel\n"
     ]
    }
   ],
   "source": [
    "doc_summary(lg_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "682900fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T08:45:33.759649800Z",
     "start_time": "2023-10-09T08:45:29.126255500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new MapReduceDocumentsChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"Word-As-Image for Semantic Typography\n",
      "Shir Iluz∗\n",
      "Tel-Aviv University, IsraelYael Vinker∗\n",
      "Tel-Aviv University, IsraelAmir Hertz\n",
      "Tel-Aviv University, Israel\n",
      "Daniel Berio\n",
      "Goldsmiths University, LondonDaniel Cohen-Or\n",
      "Tel-Aviv University, IsraelAriel Shamir\n",
      "Reichman University, Israel\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"Fig. 1. A few examples of our word-as-image illustrations in various fonts and for different textual concept. The semantically adjusted letters are created\n",
      "completely automatically using our method, and can then be used for further creative design as we illustrate here.\n",
      "A word-as-image is a semantic typography technique where a word illus-\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"tration presents a visualization of the meaning of the word, while also\n",
      "preserving its readability. We present a method to create word-as-image\n",
      "illustrations automatically. This task is highly challenging as it requires\n",
      "semantic understanding of the word and a creative idea of where and how to\n",
      "depict these semantics in a visually pleasing and legible manner. We rely on\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"the remarkable ability of recent large pretrained language-vision models to\n",
      "distill textual concepts visually. We target simple, concise, black-and-white\n",
      "designs that convey the semantics clearly. We deliberately do not change the\n",
      "color or texture of the letters and do not use embellishments. Our method\n",
      "optimizes the outline of each letter to convey the desired concept, guided by\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"a pretrained Stable Diffusion model. We incorporate additional loss terms\n",
      "to ensure the legibility of the text and the preservation of the style of the\n",
      "font. We show high quality and engaging results on numerous examples\n",
      "and compare to alternative techniques.\n",
      "Code will be available at our project page.\n",
      "1 INTRODUCTION\n",
      "Semantic typography is the practice of using typography to visually\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\" This paper examines the concept of semantic typography, wherein words are used as images. The authors, Shir Iluz, Yael Vinker, Amir Hertz, Daniel Berio, Daniel Cohen-Or and Ariel Shamir, represent Tel-Aviv University, Goldsmiths University and Reichman University in Israel. They explore how this technique can be applied to create meaningful, visually-appealing typography.\n",
      "\n",
      " \n",
      "This figure shows examples of word-as-image illustrations in various fonts and for different textual concepts. These semantically adjusted letters are created automatically using a method, and can then be used for creative design. Word-as-image is a typography technique where a word is illustrated.\n",
      "\n",
      " This paper presents a technique to automatically generate visual illustrations of words that both capture the semantic meaning of the word and are still legible. This task requires understanding of the word's meaning as well as creativity in depicting the meaning visually.\n",
      "\n",
      " This paper discusses the ability of large language-vision models to translate textual concepts to visual designs. The designs are kept simple with black-and-white colors, and the outlines of each letter are optimized to convey the desired concept.\n",
      "\n",
      " This paper presents a pretrained Stable Diffusion model with additional loss terms to ensure legible text and preserve the font style. High quality and engaging results are demonstrated through numerous examples and compared to alternative techniques. Code for the model is available on the project page.\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "' \\nThis paper examines semantic typography, a technique where words are used as images. It explores how this technique can be used to create meaningful, visually-appealing typography. A model is proposed that uses language-vision models to automatically generate visuals of words, with the outlines of each letter optimized to convey the desired concept. Examples and comparisons to alternative techniques are provided.'"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(lg_docs[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b99505",
   "metadata": {},
   "source": [
    "### Summarize: Refine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "49b2dbfe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T08:45:33.769479400Z",
     "start_time": "2023-10-09T08:45:33.762494500Z"
    }
   },
   "outputs": [],
   "source": [
    "chain = load_summarize_chain(llm, chain_type=\"refine\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "efadaf1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T08:45:59.058706900Z",
     "start_time": "2023-10-09T08:45:33.765489500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new RefineDocumentsChain chain...\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"Word-As-Image for Semantic Typography\n",
      "Shir Iluz∗\n",
      "Tel-Aviv University, IsraelYael Vinker∗\n",
      "Tel-Aviv University, IsraelAmir Hertz\n",
      "Tel-Aviv University, Israel\n",
      "Daniel Berio\n",
      "Goldsmiths University, LondonDaniel Cohen-Or\n",
      "Tel-Aviv University, IsraelAriel Shamir\n",
      "Reichman University, Israel\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mYour job is to produce a final summary\n",
      "We have provided an existing summary up to a certain point:  This paper discusses a research project on the concept of semantic typography, in which words are used as images. The research was conducted by a team of experts from Tel-Aviv University, Reichman University, and Goldsmiths University in London.\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "Fig. 1. A few examples of our word-as-image illustrations in various fonts and for different textual concept. The semantically adjusted letters are created\n",
      "completely automatically using our method, and can then be used for further creative design as we illustrate here.\n",
      "A word-as-image is a semantic typography technique where a word illus-\n",
      "------------\n",
      "Given the new context, refine the original summaryIf the context isn't useful, return the original summary.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mYour job is to produce a final summary\n",
      "We have provided an existing summary up to a certain point: \n",
      "This paper discusses a research project on the concept of semantic typography, in which words are used as images. The research was conducted by a team of experts from Tel-Aviv University, Reichman University, and Goldsmiths University in London. The technique involves creating semantically adjusted letters which are used to illustrate various textual concepts, as illustrated in Fig. 1. These letters can then be used for further creative design.\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "tration presents a visualization of the meaning of the word, while also\n",
      "preserving its readability. We present a method to create word-as-image\n",
      "illustrations automatically. This task is highly challenging as it requires\n",
      "semantic understanding of the word and a creative idea of where and how to\n",
      "depict these semantics in a visually pleasing and legible manner. We rely on\n",
      "------------\n",
      "Given the new context, refine the original summaryIf the context isn't useful, return the original summary.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mYour job is to produce a final summary\n",
      "We have provided an existing summary up to a certain point: \n",
      "This paper discusses a research project on the concept of semantic typography, in which words are used as images. The research was conducted by a team of experts from Tel-Aviv University, Reichman University, and Goldsmiths University in London. The technique involves creating semantically adjusted letters which are used to illustrate various textual concepts, as illustrated in Fig. 1. These letters can then be used for further creative design. The illustration presents a visualization of the meaning of the word, while also preserving its readability. The paper presents a method to create word-as-image illustrations automatically, as this task is highly challenging as it requires semantic understanding of the word and a creative idea of where and how to depict these semantics in a visually pleasing and legible manner.\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "the remarkable ability of recent large pretrained language-vision models to\n",
      "distill textual concepts visually. We target simple, concise, black-and-white\n",
      "designs that convey the semantics clearly. We deliberately do not change the\n",
      "color or texture of the letters and do not use embellishments. Our method\n",
      "optimizes the outline of each letter to convey the desired concept, guided by\n",
      "------------\n",
      "Given the new context, refine the original summaryIf the context isn't useful, return the original summary.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mYour job is to produce a final summary\n",
      "We have provided an existing summary up to a certain point: \n",
      "This paper discusses a research project on the concept of semantic typography, in which words are used as images. The research was conducted by a team of experts from Tel-Aviv University, Reichman University, and Goldsmiths University in London. The technique involves creating semantically adjusted letters which are used to illustrate various textual concepts, as illustrated in Fig. 1. These letters can then be used for further creative design. The illustration presents a visualization of the meaning of the word, while also preserving its readability. The paper presents a method to create word-as-image illustrations automatically, as this task is highly challenging as it requires semantic understanding of the word and a creative idea of where and how to depict these semantics in a visually pleasing and legible manner. This method utilizes the remarkable ability of recent large pretrained language-vision models to distill textual concepts visually. The research team targets simple, concise, black-and-white designs that convey the semantics clearly, and deliberately avoids changing the color or texture of the letters or using embellishments. The method optimizes the outline of each letter to convey the desired concept, guided by large language-vision models.\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "a pretrained Stable Diffusion model. We incorporate additional loss terms\n",
      "to ensure the legibility of the text and the preservation of the style of the\n",
      "font. We show high quality and engaging results on numerous examples\n",
      "and compare to alternative techniques.\n",
      "Code will be available at our project page.\n",
      "1 INTRODUCTION\n",
      "Semantic typography is the practice of using typography to visually\n",
      "------------\n",
      "Given the new context, refine the original summaryIf the context isn't useful, return the original summary.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\\nThis paper discusses a research project on the concept of semantic typography, in which words are used as images. The research was conducted by a team of experts from Tel-Aviv University, Reichman University, and Goldsmiths University in London. The technique involves creating semantically adjusted letters which are used to illustrate various textual concepts, as illustrated in Fig. 1. These letters can then be used for further creative design. The illustration presents a visualization of the meaning of the word, while also preserving its readability. The paper presents a method to create word-as-image illustrations automatically, as this task is highly challenging as it requires semantic understanding of the word and a creative idea of where and how to depict these semantics in a visually pleasing and legible manner. This method utilizes the remarkable ability of recent large pretrained language-vision models, such as a pretrained Stable Diffusion model, to distill textual concepts visually. The research team targets simple, concise, black-and-white designs that convey the semantics clearly, and deliberately avoids changing the color or texture of the letters or using embellishments. The method optimizes the outline of each letter to convey the desired concept, guided by large language-vision models, and incorporates additional loss terms to ensure'"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(lg_docs[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6962c2",
   "metadata": {},
   "source": [
    "### Q&A: Map Re-Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ba864773",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T08:45:59.066069100Z",
     "start_time": "2023-10-09T08:45:59.060575Z"
    }
   },
   "outputs": [],
   "source": [
    "chain = load_qa_chain(llm, chain_type=\"map_rerank\", verbose=True, return_intermediate_steps=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4ac90ccc34c0c87f"
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new MapRerankDocumentsChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Word-As-Image for Semantic Typography\n",
      "Shir Iluz∗\n",
      "Tel-Aviv University, IsraelYael Vinker∗\n",
      "Tel-Aviv University, IsraelAmir Hertz\n",
      "Tel-Aviv University, Israel\n",
      "Daniel Berio\n",
      "Goldsmiths University, LondonDaniel Cohen-Or\n",
      "Tel-Aviv University, IsraelAriel Shamir\n",
      "Reichman University, Israel\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Fig. 1. A few examples of our word-as-image illustrations in various fonts and for different textual concept. The semantically adjusted letters are created\n",
      "completely automatically using our method, and can then be used for further creative design as we illustrate here.\n",
      "A word-as-image is a semantic typography technique where a word illus-\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "tration presents a visualization of the meaning of the word, while also\n",
      "preserving its readability. We present a method to create word-as-image\n",
      "illustrations automatically. This task is highly challenging as it requires\n",
      "semantic understanding of the word and a creative idea of where and how to\n",
      "depict these semantics in a visually pleasing and legible manner. We rely on\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "the remarkable ability of recent large pretrained language-vision models to\n",
      "distill textual concepts visually. We target simple, concise, black-and-white\n",
      "designs that convey the semantics clearly. We deliberately do not change the\n",
      "color or texture of the letters and do not use embellishments. Our method\n",
      "optimizes the outline of each letter to convey the desired concept, guided by\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "a pretrained Stable Diffusion model. We incorporate additional loss terms\n",
      "to ensure the legibility of the text and the preservation of the style of the\n",
      "font. We show high quality and engaging results on numerous examples\n",
      "and compare to alternative techniques.\n",
      "Code will be available at our project page.\n",
      "1 INTRODUCTION\n",
      "Semantic typography is the practice of using typography to visually\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "reinforce the meaning of text. This can be achieved through the\n",
      "choice of typefaces, font sizes, font styles, and other typographic\n",
      "elements. A more elaborate and engaging technique for semantic\n",
      "typography is presented by word-as-image illustrations, where the\n",
      "semantics of a given word are illustrated using only the graphical\n",
      "elements of its letters. Such illustrations provide a visual repre-\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "sentation of the meaning of the word, while also preserving the\n",
      "readability of the word as a whole.\n",
      "The task of creating a word-as-image is highly challenging, as it\n",
      "requires the ability to understand and depict the visual characteris-\n",
      "tics of the given concept, and to convey them in a concise, aesthetic,\n",
      "and comprehensible manner without harming legibility. It requires\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "∗Denotes equal contribution.a great deal of creativity and design skills to integrate the chosen\n",
      "visual concept into the letter’s shape [Lee 2011]. In Figure 2 we show\n",
      "some word-as-image examples created manually. For example, to\n",
      "create the “jazz” depiction, the designer had to first choose the visual\n",
      "concept that would best fit the semantics of the text (a saxophone),\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "consider the desired font characteristics, and then choose the most\n",
      "suitable letter to be replaced. Finding the right visual element to\n",
      "illustrate a concept is ill-defined as there are countless ways to il-\n",
      "lustrate any given concept. In addition, one cannot simply copy a\n",
      "selected visual element onto the word – there is a need to find subtle\n",
      "modifications of the letters shape.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Because of these complexities, the task of automatic creation of\n",
      "word-as-image illustrations was practically impossible to achieve\n",
      "using computers until recently. In this paper, we define an algo-\n",
      "rithm for automatic creation of word-as-image illustrations based\n",
      "on recent advances in deep-learning and the availability of huge\n",
      "foundational models that combine language and visual understand-\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "ing. Our resulting illustrations (see Figure 1) could be used for logo\n",
      "design, for signs, in greeting cards and invitations, and simply for\n",
      "fun. They can be used as-is, or as inspiration for further refinement\n",
      "of the design.\n",
      "Existing methods in the field of text stylization often rely on raster\n",
      "textures [Yang et al .2018], place a manually created style on top\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "of the strokes segmentation [Berio et al .2022], or deform the text\n",
      "into a pre-defined target shape [Zou et al .2016] (see Figure 3). Only\n",
      "a few works [Tendulkar et al .2019; Zhang et al .2017] deal with\n",
      "semantic typography, and they often operate in the raster domain\n",
      "and use existing icons for replacement (see Figure 3E).\n",
      "Our word-as-image illustrations concentrate on changing only\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "thegeometry of the letters to convey the meaning. We deliberately\n",
      "do not change color or texture and do not use embellishments. ThisarXiv:2303.01818v2  [cs.CV]  6 Mar 2023\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "2•Shir Iluz, Yael Vinker, Amir Hertz, Daniel Berio, Daniel Cohen-Or, and Ariel Shamir\n",
      "Fig. 2. Manually created word-as-image illustrations.\n",
      "allows simple, concise, black-and-white designs that convey the\n",
      "semantics clearly. In addition, since we preserve the vector-based\n",
      "representation of the letters, this allows smooth rasterization in\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "any size, as well as applying additional style manipulations to the\n",
      "illustration using colors and texture, if desired.\n",
      "Given an input word, our method is applied separately for each\n",
      "letter, allowing the user to later choose the most likeable combina-\n",
      "tion for replacement. We represent each letter as a closed vectorized\n",
      "shape, and optimize its parameters to reflect the meaning of the\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "word, while still preserving its original style and design.\n",
      "We rely on the prior of a pretrained Stable Diffusion model [Rom-\n",
      "bach et al .2021] to connect between text and images, and utilize\n",
      "the Score Distillation Sampling approach [Poole et al .2022] (see\n",
      "Section 3) to encourage the appearance of the letter to reflect the\n",
      "provided textual concept. Since the Stable Diffusion model is trained\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "on raster images, we use a differentiable rasterizer [Li et al .2020]\n",
      "that allows to backpropagate gradients from a raster-based loss to\n",
      "the shape’s parameters.\n",
      "To preserve the shape of the original letter and ensure legibility\n",
      "of the word, we utilize two additional loss functions. The first loss\n",
      "regulates the shape modification by constraining the deformation\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "to be as-conformal-as-possible over a triangulation of the letter’s\n",
      "shape. The second loss preserves the local tone and structure of the\n",
      "letter by comparing the low-pass filter of the resulting rasterized\n",
      "letter to the original one.\n",
      "We compare to several baselines, and present many results using\n",
      "various typefaces and a large number of concepts. Our word-as-\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "image illustrations convey the intended concept while maintaining\n",
      "legibility and preserving the appearance of the font, demonstrating\n",
      "visual creativity.\n",
      "2 RELATED WORK\n",
      "Text Stylization. One approach to text stylization is artistic text\n",
      "style transfer, where the style from a given source image is migrated\n",
      "into the desired text (such as in Figure 3A). To tackle this task,\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "existing works incorporate patch-based texture synthesis [Fish et al .\n",
      "2020; Yang et al .2017] as well as variants of GANs [Azadi et al .\n",
      "2018; Jiang et al .2019; Mao et al .2022; Wang et al .2019; Yang et al .\n",
      "2022]. These works operate within the raster domain, a format that\n",
      "is undesirable for typographers since fonts must be scalable. In\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "contrast, we operate on the parametric outlines of the letters, and\n",
      "our glyph manipulation is guided by the semantic meaning of the\n",
      "word, rather than a pre-defined style image.\n",
      "A number of works [Ha and Eck 2018; Lopes et al .2019; Wang\n",
      "and Lian 2021] tackle the task of font generation and stylization\n",
      "in the vector domain. Commonly, a latent feature space of font’s\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "outlines is constructed, represented as outline samples [Balashova\n",
      "et al.2019; Campbell and Kautz 2014] or parametric curve segments\n",
      "[Ha and Eck 2018; Lopes et al .2019; Wang and Lian 2021]. These\n",
      "Fig. 3. Examples of previous text stylization works – (A) Yang et al. [2018],\n",
      "(B) Berio et al. [2022], (C) Zhang et al. [2017], (D) Zou et al. [2016], and (E)\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Tendulkar et al. [2019]. Most use color and texture or copy icons onto the\n",
      "letters. Our work concentrates on subtle geometric shape deformations of\n",
      "the letters to convey the semantic meaning without color or texture (that\n",
      "can be added later).\n",
      "approaches are often limited to mild deviations from the input data.\n",
      "Other methods rely on templates [Lian et al .2018; Suveeranont and\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Igarashi 2010] or on user guided [Phan et al .2015] and automatic\n",
      "[Berio et al .2022] stroke segmentation to produce letter stylization\n",
      "(such as in Figure 3B). However, they rely on a manually defined\n",
      "style, while we rely on the expressiveness of Stable Diffusion to\n",
      "guide the modification of the letters’ shape, to convey the meaning\n",
      "of the provided word. In the task of calligram generation [Xu and\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Kaplan 2007; Zou et al .2016] the entire word is deformed into a\n",
      "given target shape. This task prioritises shape over the readability\n",
      "of the word (see Figure 3D), and is inherently different from ours,\n",
      "as we use the semantics of the word to derive the deformation of\n",
      "individual letters.\n",
      "Most related to our goal, are works that perform semantic styl-\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "ization of text. Tendulkar et al .[2019] replace letters in a given\n",
      "word with clip-art icons describing a given theme (see Figure 3E).\n",
      "To choose the most suitable icon for replacement, an autoencoder\n",
      "is used to measure the distance between the letter and icons from\n",
      "the desired class. Similarly, Zhang et al .[2017] replace stroke-like\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "parts of one or more letters with instances of clip art to generate\n",
      "ornamental stylizations. An example is shown in Figure 3C. These\n",
      "approaches operate in the raster domain, and replace letters with\n",
      "existing icons, which limits them to a predefined set of classes\n",
      "present in the dataset. Our method, however, operates in the vector\n",
      "domain, and incorporates the expressiveness of large pretrained\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "image-language models to create a new illustration that conveys\n",
      "the desired concept.\n",
      "Large Language-Vision Models. With the recent advancement of\n",
      "language-vision models [Radford et al .2021] and diffusion mod-\n",
      "els [Nichol et al .2021; Ramesh et al .2022; Rombach et al .2021], the\n",
      "field of image generation and editing has undergone unprecedented\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "evolution. Having been trained on millions of images and text pairs,\n",
      "these models have proven effective for performing challenging vi-\n",
      "sion related tasks such as image segmentation [Amit et al .2021],\n",
      "domain adaptation [Song et al .2022], image editing [Avrahami et al .\n",
      "2022; Hertz et al .2022; Tumanyan et al .2022a], personalization [Gal\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Word-As-Image for Semantic Typography •3\n",
      "Fig. 4. More word-as-images produced by our method. Note how styles of\n",
      "different fonts are preserved by the semantic modification.\n",
      "et al.2022, 2023; Ruiz et al .2022], and explainability [Chefer et al .\n",
      "2021]. Despite being trained on raster images, their strong visual\n",
      "and semantic priors have also been shown to be successfully applied\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "to other domains, such as motion [Tevet et al .2022], meshes [Michel\n",
      "et al.2021], point cloud [Zhang et al .2021], and vector graphics.\n",
      "CLIPDraw [Frans et al .2021] uses a differentiable rasterizer [Li\n",
      "et al.2020] to optimize a set of colorful curves w.r.t. a given text\n",
      "prompt, guided by CLIP’s image-text similarity metric. Tian and Ha\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "[2021] use evolutionary algorithms combined with CLIP guidance to\n",
      "create abstract visual concepts based on text. Other works [Vinker\n",
      "et al.2022a,b] utilize the image encoder of CLIP to generate abstract\n",
      "vector sketches from images.\n",
      "Diffusion models have been used for the task of text guided image-\n",
      "to-image translation [Choi et al .2021; Tumanyan et al .2022b]. In\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "SDEdit [Meng et al .2022], an adequate amount of noise is added\n",
      "to a reference image, such that its overall structure is preserved,\n",
      "and then the image is denoised in a reverse process with a guiding\n",
      "text. Pretrained diffusion models have also been used to generate\n",
      "3D objects [Metzer et al .2022; Poole et al .2022], or vector art [Jain\n",
      "et al. 2022] conditioned on text.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "In our work we also utilize the strong visual and semantic prior\n",
      "induced by a pretrained Stable Diffusion model [Rombach et al .\n",
      "2021], however, for the task of semantic typography . For that purpose\n",
      "we add new components to the optimization process to preserve\n",
      "the font’s style and text legibility.\n",
      "3 BACKGROUND\n",
      "3.1 Fonts and Vector Representation\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Modern typeface formats such as TrueType [Penney 1996] and\n",
      "PostScript [Inc. 1990] represent glyphs using a vectorized graphic\n",
      "representation of their outlines. Specifically, the outline contours are\n",
      "typically represented by a collection of lines and Bézier or B-Spline\n",
      "curves. This representation allows to scale the letters and rasterize\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "them in any desired size similar to other vector representations.\n",
      "This property is preserved by our method as our output preserves\n",
      "the vectorized representations of the letters.3.2 Latent Diffusion Models\n",
      "Diffusion models are generative models that are trained to learn\n",
      "a data distribution by the gradual denoising of a variable sampled\n",
      "from a Gaussian distribution.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "In our work, we use the publicly available text-to-image Stable\n",
      "Diffusion model [Rombach et al .2021]. Stable Diffusion is a type of\n",
      "a latent diffusion model (LDM), where the diffusion process is done\n",
      "over the latent space of a pretrained image autoencoder. The encoder\n",
      "Eis tasked with mapping an input image 𝑥into a latent vector 𝑧,\n",
      "and the decoderDis trained to decode 𝑧such thatD(𝑧)≈𝑥.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "As a second stage, a denoising diffusion probabilistic model (DDPM)\n",
      "[Ho et al .2020] is trained to generate codes within the learned latent\n",
      "space. At each step during training, a scalar 𝑡∈{1,2,...𝑇}is uni-\n",
      "formly sampled and used to define a noised latent code 𝑧𝑡=𝛼𝑡𝑧+𝜎𝑡𝜖,\n",
      "where𝜖∼N( 0,𝐼)and𝛼𝑡,𝜎𝑡are terms that control the noise sched-\n",
      "ule, and are functions of the diffusion process time 𝑡.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "The denoising network 𝜖𝜃which is based on a UNet architecture\n",
      "[Ronneberger et al .2015], receives as input the noised code 𝑧𝑡, the\n",
      "timestep𝑡and an optional condition vector 𝑐(𝑦), and is tasked with\n",
      "predicting the added noise 𝜖. The LDM loss is defined by:\n",
      "L𝐿𝐷𝑀=E𝑧∼E(𝑥),𝑦,𝜖∼N( 0,1),𝑡\u0002\n",
      "||𝜖−𝜖𝜃(𝑧𝑡,𝑡,𝑐(𝑦))||2\n",
      "2\u0003\n",
      ".(1)\n",
      "In Stable Diffusion, for text-to-image generation, the condition\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "vector is the text embedding produced by a pre-trained CLIP text\n",
      "encoder [Radford et al .2021]. At inference time, a random latent\n",
      "code𝑧𝑇∼N( 0,𝐼)is sampled, and iteratively denoised by the trained\n",
      "𝜖𝜃until producing a clean 𝑧0latent code, which is passed through\n",
      "the decoder 𝐷to produce the image 𝑥.\n",
      "3.3 Score Distillation\n",
      "It is desirable to utilize the strong prior of pretrained large text-\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "image models for the generation of modalities beyond rasterized\n",
      "images. In Stable Diffusion, text conditioning is performed via the\n",
      "cross-attention layers defined at different resolutions in the UNet\n",
      "network. Thus, it is not trivial to guide an optimization process\n",
      "using the conditioned diffusion model.\n",
      "DreamFusion [Poole et al .2022] proposed a way to use the diffu-\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "sion loss to optimize the parameters of a NeRF model for text-to-3D\n",
      "generation. At each iteration, the radiance field is rendered from a\n",
      "random angle, forming the image 𝑥, which is then noised to form\n",
      "𝑥𝑡=𝛼𝑡𝑥+𝜎𝑡𝜖. The noised image is then passed to the pretrained\n",
      "UNet model of Imagen [Saharia et al .2022], that outputs the pre-\n",
      "diction of the noise 𝜖. The score distillation loss is defined by the\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "gradients of the original diffusion loss:\n",
      "∇𝜙L𝑆𝐷𝑆=\u0014\n",
      "𝑤(𝑡)(𝜖𝜃(𝑥𝑡,𝑡,𝑦)−𝜖)𝜕𝑥\n",
      "𝜕𝜙\u0015\n",
      "(2)\n",
      "where𝑦is the condition text prompt, 𝜙are the NeRF’s parameters\n",
      "and𝑤(𝑡)is a constant multiplier that depends on 𝛼𝑡. During train-\n",
      "ing, the gradients are back-propagated to the NeRF parameters to\n",
      "gradually change the 3D object to fit the text prompt. Note that the\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "gradients of the UNet are skipped, and the gradients to modify the\n",
      "Nerf’s parameters are derived directly from the LDM loss.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "4•Shir Iluz, Yael Vinker, Amir Hertz, Daniel Berio, Daniel Cohen-Or, and Ariel Shamir\n",
      "zt~[50,950]z!“Surfing * “\n",
      "CLIPAugment..Encoder\n",
      "zUNet\n",
      "DiffVG𝑝!𝑝\"𝑝#!𝑝!𝑝\"𝑝#!\n",
      "LPF\n",
      "LPF\n",
      "13\n",
      "2\n",
      "𝑃=𝑃\"=\n",
      "𝑙!𝑙!$\n",
      "𝒟\n",
      "𝒟\n",
      "Fig. 5. An overview of our method. Given an input letter 𝑙𝑖represented by a set of control points 𝑃, and a concept (shown in purple), we optimize the new\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "positions ˆ𝑃of the deformed letter ˆ𝑙𝑖iteratively. At each iteration, the set ˆ𝑃is fed into a differentiable rasterizer (DiffVG marked in blue) that outputs the\n",
      "rasterized deformed letter ˆ𝑙𝑖.ˆ𝑙𝑖is then augmented and passed into a pretrained frozen Stable Diffusion model, that drives the letter shape to convey the\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "semantic concept using the ∇ˆ𝑃LLSDS loss (1).𝑙𝑖and ˆ𝑙𝑖are also passed through a low pass filter (LPF marked in yellow) to compute L𝑡𝑜𝑛𝑒 (2) which encourages\n",
      "the preservation of the overall tone of the font style and also the local letter shape. Additionally, the sets 𝑃and ˆ𝑃are passed through a Delaunay triangulation\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "operator (Dmarked in green), defining L𝑎𝑐𝑎𝑝 (3) which encourages the preservation of the initial shape.\n",
      "3.4 VectorFusion\n",
      "Recently, VectorFusion [Jain et al .2022] utilized the SDS loss for the\n",
      "task of text-to-SVG generation. The proposed generation pipeline\n",
      "involves two stages. Given a text prompt, first, an image is generated\n",
      "using Stable Diffusion (with an added suffix to the prompt), and\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "is then vectorized automatically using LIVE [Ma et al .2022]. This\n",
      "defines an initial set of parameters to be optimized in the second\n",
      "stage using the SDS loss. At each iteration, a differentiable rasterizer\n",
      "[Li et al. 2020] is used to produce a 600×600image, which is then\n",
      "augmented as suggested in CLIPDraw [Frans et al .2021] to get a\n",
      "512×512image𝑥𝑎𝑢𝑔. Then𝑥𝑎𝑢𝑔is fed into the pretrained encoder\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Eof Stable Diffusion to produce the corresponding latent code\n",
      "𝑧=E(𝑥𝑎𝑢𝑔). The SDS loss is then applied in this latent space, in a\n",
      "similar way to the one defined in DreamFusion:\n",
      "∇𝜃LLSDS=E𝑡,𝜖\u0014\n",
      "𝑤(𝑡)\u0010\n",
      "ˆ𝜖𝜙(𝛼𝑡𝑧𝑡+𝜎𝑡𝜖,𝑦)−𝜖\u0011𝜕𝑧\n",
      "𝜕𝑧𝑎𝑢𝑔𝜕𝑥𝑎𝑢𝑔\n",
      "𝜕𝜃\u0015\n",
      "(3)\n",
      "We find the SDS approach useful for our task of producing se-\n",
      "mantic glyphs, and we follow the technical steps proposed in Vec-\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "torFusion (e.g. augmentations and the added suffix).\n",
      "4 METHOD\n",
      "Given a word 𝑊represented as a string with 𝑛letters{𝑙1,...𝑙𝑛}, our\n",
      "method is applied to every letter 𝑙𝑖separately to produce a semantic\n",
      "visual depiction of the letter. The user can then choose which letters\n",
      "to replace and which to keep in their original form.\n",
      "4.1 Letter Representation\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "We begin by defining the parametric representation of the letters\n",
      "in𝑊. We use the FreeType font library [FreeType 2009] to extract\n",
      "the outline of each letter. We then translate each outline into a set\n",
      "of cubic Bézier curves, to have a consistent representation across\n",
      "different fonts and letters, and to facilitate the use of diffvg [Li et al .\n",
      "2020] for differentiable rasterization.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Fig. 6. Illustration of the letter’s outline and control points before (left) and\n",
      "after (right) the subdivision process. The orange dots are the initial Bézier\n",
      "curve segment endpoints. The blue dots are the remaining control points\n",
      "respectively before and after subdivision.\n",
      "Depending on the letter’s complexity and the style of the font,\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "the extracted outlines are defined by a different number of control\n",
      "points. We have found that the initial number of control points\n",
      "affects the final appearance significantly: as the number of control\n",
      "points increases, there is more freedom for visual changes to occur.\n",
      "Therefore, we additionally apply a subdivision procedure to letters\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "containing a small number of control points. We define a desired\n",
      "number of control points for each letter of the alphabet (shared\n",
      "across different fonts), and then iteratively subdivide the Bézier\n",
      "segments until reaching this target number. At each iteration, we\n",
      "compute the maximum arc length among all Bézier segments and\n",
      "split each segment with this length into two (see Figure 6). We\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "analyse the effect of the number of control points in Section 5.3.\n",
      "This procedure defines a set of 𝑘𝑖control points 𝑃𝑖={𝑝𝑗}𝑘𝑖\n",
      "𝑗=1\n",
      "representing the shape of the letter 𝑙𝑖.\n",
      "4.2 Optimization\n",
      "The pipeline of our method is provided in Figure 5. Since we are\n",
      "optimizing each letter 𝑙𝑖separately, for brevity, we will omit the\n",
      "letter index𝑖in the following text and define the set of control points\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "for the input letter as 𝑃.\n",
      "Given𝑃and the desired textual concept 𝑐(both marked in purple\n",
      "in Figure 5), our goal is to produce a new set of control points, ˆ𝑃,\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Word-As-Image for Semantic Typography •5\n",
      "Fig. 7. Visual illustration of the constraint Delaunay triangulation applied\n",
      "to the initial shapes (left) and the resulting ones (right), for the word “pants”.\n",
      "The ACAP loss maintains the structure of the letter after the deformation.\n",
      "The zoomed rectangle shows the angles for a given control point 𝑝𝑗.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "defining an adjusted letter ˆ𝑙that conveys the given concept, while\n",
      "maintaining the overall structure and characteristics of the initial\n",
      "letter𝑙.\n",
      "We initialize the learned set of control points ˆ𝑃with𝑃, and pass\n",
      "it through a differentiable rasterizer R[Li et al .2020] (marked in\n",
      "blue), which outputs the rasterized letter R(ˆ𝑃). The rasterized letter\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "is then randomly augmented and passed into a pretrained Stable\n",
      "Diffusion [Rombach et al .2021] model, conditioned on the CLIP’s\n",
      "embedding of the given text 𝑐. The SDS loss∇ˆ𝑃LLSDS is then used\n",
      "as described in Section 3 to encourage R(ˆ𝑃)to convey the given\n",
      "text prompt.\n",
      "To preserve the shape of each individual letter and ensure the\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "legibility of the word as a whole, we use two additional loss functions\n",
      "to guide the optimization process. The first loss limits the overall\n",
      "shape change by defining as-conformal-as-possible constraint on\n",
      "the shape deformation. The second loss preserves the overall shape\n",
      "and style of the font by constraining the tone (i.e. amount of dark\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "vs. light areas in local parts of the shape) of the modified letter not\n",
      "to diverge too much from the original letter (see Section 4.3).\n",
      "The gradients obtained from all the losses are then backpropa-\n",
      "gated, to update the parameters ˆ𝑃. We repeat this process for 500\n",
      "steps, which takes∼5minutes to produce a single letter illustration\n",
      "on RTX2080 GPU.\n",
      "4.3 Loss Functions\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Our primary objective of encouraging the resulting shape to con-\n",
      "vey the intended semantic concept, is utilized by ∇ˆ𝑃LLSDS loss\n",
      "(described in Section 3). We observe that using ∇ˆ𝑃LLSDS solely can\n",
      "cause large deviations from the initial letter appearance, which is\n",
      "undesired. Hence, our additional goal is to maintain the shape and\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "legibility of the letter R(ˆ𝑃), as well as to keep the original font’s\n",
      "characteristics. For that purpose we use two additional losses.\n",
      "As-Conformal-As-Possible Deformation Loss. To prevent the final\n",
      "letter shape from diverging too much from the initial shape, we\n",
      "triangulate the inner part of the letter and constrain the deformation\n",
      "of the letter to be as conformal as possible (ACAP) [Hormann and\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Greiner 2000]. We use constrained Delaunay triangulation [Barber\n",
      "and Huhdanpaa 1995; Delaunay et al .1934] on the set of control\n",
      "points defining the glyph. It is known that Delaunay triangulation\n",
      "can be used to produce the skeleton of an outline [Prasad 1997; Zou\n",
      "et al.2001], so the ACAP loss also implicitly captures a skeletal\n",
      "representation of the letter form.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Fig. 8. Our tone-preserving loss preserves the local tone of the font by\n",
      "comparing the low-pass filter of the letters images before (left) and after\n",
      "deformation (right). It constrains the adjusted letter not to deviate too much\n",
      "from the original. This example is of the letter B and the word “Bear”.\n",
      "The Delaunay triangulation D(𝑃)splits the glyph represented by\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "𝑃into a set of triangles. This defines a set of size 𝑚𝑗of corresponding\n",
      "angles for each control point 𝑝𝑗(see Figure 7). We denote this set of\n",
      "angles as{𝛼𝑖\n",
      "𝑗}𝑚𝑗\n",
      "𝑖=1. The ACAP loss encourages the induced angles\n",
      "of the optimized shape ˆ𝑃not to deviate much from the angles of\n",
      "the original shape 𝑃, and is defined as the L2 distance between the\n",
      "corresponding angles:\n",
      "L𝑎𝑐𝑎𝑝(𝑃,ˆ𝑃)=1\n",
      "𝑘𝑘∑︁\n",
      "𝑗=1 𝑚𝑗∑︁\n",
      "𝑖=1\u0000𝛼𝑖\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "𝑗−ˆ𝛼𝑖\n",
      "𝑗\u00012!\n",
      "(4)\n",
      "where𝑘=|𝑃|and ˆ𝛼are the angles induced by D(ˆ𝑃).\n",
      "Tone Preservation Loss. To preserve the style of the font as well\n",
      "as the structure of the letter we add a local-tone preservation loss\n",
      "term. This term constrains the tone (amount of black vs. white in\n",
      "all regions of the shape) of the adjusted letter not to deviate too\n",
      "much from tone of the original font’s letter. Towards this end, we\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "apply a low pass filter (LPF) to the rasterized letter (before and after\n",
      "deformation) and compute the L2 distance between the resulting\n",
      "blurred letters:\n",
      "2?𝑃𝐹(R(𝑃))−𝐿𝑃𝐹(R(ˆ𝑃))\n",
      "2(5)\n",
      "An example of the blurred letters is shown in Figure 8, as can be\n",
      "seen, we use a high value of standard deviation 𝜎in the blurring\n",
      "kernel to blur out small details such as the ears of bear.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Our final objective is then defined by the weighted average of the\n",
      "three terms:\n",
      "min\n",
      "ˆ𝑃∇ˆ𝑃LLSDS(R(ˆ𝑃),𝑐)+𝛼·L𝑎𝑐𝑎𝑝(𝑃,ˆ𝑃)\n",
      "+𝛽𝑡·L𝑡𝑜𝑛𝑒(R(𝑃),R(ˆ𝑃))(6)\n",
      "where𝛼=0.5and𝛽𝑡depends on the step 𝑡as described next.\n",
      "4.4 Weighting\n",
      "Choosing the relative weights of the three losses presented above\n",
      "is crucial to the appearance of the final letter. While the ∇ˆ𝑃LLSDS\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "loss encourages the shape to deviate from its original appearance to\n",
      "better fit the semantic concept, the two terms L𝑡𝑜𝑛𝑒 andL𝑎𝑐𝑎𝑝 are\n",
      "responsible for maintaining the original shape. Hence, we have two\n",
      "competing parts in the formula, and would like to find a balance\n",
      "between them to maintain the legibility of the letter while allowing\n",
      "the desired semantic shape to change.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "We find thatL𝑡𝑜𝑛𝑒 can be very dominant. In some cases, if it is\n",
      "used from the beginning, no semantic deformation is performed.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "6•Shir Iluz, Yael Vinker, Amir Hertz, Daniel Berio, Daniel Cohen-Or, and Ariel Shamir\n",
      "Fig. 9. Word-as-images produced by our method for the word “YOGA”,\n",
      "using eight different fonts.\n",
      "Therefore, we adjust the weight of L𝑡𝑜𝑛𝑒 to kick-in only after some\n",
      "semantic deformation has occurred. We define 𝛽𝑡as follows:\n",
      "𝛽𝑡=𝑎·exp\u0000−(𝑡−𝑏)2\n",
      "2𝑐2\u0001(7)\n",
      "with𝑎=100,𝑏=300,𝑐=30. We analyse the affect of various\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "weighting in Section 5.3. Note that the same hyper-parameter choice\n",
      "works for various words, letters, and fonts.\n",
      "5 RESULTS\n",
      "The robustness of our approach means it should be capable of han-\n",
      "dling a wide range of input concepts as well as supporting different\n",
      "font designs. Figures 1, 4, 33, 17, and more results in the supplemen-\n",
      "tal file demonstrate that our approach can handle inputs from many\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "different categories and various fonts, and that the generated results\n",
      "are legible and creative. Figure 9 demonstrate how the illustrations\n",
      "created by our method for the same word follow the characteristics\n",
      "of different fonts. Although the perceived aesthetics of a word-as-\n",
      "image illustration can be subjective, we define three objectives for\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "an effective result: (1) it should visually capture the given semantic\n",
      "concept, (2) it should maintain readability, and (3) it should preserve\n",
      "the original font’s characteristics.\n",
      "We evaluate the performance of our method on a randomly se-\n",
      "lected set of inputs. We select five common concept classes - animals,\n",
      "fruits, plants, sports, and professions. Using ChatGPT, we sample ten\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "random instances for each class, resulting in 50 words in total. Next,\n",
      "we select four fonts that have distinct visual characteristics, namely\n",
      "Quicksand, Bell MT, Noteworthy-Bold, and HobeauxRococeaux-\n",
      "Sherman. For each word, we randomly sampled one of the four\n",
      "fonts, and applied our method to each letter. For each word with\n",
      "𝑛letters we can generate 2𝑛possible word-as-images, which are\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "all possible combinations of replacements of illustrated letters. A\n",
      "selected subset of these results is presented in Figure 33. The results\n",
      "of all letters and words are presented in the supplementary material.\n",
      "As can be seen, the resulting word-as-image illustrations success-\n",
      "fully convey the given semantic concept in most cases while still\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "remaining legible. In addition, our method successfully captures\n",
      "the font characteristics. For example, in Figure 33, the replacementsTable 1. Perceptual study results. The level of concept recognizability and\n",
      "letter legibility are very high, and style matching of the font is well above\n",
      "random. The “Only SDS” results are created by removing our structure and\n",
      "style preserving losses.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Method Semantics Legibility Font\n",
      "Ours 0.8 0.9 0.51\n",
      "Only SDS 0.88 0.53 0.33\n",
      "for the “DRESS” and “LION” are thin and fit well with the rest of\n",
      "the word. In addition, observe the serifs of the letter A used for the\n",
      "fin of the shark in the “SHARK” example. We further use human\n",
      "evaluation to validate this as described below.\n",
      "5.1 Quantitative\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "We conduct a perceptual study to quantitatively assess the three\n",
      "objectives of our resulting word-as-images. We randomly select two\n",
      "instances from each of the resulting word-as-image illustrations\n",
      "for the five classes described above, and visually select one letter\n",
      "from each word, resulting in 10 letters in total. In each question\n",
      "we show an isolated letter illustration, without the context of the\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "word. To evaluate the ability of our method to visually depict the\n",
      "desired concept, we present four label options from the same class,\n",
      "and ask participants to choose the one that describes the letter\n",
      "illustration best. To evaluate the legibility of the results, we ask\n",
      "participants to choose the most suitable letter from a random list of\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "four letters. To asses the preservation of the font style, we present\n",
      "the four fonts and ask participants to choose the most suitable font\n",
      "for the illustration. We gathered answers from 40 participants, and\n",
      "the results are shown in Table 1. As can be seen, the level of concept\n",
      "recognizability and letter legibility are very high, and the 51%of\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "style matching of the letter illustration to the original font is well\n",
      "above random, which is 25%. We also test our algorithm without\n",
      "the two additional structure and style preserving losses ( L𝑎𝑐𝑎𝑝 and\n",
      "L𝑡𝑜𝑛𝑒) on the same words and letters (“Only SDS” in the table).\n",
      "As expected, without the additional constraints, the letter deforms\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "significantly resulting in higher concept recognizability but lower\n",
      "legibility and font style preservation. More details and examples are\n",
      "provided in the supplementary material.\n",
      "5.2 Comparison\n",
      "In the absence of a relevant baseline for comparison, we define base-\n",
      "lines based on large popular text-to-image models. Specifically, we\n",
      "use(1) SD Stable Diffusion [Rombach et al .2021], (2) SDEdit [Meng\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "et al.2022], (3) DallE2 [Ramesh et al .2022] illustrating the word,\n",
      "(4) DallE2+letter illustrating only the letter, and (5) CLIPDraw\n",
      "[Frans et al .2021]. We applied the methods above (details can be\n",
      "found in supplemental material) to three representative words –\n",
      "“bird”, “dress”, and “tulip”, with the fonts Bell MT, Quicksand, and\n",
      "Noteworthy-Bold, respectively. The results can be seen in Figure 10.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "In some cases Stable Diffusion (SD) did not manage to produce\n",
      "text at all (such as for the bird) and when text is produced, it is\n",
      "often not legible. The results obtained by SDEdit preserve the font’s\n",
      "characteristics and the letter’s legibility, but often fail to reflect\n",
      "the desired concept, such as in the case of the bird and the dress.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Word-As-Image for Semantic Typography •7\n",
      "The word\n",
      "BIRD and\n",
      "the letter R\n",
      "The word\n",
      "DRESS and\n",
      "the letter E\n",
      "The word\n",
      "TULIP and\n",
      "the letter U\n",
      "Input SD SDEdit DallE2 DallE2+letter CLIPDraw Ours\n",
      "Fig. 10. Comparison to alternative methods based on large scale text-to-image models. On the left are the letters used as input (only for SDEdit, CLIPDraw, and\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "ours), as well as the desired object of interest. The results from left to right obtained using Stable Diffusion [Rombach et al .2021], SDEdit [Meng et al .2022],\n",
      "DallE2 [Ramesh et al .2022], DallE2 with a letter specific prompt, CLIPDraw [Frans et al .2021], and our single-letter results, as well as the final word-as-image.\n",
      "Additionally, it operates in the raster domain and tends to adddetails\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "on top of the letter, while our method operates directly on the vector\n",
      "representation of the letters with the objective of modifying their\n",
      "shape . DallE2 manages to reflect the visual concept, however it often\n",
      "fails to produce legible text. When applied with a dedicated prompt\n",
      "to produce the word-as-image of only one letter (fifth column), it\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "manages to produce a legible letter, but there is less control over\n",
      "the output – it is impossible to specify the desired font or to control\n",
      "the size, position, and shape of the generated letter. Therefore, it is\n",
      "not clear how to combine these output illustrations into the entire\n",
      "word to create a word-as-image.\n",
      "CLIPDraw produces reasonable results conveying the semantics\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "of the input word. However, the results are non-smooth and the\n",
      "characteristics of the font are not preserved (for example observe\n",
      "how the letter \"E\" differs from the input letter). We further examine\n",
      "CLIPDraw with our shape preservation losses in the next Section.\n",
      "5.3 Ablation\n",
      "Figure 11 illustrates the impact of the letter’s initial number of\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "control points. When less control points are used ( 𝑃𝑜is the original\n",
      "number of control points), we may get insufficient variations, such\n",
      "as for the gorilla. However, this can also result in more abstract\n",
      "depictions, such as the ballerina. As we add control points, we get\n",
      "more graphic results, with the tradeoff that it often deviate from the\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "original letter. In Figure 15 we show the results of using only the\n",
      "∇ˆ𝑃LLSDS loss. As can be seen, in that case the illustrations strongly\n",
      "convey the semantic concept, however at the cost of legibility. In\n",
      "Figure 16 we analyze the effect of the weight 𝛼applied toL𝑎𝑐𝑎𝑝.\n",
      "Ranging from 1to0. WhenL𝑎𝑐𝑎𝑝 is too dominant, the results may\n",
      "not enough reflect the semantic concept, while the opposite case\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "harms legibility. Figure 13 illustrates a change in the 𝜎parameter of\n",
      "the low pass filter. When 𝜎=1almost no blur is applied, resulting\n",
      "in a shape constraint that is too strong.\n",
      "In Figure 14 we show the results of replacing the ∇ˆ𝑃LLSDS loss\n",
      "with a CLIP based loss, while using our proposed shape preservation\n",
      "terms. Although the results obtained with CLIP often depict the\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "desired visual concept, we find that using Stable Diffusion leads\n",
      "to smoother illustrations, that capture a wider range of semantic\n",
      "concepts.By using the hyperparameters described in the paper, we are able\n",
      "to achieve a reasonable balance between semantics and legibility.\n",
      "The parameters were determined manually based on visual assess-\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "ments, but can be adjusted as needed based on the user’s personal\n",
      "taste and goals.\n",
      "\"Ballet\"\n",
      "\"Gorilla\"\n",
      "\"Gym\"\n",
      "Input 𝑃𝑜𝑃 2×𝑃\n",
      "Fig. 11. The effect of the initial number of control points on outputs. On the\n",
      "left are the input letters and the target concepts used to generate the results\n",
      "on the right. 𝑃𝑜indicates the original number of control points as extracted\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "from the font, 𝑃is the input letter with our chosen hyperparameters, and\n",
      "for2×𝑃we increase the number of control points in 𝑃by two.\n",
      "6 CONCLUSIONS\n",
      "We presented a method for the automatic creation of vector-format\n",
      "word-as-image illustrations. Our method can handle a large variety\n",
      "of semantic concepts and use any font, while preserving the legibility\n",
      "of the text and the font’s style.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "There are limitations to our method. First, our method works\n",
      "letter by letter, and therefore, it cannot deform the shape of the\n",
      "entire word. In the future we can try to optimize the shape of several\n",
      "letters. Second, the approach works best on concrete visual concepts,\n",
      "and may fail with more abstract ones. This can be alleviated by\n",
      "optimizing the shape of letters using different concepts than the\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "word itself. Third, the layout of letters can also be automated for\n",
      "example, using methods such as [Wang et al. 2022].\n",
      "Our word-as-image illustrations demonstrate visual creativity\n",
      "and open the possibility for the use of large vision-language models\n",
      "for semantic typography, possibly also adding human-in-the-loop\n",
      "to arrive at more synergistic design methods of ML models and\n",
      "humans.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "8•Shir Iluz, Yael Vinker, Amir Hertz, Daniel Berio, Daniel Cohen-Or, and Ariel Shamir\n",
      "\"Bear\"\n",
      "\"Singer\"\n",
      "\"Giraffe\"\n",
      "Input 1 5 30 200Without\n",
      "L𝑡𝑜𝑛𝑒\n",
      "Fig. 13. Altering the 𝜎parameter of the low pass filter using in the L𝑡𝑜𝑛𝑒\n",
      "loss. On the leftmost column are the original letters and concepts used, then\n",
      "from left to right are the results obtained when using 𝜎∈{1,5,30,200},\n",
      "and withoutL𝑡𝑜𝑛𝑒.\n",
      "Input\n",
      "Letter\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "CLIP\n",
      "loss\n",
      "SDS\n",
      "loss\n",
      "\"Snail\" \"Skirt\" \"Socks\" \"Queen\" \"Strawberry\"\n",
      "Fig. 14. Replacing the SDS loss with a CLIP-based loss.Input\n",
      "Letter\n",
      "Ours\n",
      "Only\n",
      "SDS\n",
      "\"Cat\" \"Music\" \"Robot\" \"Cup\" \"Hands\"\n",
      "Fig. 15. The effect of using only the SDS loss: note how the third row simply\n",
      "looks like icon illustrations, while the second row still resembles legible\n",
      "letters.\n",
      "\"Bear\"\n",
      "\"Singer\"\n",
      "\"Giraffe\"\n",
      "Input 1 0.75 0.5 0.25Without\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "L𝑎𝑐𝑎𝑝\n",
      "Fig. 16. Altering the weight 𝛼of theL𝑎𝑐𝑎𝑝 loss. On the leftmost column\n",
      "are the original letters and concepts used, then from left to right are the\n",
      "results obtained when using 𝛼∈{1,0.75,0.5,0.25,0}.\n",
      "Fig. 12. Word-as-images produced by our method. This subset was chosen from the random set of words.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Word-As-Image for Semantic Typography •9\n",
      "Fig. 17. Additional results produced by our method.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "10 •Shir Iluz, Yael Vinker, Amir Hertz, Daniel Berio, Daniel Cohen-Or, and Ariel Shamir\n",
      "7 ACKNOWLEDGMENTS\n",
      "We are grateful to Richard Hao Zhang for the early discussion of\n",
      "the text-as-image problem. Ali Mahdavi-Amiri and Oren Katzir for\n",
      "reviewing earlier versions of the manuscript and to Anran Qi for\n",
      "assisting in evaluating the Chinese words. This research was sup-\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "ported in part by the Israel Science Foundation (grants no. 2492/20\n",
      "and 3441/21), Len Blavatnik and the Blavatnik family foundation,\n",
      "and the Tel Aviv University Innovation Laboratories (TILabs).\n",
      "REFERENCES\n",
      "Tomer Amit, Tal Shaharbany, Eliya Nachmani, and Lior Wolf. 2021. SegDiff: Image\n",
      "Segmentation with Diffusion Probabilistic Models. https://doi.org/10.48550/ARXIV.\n",
      "2112.00390\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Omri Avrahami, Dani Lischinski, and Ohad Fried. 2022. Blended Diffusion for Text-\n",
      "Driven Editing of Natural Images. In Proceedings of the IEEE/CVF Conference on\n",
      "Computer Vision and Pattern Recognition (CVPR) . 18208–18218.\n",
      "Samaneh Azadi, Matthew Fisher, Vladimir G. Kim, Zhaowen Wang, Eli Shechtman,\n",
      "and Trevor Darrell. 2018. Multi-Content GAN for Few-Shot Font Style Transfer.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "InProceedings of the IEEE Conference on Computer Vision and Pattern Recognition\n",
      "(CVPR) . IEEE, Salt Lake City, UT, USA, 7564–7573.\n",
      "Elena Balashova, Amit H. Bermano, Vladimir G. Kim, Stephen DiVerdi, Aaron Hertz-\n",
      "mann, and Thomas Funkhouser. 2019. Learning a Stroke-Based Representation for\n",
      "Fonts. Computer Graphics Forum 38, 1 (2019), 429–442.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Brad Barber and Hannu Huhdanpaa. 1995. QHull. The Geometry Center, University of\n",
      "Minnesota, http://www. geom. umn. edu/software/qhull (1995).\n",
      "Daniel Berio, Frederic Fol Leymarie, Paul Asente, and Jose Echevarria. 2022. StrokeStyles:\n",
      "Stroke-Based Segmentation and Stylization of Fonts. ACM Trans. Graph. 41, 3, Article\n",
      "28 (apr 2022), 21 pages. https://doi.org/10.1145/3505246\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Neill DF Campbell and Jan Kautz. 2014. Learning a Manifold of Fonts. ACM Transactions\n",
      "on Graphics (TOG) 33, 4 (2014). https://doi.org/10.1145/2601097.2601212 Article no.\n",
      "91.\n",
      "Hila Chefer, Shir Gur, and Lior Wolf. 2021. Transformer Interpretability Beyond Atten-\n",
      "tion Visualization. In Proceedings of the IEEE/CVF Conference on Computer Vision\n",
      "and Pattern Recognition (CVPR) . 782–791.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Jooyoung Choi, Sungwon Kim, Yonghyun Jeong, Youngjune Gwon, and Sungroh Yoon.\n",
      "2021. ILVR: Conditioning Method for Denoising Diffusion Probabilistic Models.\n",
      "CoRR abs/2108.02938 (2021). arXiv:2108.02938 https://arxiv.org/abs/2108.02938\n",
      "Boris Delaunay et al .1934. Sur la sphere vide. Izv. Akad. Nauk SSSR, Otdelenie Matem-\n",
      "aticheskii i Estestvennyka Nauk 7, 793-800 (1934), 1–2.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Noa Fish, Lilach Perry, Amit Bermano, and Daniel Cohen-Or. 2020. SketchPatch: Sketch\n",
      "Stylization via Seamless Patch-Level Synthesis. ACM Trans. Graph. 39, 6, Article\n",
      "227 (nov 2020), 14 pages. https://doi.org/10.1145/3414685.3417816\n",
      "Kevin Frans, Lisa B Soros, and Olaf Witkowski. 2021. Clipdraw: Exploring\n",
      "text-to-drawing synthesis through language-image encoders. arXiv preprint\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "arXiv:2106.14843 (2021).\n",
      "FreeType. 2009. FreeType library. https://freetype.org/\n",
      "Rinon Gal, Yuval Alaluf, Yuval Atzmon, Or Patashnik, Amit H. Bermano, Gal Chechik,\n",
      "and Daniel Cohen-Or. 2022. An Image is Worth One Word: Personalizing Text-to-\n",
      "Image Generation using Textual Inversion. https://doi.org/10.48550/ARXIV.2208.\n",
      "01618\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Rinon Gal, Moab Arar, Yuval Atzmon, Amit H. Bermano, Gal Chechik, and Daniel\n",
      "Cohen-Or. 2023. Designing an Encoder for Fast Personalization of Text-to-Image\n",
      "Models. https://doi.org/10.48550/ARXIV.2302.12228\n",
      "David Ha and Douglas Eck. 2018. A Neural Representation of Sketch Draw-\n",
      "ings. In Sixth International Conference on Learning Representations (ICLR) .\n",
      "https://arxiv.org/abs/1704.03477.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Amir Hertz, Ron Mokady, Jay Tenenbaum, Kfir Aberman, Yael Pritch, and Daniel\n",
      "Cohen-Or. 2022. Prompt-to-prompt image editing with cross attention control.\n",
      "(2022).\n",
      "Jonathan Ho, Ajay Jain, and Pieter Abbeel. 2020. Denoising Diffusion Probabilistic\n",
      "Models. CoRR abs/2006.11239 (2020). arXiv:2006.11239 https://arxiv.org/abs/2006.\n",
      "11239\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Kai Hormann and Günther Greiner. 2000. MIPS: An efficient global parametrization\n",
      "method . Technical Report. Erlangen-Nuernberg Univ (Germany) Computer Graphics\n",
      "Group.\n",
      "Adobe Systems Inc. 1990. Adobe Type 1 Font Format . Addison Wesley Publishing\n",
      "Company.\n",
      "Ajay Jain, Amber Xie, and Pieter Abbeel. 2022. VectorFusion: Text-to-SVG by Abstract-\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "ing Pixel-Based Diffusion Models. arXiv preprint arXiv:2211.11319 (2022).\n",
      "Yue Jiang, Zhouhui Lian, Yingmin Tang, and Jianguo Xiao. 2019. SCFont: Structure-\n",
      "Guided Chinese Font Generation via Deep Stacked Networks. Proceedings of the\n",
      "AAAI Conference on Artificial Intelligence 33, 01 (Jul. 2019), 4015–4022. https://doi.org/10.1609/aaai.v33i01.33014015\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Ji Lee. 2011. Word As Image . Adams Media, London.\n",
      "Tzu-Mao Li, Michal Lukáč, Gharbi Michaël, and Jonathan Ragan-Kelley. 2020. Differen-\n",
      "tiable Vector Graphics Rasterization for Editing and Learning. ACM Trans. Graph.\n",
      "(Proc. SIGGRAPH Asia) 39, 6 (2020), 193:1–193:15.\n",
      "Zhouhui Lian, Bo Zhao, Xudong Chen, and Jianguo Xiao. 2018. EasyFont: A style\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "learning-based system to easily build your large-scale handwriting fonts. ACM\n",
      "Transactions on Graphics (TOG) 38, 1 (2018), 1–18.\n",
      "Raphael Gontijo Lopes, David Ha, Douglas Eck, and Jonathon Shlens. 2019. A Learned\n",
      "Representation for Scalable Vector Graphics. In Proceedings of the IEEE/CVF Interna-\n",
      "tional Conference on Computer Vision (ICCV) .\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Xu Ma, Yuqian Zhou, Xingqian Xu, Bin Sun, Valerii Filev, Nikita Orlov, Yun Fu, and\n",
      "Humphrey Shi. 2022. Towards Layer-wise Image Vectorization. https://doi.org/10.\n",
      "48550/ARXIV.2206.04655\n",
      "Wendong Mao, Shuai Yang, Huihong Shi, Jiaying Liu, and Zhongfeng Wang. 2022. Intel-\n",
      "ligent Typography: Artistic Text Style Transfer for Complex Texture and Structure.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "IEEE Transactions on Multimedia (2022), 1–15. https://doi.org/10.1109/TMM.2022.\n",
      "3209870\n",
      "Chenlin Meng, Yutong He, Yang Song, Jiaming Song, Jiajun Wu, Jun-Yan Zhu, and\n",
      "Stefano Ermon. 2022. SDEdit: Guided Image Synthesis and Editing with Stochastic\n",
      "Differential Equations. In International Conference on Learning Representations .\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Gal Metzer, Elad Richardson, Or Patashnik, Raja Giryes, and Daniel Cohen-Or. 2022.\n",
      "Latent-NeRF for Shape-Guided Generation of 3D Shapes and Textures. https:\n",
      "//doi.org/10.48550/ARXIV.2211.07600\n",
      "Oscar Michel, Roi Bar-On, Richard Liu, Sagie Benaim, and Rana Hanocka.\n",
      "2021. Text2Mesh: Text-Driven Neural Stylization for Meshes. arXiv preprint\n",
      "arXiv:2112.03221 (2021).\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Alex Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam, Pamela Mishkin, Bob\n",
      "McGrew, Ilya Sutskever, and Mark Chen. 2021. Glide: Towards photorealistic\n",
      "image generation and editing with text-guided diffusion models. arXiv preprint\n",
      "arXiv:2112.10741 (2021).\n",
      "Laurence Penney. 1996. A History of TrueType. https://www.truetype-\n",
      "typography.com/.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Huy Quoc Phan, Hongbo Fu, and Antoni B Chan. 2015. Flexyfont: Learning Transferring\n",
      "Rules for Flexible Typeface Synthesis. Computer Graphics Forum 34, 7 (2015), 245–\n",
      "256.\n",
      "Ben Poole, Ajay Jain, Jonathan T Barron, and Ben Mildenhall. 2022. Dreamfusion:\n",
      "Text-to-3d using 2d diffusion. arXiv preprint arXiv:2209.14988 (2022).\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Lakshman Prasad. 1997. Morphological analysis of shapes. CNLS newsletter 139, 1\n",
      "(1997), 1997–07.\n",
      "Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini\n",
      "Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen\n",
      "Krueger, and Ilya Sutskever. 2021. Learning Transferable Visual Models From\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Natural Language Supervision. CoRR abs/2103.00020 (2021). arXiv:2103.00020\n",
      "https://arxiv.org/abs/2103.00020\n",
      "Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen. 2022.\n",
      "Hierarchical text-conditional image generation with clip latents. arXiv preprint\n",
      "arXiv:2204.06125 (2022).\n",
      "Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Ommer. 2021. High-Resolution Image Synthesis with Latent Diffusion Models.\n",
      "arXiv:2112.10752 [cs.CV]\n",
      "Olaf Ronneberger, Philipp Fischer, and Thomas Brox. 2015. U-net: Convolutional\n",
      "networks for biomedical image segmentation. In International Conference on Medical\n",
      "image computing and computer-assisted intervention . Springer, 234–241.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Nataniel Ruiz, Yuanzhen Li, Varun Jampani, Yael Pritch, Michael Rubinstein, and Kfir\n",
      "Aberman. 2022. DreamBooth: Fine Tuning Text-to-image Diffusion Models for\n",
      "Subject-Driven Generation. (2022).\n",
      "Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily Den-\n",
      "ton, Seyed Kamyar Seyed Ghasemipour, Burcu Karagol Ayan, S. Sara Mahdavi,\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Rapha Gontijo Lopes, Tim Salimans, Jonathan Ho, David J Fleet, and Mohammad\n",
      "Norouzi. 2022. Photorealistic Text-to-Image Diffusion Models with Deep Language\n",
      "Understanding. https://doi.org/10.48550/ARXIV.2205.11487\n",
      "Kunpeng Song, Ligong Han, Bingchen Liu, Dimitris Metaxas, and Ahmed Elgammal.\n",
      "2022. Diffusion Guided Domain Adaptation of Image Generators. https://doi.org/\n",
      "10.48550/ARXIV.2212.04473\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Rapee Suveeranont and Takeo Igarashi. 2010. Example-Based Automatic Font Genera-\n",
      "tion. In Smart Graphics . Number LNCS 6133 in Lecture Notes in Computer Science.\n",
      "127–138.\n",
      "Purva Tendulkar, Kalpesh Krishna, Ramprasaath R. Selvaraju, and Devi Parikh. 2019.\n",
      "Trick or TReAT: Thematic Reinforcement for Artistic Typography. https://doi.org/\n",
      "10.48550/ARXIV.1903.07820\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Guy Tevet, Brian Gordon, Amir Hertz, Amit H Bermano, and Daniel Cohen-Or. 2022.\n",
      "Motionclip: Exposing human motion generation to clip space. In Computer Vision–\n",
      "ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23–27, 2022, Proceedings,\n",
      "Part XXII . Springer, 358–374.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Word-As-Image for Semantic Typography •11\n",
      "Yingtao Tian and David Ha. 2021. Modern Evolution Strategies for Creativity: Fitting\n",
      "Concrete Images and Abstract Conceptst. arXiv:2109.08857 [cs.NE]\n",
      "Narek Tumanyan, Michal Geyer, Shai Bagon, and Tali Dekel. 2022a. Plug-and-Play\n",
      "Diffusion Features for Text-Driven Image-to-Image Translation. https://doi.org/10.\n",
      "48550/ARXIV.2211.12572\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Narek Tumanyan, Michal Geyer, Shai Bagon, and Tali Dekel. 2022b. Plug-and-Play\n",
      "Diffusion Features for Text-Driven Image-to-Image Translation. https://doi.org/10.\n",
      "48550/ARXIV.2211.12572\n",
      "Yael Vinker, Yuval Alaluf, Daniel Cohen-Or, and Ariel Shamir. 2022a. CLIPascene: Scene\n",
      "Sketching with Different Types and Levels of Abstraction. https://doi.org/10.48550/\n",
      "ARXIV.2211.17256\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Yael Vinker, Ehsan Pajouheshgar, Jessica Y. Bo, Roman Christian Bachmann, Amit Haim\n",
      "Bermano, Daniel Cohen-Or, Amir Zamir, and Ariel Shamir. 2022b. CLIPasso:\n",
      "Semantically-Aware Object Sketching. ACM Trans. Graph. 41, 4, Article 86 (jul\n",
      "2022), 11 pages. https://doi.org/10.1145/3528223.3530068\n",
      "Patrick von Platen, Suraj Patil, Anton Lozhkov, Pedro Cuenca, Nathan Lambert, Kashif\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Rasul, Mishig Davaadorj, and Thomas Wolf. 2022. Diffusers: State-of-the-art diffu-\n",
      "sion models. https://github.com/huggingface/diffusers.\n",
      "Wenjing Wang, Jiaying Liu, Shuai Yang, and Zongming Guo. 2019. Typography With\n",
      "Decor: Intelligent Text Style Transfer. In Proceedings of the IEEE/CVF Conference on\n",
      "Computer Vision and Pattern Recognition (CVPR) .\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Yizhi Wang and Zhouhui Lian. 2021. DeepVecFont: Synthesizing High-Quality Vector\n",
      "Fonts via Dual-Modality Learning. ACM Transactions on Graphics 40, 6 (Dec. 2021),\n",
      "1–15. https://doi.org/10.1145/3478513.3480488\n",
      "Yizhi Wang, Guo Pu, Wenhan Luo, Yexin Wang, Pengfei Xiong, Hongwen Kang, and\n",
      "Zhouhui Lian. 2022. Aesthetic Text Logo Synthesis via Content-Aware Layout\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Inferring. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern\n",
      "Recognition (CVPR) . 2436–2445.\n",
      "Jie Xu and Craig S. Kaplan. 2007. Calligraphic Packing. In Proceedings of Graphics\n",
      "Interface 2007 on - GI ’07 . ACM Press, Montreal, Canada, 43. https://doi.org/10.1145/\n",
      "1268517.1268527\n",
      "Shuai Yang, Jiaying Liu, Zhouhui Lian, and Zongming Guo. 2017. Awesome Typography:\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Statistics-Based Text Effects Transfer. In Proceedings of the IEEE Conference on\n",
      "Computer Vision and Pattern Recognition (CVPR) .\n",
      "Shuai Yang, Jiaying Liu, Wenhan Yang, and Zongming Guo. 2018. Context-Aware Un-\n",
      "supervised Text Stylization. In Proceedings of the 26th ACM International Conference\n",
      "on Multimedia (Seoul, Republic of Korea) (MM ’18) . Association for Computing Ma-\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "chinery, New York, NY, USA, 1688–1696. https://doi.org/10.1145/3240508.3240580\n",
      "Shuai Yang, Zhangyang Wang, and Jiaying Liu. 2022. Shape-Matching GAN++: Scale\n",
      "Controllable Dynamic Artistic Text Style Transfer. IEEE Transactions on Pattern\n",
      "Analysis and Machine Intelligence 44, 7 (2022), 3807–3820. https://doi.org/10.1109/\n",
      "TPAMI.2021.3055211\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Junsong Zhang, Yu Wang, Weiyi Xiao, and Zhenshan Luo. 2017. Synthesizing Orna-\n",
      "mental Typefaces: Synthesizing Ornamental Typefaces. Computer Graphics Forum\n",
      "36, 1 (Jan. 2017), 64–75. https://doi.org/10.1111/cgf.12785\n",
      "Renrui Zhang, Ziyu Guo, Wei Zhang, Kunchang Li, Xupeng Miao, Bin Cui, Yu Qiao,\n",
      "Peng Gao, and Hongsheng Li. 2021. PointCLIP: Point Cloud Understanding by CLIP.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "https://doi.org/10.48550/ARXIV.2112.02413\n",
      "Changqing Zou, Junjie Cao, Warunika Ranaweera, Ibraheem Alhashim, Ping Tan, Alla\n",
      "Sheffer, and Hao Zhang. 2016. Legible Compact Calligrams. ACM Transactions on\n",
      "Graphics 35, 4 (July 2016), 1–12. https://doi.org/10.1145/2897824.2925887\n",
      "Ju Jia Zou, Hung-Hsin Chang, and Hong Yan. 2001. Shape skeletonization by identifying\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "discrete local symmetries. Pattern Recognition 34, 10 (2001), 1895–1905.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "12 •Shir Iluz, Yael Vinker, Amir Hertz, Daniel Berio, Daniel Cohen-Or, and Ariel Shamir\n",
      "SUPPLEMENTARY MATERIAL\n",
      "A IMPLEMENTATION DETAILS\n",
      "In this section we provide further implementation details. We intend\n",
      "to release the code to promote future research in this domain.\n",
      "Our method is based on the pre-trained 𝑣1−5Stable Diffusion\n",
      "model [Rombach et al .2021], which we use through the diffusers\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "[von Platen et al .2022] Python package. We optimize only the\n",
      "control points’ coordinates (i.e. we do not modify the color, width,\n",
      "and other parameters of the shape). We use the Adam optimizer with\n",
      "𝛽1=0.9,𝛽2=0.9,𝜖=10−6. We use learning rate warm-up from\n",
      "0.1to0.8over 100iterations and exponential decay from 0.8to0.4\n",
      "over the rest 400iterations, 500iteration in total. The optimization\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "process requires at least 10GB memory and approximately 5 minutes\n",
      "to produce a single letter illustration on RTX2080 GPU.\n",
      "Before we feed the rasterized 600𝑥600letter image into the Stable\n",
      "Diffusion model, we apply random augmentations as proposed in\n",
      "CLIPDraw [Frans et al .2021]. Specifically, perspective transform\n",
      "with a distortion scale of 0.5, with probability 0.7, and a random\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "512𝑥512crop. We add the suffix \"a [ word ]. minimal flat 2d vector.\n",
      "lineal color. trending on artstation.\" to the target word 𝑊, before\n",
      "feeding it into the text encoder of a pretrained CLIP model.\n",
      "B COMPARISONS\n",
      "As described in Section 5.2 we define five baselines to compare with.\n",
      "In this section we provide more details about the evaluation and\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "more qualitative results. For (1) SD , we run Stable Diffusion [Rom-\n",
      "bach et al .2021] with the default hyper parameters of 50inference\n",
      "steps and a guidance scale of 7.5. We use the prompt “Word as image\n",
      "of the word [ word ]. [font] font. minimal flat 2d vector. lineal color.\n",
      "black and white style”.\n",
      "For(2) SDEdit [Meng et al .2022], we utilized the diffusers [von\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Platen et al .2022] implementation, using the prompt “A [ word ].\n",
      "minimal flat 2d vector. lineal color. black and white style”, and the\n",
      "rasterized input letter as the reference image. We use the default\n",
      "values of 50inference steps and a guidance scale of 7.5. We use a\n",
      "strength value of 0.85. The strength value determines the quantity\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "of noise added to the input image – a value close to 1.0results in\n",
      "higher degree of variation in the output, and vice versa.\n",
      "We use the official website of OpenAI to run (3) DallE2 [Ramesh\n",
      "et al.2022], using the prompt “Word as image of the word [ word ].\n",
      "Where the letter [ letter ] looks like a [ word ]. [font] font. minimal\n",
      "flat 2d vector. lineal color. black and white style”. To encourage\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "the manipulation of a specific letter, for (4) DallE2+letter we use\n",
      "the prompt “The letter [ letter ] in the shape of a [ word ]. [font] font.\n",
      "minimal flat 2d vector. lineal color. black and white style”. For (5)\n",
      "CLIPDraw [Frans et al .2021], we use the author’s official imple-\n",
      "mentation with the recommended hyper-parameters. Instead of\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "using randomly initialized strokes, we use our vectorized letter as\n",
      "input, along with the prompt “A [ word ]. [font] font. minimal flat\n",
      "2d vector. lineal color. black and white style”. We provide more\n",
      "comparisons to the methods described above in Figure 20.\n",
      "Fig. 18. Some additional examples of word-as-image applied on Chinese\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "characters. In Chinese, a whole word can be represented by one character.\n",
      "Here we show from left: bird, rabbit, cat and surfing (two last characters\n",
      "together). The complexity of characters imposes an additional challenge for\n",
      "our method. This could be alleviated in the future for example by dividing\n",
      "the characters to radicals and applying the method only on parts of the\n",
      "character.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "C PERCEPTUAL STUDY\n",
      "In this section, we provide more details about the perceptual study\n",
      "described in Section 5.1. The randomly chosen objects, fonts, and\n",
      "letters are shown in Table 2. A few visual examples are shown in\n",
      "Figure 19.\n",
      "Ours Only SDS\n",
      "\"Coat\"\n",
      "\"Soccer\"\n",
      "\"Shirt\"\n",
      "\"Rugby\"\n",
      "Font\n",
      "Rec.\n",
      "Fig. 19. Examples of illustrations presented in the perceptual study. Each\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "pair in the top part shows illustrations obtained using our proposed method\n",
      "(left) and using only SDS loss (right). On the bottom is an example of an\n",
      "illustration presented for the font recognition questions.\n",
      "D ADDITIONAL RESULTS\n",
      "We provide additional results of our generated word-as-images. In\n",
      "Figures 21-32 we show results of selected words and unique fonts.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Word-As-Image for Semantic Typography •13\n",
      "\"Muffin\"\n",
      "\"Tiger\"\n",
      "\"Octopus\"\n",
      "\"Plant\"\n",
      "\"Astronaut\"\n",
      "\"Robot\"\n",
      "\"Bunny\"\n",
      "\"Flamingo\"\n",
      "\"Paris\"\n",
      "\"Owl\"\n",
      "\"Swan\"\n",
      "\"Mermaid\"\n",
      "Input SD SDEdit DallE2 DallE2+letter CLIPDraw Ours\n",
      "Fig. 20. Comparison to alternative methods based on large scale text-to-image models. On the left are the letters used as input (only for SDEdit, CLIPDraw,\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "and ours), as well as the desired object of interest. The results from left to right obtained using Stable Diffusion [Rombach et al .2021], SDEdit [Meng et al .\n",
      "2022], DallE2 [Ramesh et al. 2022], DallE2 with a letter specific prompt, CLIPDraw [Frans et al. 2021], and our single-letter results.\n",
      "In Figures 33-48 we show the results obtained for the random set of\n",
      "words.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "14 •Shir Iluz, Yael Vinker, Amir Hertz, Daniel Berio, Daniel Cohen-Or, and Ariel Shamir\n",
      "Table 2. Randomly chosen objects, letters, and fonts for the perceptual\n",
      "study.\n",
      "Object Letter Font\n",
      "Pineapple P Noteworthy-Bold\n",
      "Orange O Quicksand\n",
      "Rugby Y Noteworthy-Bold\n",
      "Soccer S Noteworthy-Bold\n",
      "Bear B Bell MT\n",
      "Lion O Quicksand\n",
      "Singer N Noteworthy-Bold\n",
      "Pilot P Noteworthy-Bold\n",
      "Coat O HobeauxRococeaux-Sherman\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Shirt S Bell MT\n",
      "Fig. 21. Word-as-image illustrations created by our method.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Word-As-Image for Semantic Typography •15\n",
      "Fig. 22. Word-as-image illustrations created by our method.\n",
      "Fig. 23. Word-as-image illustrations created by our method.\n",
      "Fig. 24. Word-as-image illustrations created by our method.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "16 •Shir Iluz, Yael Vinker, Amir Hertz, Daniel Berio, Daniel Cohen-Or, and Ariel Shamir\n",
      "Fig. 25. Word-as-image illustrations created by our method.\n",
      "Fig. 26. Word-as-image illustrations created by our method.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Word-As-Image for Semantic Typography •17\n",
      "Fig. 27. Word-as-image illustrations created by our method.\n",
      "Fig. 28. Word-as-image illustrations created by our method.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "18 •Shir Iluz, Yael Vinker, Amir Hertz, Daniel Berio, Daniel Cohen-Or, and Ariel Shamir\n",
      "Fig. 29. Word-as-image illustrations created by our method.\n",
      "Fig. 30. Word-as-image illustrations created by our method.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Word-As-Image for Semantic Typography •19\n",
      "Fig. 31. Word-as-image illustrations created by our method.\n",
      "Fig. 32. Word-as-image illustrations created by our method.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "20 •Shir Iluz, Yael Vinker, Amir Hertz, Daniel Berio, Daniel Cohen-Or, and Ariel Shamir\n",
      "Fig. 33. Word-as-image illustrations created by our method for randomly chosen words.\n",
      "Fig. 34. Word-as-image illustrations created by our method for randomly chosen words.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Word-As-Image for Semantic Typography •21\n",
      "Fig. 35. Word-as-image illustrations created by our method for randomly chosen words.\n",
      "Fig. 36. Word-as-image illustrations created by our method for randomly chosen words.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "22 •Shir Iluz, Yael Vinker, Amir Hertz, Daniel Berio, Daniel Cohen-Or, and Ariel Shamir\n",
      "Fig. 37. Word-as-image illustrations created by our method for randomly chosen words.\n",
      "Fig. 38. Word-as-image illustrations created by our method for randomly chosen words.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Word-As-Image for Semantic Typography •23\n",
      "Fig. 39. Word-as-image illustrations created by our method for randomly chosen words.\n",
      "Fig. 40. Word-as-image illustrations created by our method for randomly chosen words.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "24 •Shir Iluz, Yael Vinker, Amir Hertz, Daniel Berio, Daniel Cohen-Or, and Ariel Shamir\n",
      "Fig. 41. Word-as-image illustrations created by our method for randomly chosen words.\n",
      "Fig. 42. Word-as-image illustrations created by our method for randomly chosen words.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Word-As-Image for Semantic Typography •25\n",
      "Fig. 43. Word-as-image illustrations created by our method for randomly chosen words.\n",
      "Fig. 44. Word-as-image illustrations created by our method for randomly chosen words.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "26 •Shir Iluz, Yael Vinker, Amir Hertz, Daniel Berio, Daniel Cohen-Or, and Ariel Shamir\n",
      "Fig. 45. Word-as-image illustrations created by our method for randomly chosen words.\n",
      "Fig. 46. Word-as-image illustrations created by our method for randomly chosen words.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Word-As-Image for Semantic Typography •27\n",
      "Fig. 47. Word-as-image illustrations created by our method for randomly chosen words.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "28 •Shir Iluz, Yael Vinker, Amir Hertz, Daniel Berio, Daniel Cohen-Or, and Ariel Shamir\n",
      "Fig. 48. Word-as-image illustrations created by our method for randomly chosen words.\n",
      "---------\n",
      "Question: What technique did this article use?\n",
      "Helpful Answer:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "query = \"What technique did this article use?\"\n",
    "\n",
    "result = chain({\"input_documents\": lg_docs, \"question\": query}, return_only_outputs=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T08:47:14.668600400Z",
     "start_time": "2023-10-09T08:46:54.508810100Z"
    }
   },
   "id": "23c4970c82b5229d"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6aa32765",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T07:53:55.037593200Z",
     "start_time": "2023-10-09T07:53:53.471646300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new MapRerankDocumentsChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "February 2021Before college the two main things I worked on, outside of school,\n",
      "\n",
      "were writing and programming. I didn't write essays. I wrote what\n",
      "\n",
      "beginning writers were supposed to write then, and probably still\n",
      "\n",
      "are: short stories. My stories were awful. They had hardly any plot,\n",
      "\n",
      "just characters with strong feelings, which I imagined made them\n",
      "---------\n",
      "Question: Who was the authors friend who he got permission from to use the IBM 1401?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "deep.The first programs I tried writing were on the IBM 1401 that our\n",
      "\n",
      "school district used for what was then called \"data processing.\"\n",
      "\n",
      "This was in 9th grade, so I was 13 or 14. The school district's\n",
      "\n",
      "1401 happened to be in the basement of our junior high school, and\n",
      "\n",
      "my friend Rich Draves and I got permission to use it. It was like\n",
      "---------\n",
      "Question: Who was the authors friend who he got permission from to use the IBM 1401?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "a mini Bond villain's lair down there, with all these alien-looking\n",
      "\n",
      "machines  CPU, disk drives, printer, card reader  sitting up\n",
      "\n",
      "on a raised floor under bright fluorescent lights.The language we used was an early version of Fortran. You had to\n",
      "\n",
      "type programs on punch cards, then stack them in the card reader\n",
      "\n",
      "and press a button to load the program into memory and run it. The\n",
      "---------\n",
      "Question: Who was the authors friend who he got permission from to use the IBM 1401?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "result would ordinarily be to print something on the spectacularly\n",
      "\n",
      "loud printer.I was puzzled by the 1401. I couldn't figure out what to do with\n",
      "\n",
      "it. And in retrospect there's not much I could have done with it.\n",
      "\n",
      "The only form of input to programs was data stored on punched cards,\n",
      "\n",
      "and I didn't have any data stored on punched cards. The only other\n",
      "---------\n",
      "Question: Who was the authors friend who he got permission from to use the IBM 1401?\n",
      "Helpful Answer:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "option was to do things that didn't rely on any input, like calculate\n",
      "\n",
      "approximations of pi, but I didn't know enough math to do anything\n",
      "\n",
      "interesting of that type. So I'm not surprised I can't remember any\n",
      "\n",
      "programs I wrote, because they can't have done much. My clearest\n",
      "\n",
      "memory is of the moment I learned it was possible for programs not\n",
      "---------\n",
      "Question: Who was the authors friend who he got permission from to use the IBM 1401?\n",
      "Helpful Answer:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "query = \"Who was the authors friend who he got permission from to use the IBM 1401?\"\n",
    "\n",
    "result = chain({\"input_documents\": lg_docs[:5], \"question\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "32ca3629",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T08:47:18.858993Z",
     "start_time": "2023-10-09T08:47:18.838837400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "' Word-As-Image for Semantic Typography'"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['output_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6541e14c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T08:47:27.977107100Z",
     "start_time": "2023-10-09T08:47:27.956703500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[{'answer': ' Word-As-Image for Semantic Typography', 'score': '100'},\n {'answer': ' word-as-image semantic typography technique', 'score': '100'},\n {'answer': ' The article used a method to create word-as-image illustrations automatically.',\n  'score': '100'},\n {'answer': ' This article used an optimization technique to convey desired concepts by altering the outlines of letters without changing the color or texture.',\n  'score': '90'},\n {'answer': ' Semantic typography', 'score': '100'},\n {'answer': ' word-as-image illustrations', 'score': '100'},\n {'answer': ' Creating a word-as-image', 'score': '100'},\n {'answer': ' This article used word-as-image technique.', 'score': '100'},\n {'answer': ' The technique used in this article is finding subtle modifications of the letter shape to illustrate a concept.',\n  'score': '90'},\n {'answer': ' This article used deep-learning and the availability of huge foundational models that combine language and visual understanding.',\n  'score': '100'},\n {'answer': ' This article used a technique that relies on raster textures.',\n  'score': '80'},\n {'answer': ' This article used a technique that concentrates on changing only the semantic typography of words.',\n  'score': '80'},\n {'answer': ' This article used the geometry of the letters to convey the meaning without any changes in color or texture or embellishments.',\n  'score': '100'},\n {'answer': ' Vector-based representation of the letters.', 'score': '100'},\n {'answer': ' The technique used in this article is vectorized shape optimization, which allows the user to choose the most likeable combination for letter replacement.',\n  'score': '100'},\n {'answer': ' The article used the Score Distillation Sampling approach and the Stable Diffusion model.',\n  'score': '100'},\n {'answer': \" The article used a differentiable rasterizer to backpropagate gradients from a raster-based loss to the shape's parameters.\",\n  'score': '90'},\n {'answer': ' This article used a technique of comparing a low-pass filter of the resulting rasterized letter to the original one.',\n  'score': '80'},\n {'answer': ' Artistic text style transfer', 'score': '100'},\n {'answer': ' This article used patch-based texture synthesis and variants of GANs that operate within the raster domain.',\n  'score': '90'},\n {'answer': ' This article used vector domain font generation and stylization. ',\n  'score': '100'},\n {'answer': ' Represented as outline samples or parametric curve segments',\n  'score': '100'},\n {'answer': ' geometric shape deformations of the letters', 'score': '100'},\n {'answer': ' Stable Diffusion', 'score': '100'},\n {'answer': ' This article used a technique that performs semantic stylization.',\n  'score': '100'},\n {'answer': ' The article used an autoencoder to measure the distance between the letter and icons from the desired class.',\n  'score': '100'},\n {'answer': ' Our method operates in the vector domain and incorporates the expressiveness of large pretrained models.',\n  'score': '100'},\n {'answer': ' Language-vision models and diffusion models', 'score': '100'},\n {'answer': ' This article used artificial intelligence models trained on millions of images and text pairs to perform challenging vision related tasks.',\n  'score': '80'},\n {'answer': ' Word-As-Image for Semantic Typography', 'score': '100'},\n {'answer': ' CLIPDraw and a differentiable rasterizer', 'score': '100'},\n {'answer': ' Evolutionary algorithms combined with CLIP guidance.',\n  'score': '100'},\n {'answer': ' SDEdit and pretrained diffusion models', 'score': '100'},\n {'answer': \" The article utilized the strong visual and semantic prior induced by a pretrained Stable Diffusion model, as well as adding new components to the optimization process to preserve the font's style and text legibility.\",\n  'score': '100'},\n {'answer': ' This article used a vectorized graphic representation, with outline contours typically represented by a collection of lines and Bézier or B-Spline curves.',\n  'score': '90'},\n {'answer': ' This article used Latent Diffusion Models, which are generative models that are trained to learn a data distribution by the gradual denoising of a variable sampled from a Gaussian distribution.',\n  'score': '100'},\n {'answer': ' The article used the Stable Diffusion model, which is a type of latent diffusion model (LDM).',\n  'score': '90'},\n {'answer': ' A denoising diffusion probabilistic model (DDPM)',\n  'score': '100'},\n {'answer': ' Stable Diffusion', 'score': '100'},\n {'answer': ' Score Distillation', 'score': '100'},\n {'answer': ' DreamFusion proposed a way to use the diffusion model.',\n  'score': '80'},\n {'answer': ' This article used score distillation loss to optimize the parameters of a NeRF model.',\n  'score': '100'},\n {'answer': ' This article used a technique called Neural Radiance Fields (NeRF) to gradually change a 3D object to fit a text prompt.',\n  'score': '100'},\n {'answer': ' This article used a technique called Gradient Skipping for UNets and modified the Nerf parameters using the LDM loss.',\n  'score': '100'},\n {'answer': ' The technique used in this article is called CLIPAugment and Encoder-UNet with Low-Pass Filtering (LPF).',\n  'score': '90'},\n {'answer': ' It used a differentiable rasterizer (DiffVG) and a pretrained frozen Stable Diffusion model.',\n  'score': '100'},\n {'answer': ' The article used the ∇ˆ𝑃LLSDS loss, a low pass filter, and a Delaunay triangulation.',\n  'score': '100'},\n {'answer': ' VectorFusion with the SDS loss', 'score': '100'},\n {'answer': ' This article used a differentiable rasterizer and vectorization with LIVE [Ma et al. 2022] to define an initial set of parameters to be optimized in the second stage using the SDS loss. It also augmented the 600x600 image to a 512x512 image using CLIPDraw [Frans et al. 2021] and fed it into a pretrained encoder.',\n  'score': '100'},\n {'answer': ' The article used Eof Stable Diffusion to produce the corresponding latent code.',\n  'score': '100'},\n {'answer': ' The article used a method of letter representation.',\n  'score': '100'},\n {'answer': ' This article used the FreeType font library and translated the outline of each letter into a set of cubic Bézier curves.',\n  'score': '100'},\n {'answer': ' Subdivision process', 'score': '80'},\n {'answer': ' This article used a subdivision procedure to letters.',\n  'score': '100'},\n {'answer': ' The article used a technique of iteratively subdividing Bézier segments until reaching a target number of control points. ',\n  'score': '100'},\n {'answer': ' The article used an optimization technique.', 'score': '80'},\n {'answer': ' This document does not answer the question.', 'score': '0'},\n {'answer': ' The article used the Delaunay triangulation technique.',\n  'score': '80'},\n {'answer': ' This article used a differentiable rasterizer R[Li et al .2020] to output the rasterized letter R(ˆ𝑃).',\n  'score': '100'},\n {'answer': \" This article used the SDS loss and the Stable Diffusion model, conditioned on the CLIP's embedding of the given text, to encourage R(ˆ𝑃) to convey the given text prompt and preserve the shape of each individual letter.\",\n  'score': '100'},\n {'answer': ' The article used as-conformal-as-possible constraint and a tone constraint to guide the optimization process.',\n  'score': '80'},\n {'answer': ' This article used a process of backpropagation to update parameters, which was repeated 500 steps and took approximately 5 minutes to produce a single letter illustration on RTX2080 GPU. ',\n  'score': '90'},\n {'answer': ' The technique used in this article is ∇ˆ𝑃LLSDS loss.',\n  'score': '100'},\n {'answer': ' As-Conformal-As-Possible Deformation Loss', 'score': '100'},\n {'answer': ' constrained Delaunay triangulation', 'score': '100'},\n {'answer': ' Delaunay triangulation', 'score': '100'},\n {'answer': ' The article used the ACAP loss technique.', 'score': '80'},\n {'answer': ' This article used a local-tone preservation loss term to constrain the tone of the adjusted letter.',\n  'score': '90'},\n {'answer': ' The article used a low pass filter (LPF) and computed the L2 distance between the resulting blurred letters.',\n  'score': '100'},\n {'answer': ' This article uses a weighted average of three terms to define its final objective.',\n  'score': '100'},\n {'answer': ' The article used a technique that balances between L𝑡𝑜𝑛𝑒 and L𝑎𝑐𝑎𝑝 to maintain the legibility of the letter while allowing the desired semantic shape to change.',\n  'score': '100'},\n {'answer': ' L𝑡𝑜𝑛𝑒', 'score': '100'},\n {'answer': ' They used an exponential weight adjustment technique with the parameters a = 100, b = 300, and c = 30.',\n  'score': '90'},\n {'answer': ' Our approach used a robustness technique. ', 'score': '80'},\n {'answer': ' This article used a technique to generate word-as-image illustrations.',\n  'score': '90'},\n {'answer': ' The article used ChatGPT to sample ten inputs.', 'score': '100'},\n {'answer': ' This article used a technique to randomly sample one of four fonts and apply it to each letter of the word.',\n  'score': '100'},\n {'answer': ' The article used a technique of combining letters and words to create illustrations that convey semantic concepts.',\n  'score': '90'},\n {'answer': ' This article used a technique that captures the font characteristics and style matching of the font, using structure and style preserving losses.',\n  'score': '90'},\n {'answer': ' This article used quantitative and human evaluation techniques.',\n  'score': '100'},\n {'answer': ' This article used a perceptual study to quantitatively assess the three objectives of their resulting word-as-images by randomly selecting two instances from each of the illustrations for the five classes and visually selecting one letter from each word, resulting in 10 letters in total.',\n  'score': '100'},\n {'answer': ' The technique used was to present four label options from the same class and ask participants to choose the one that describes the letter illustration best, and to evaluate the legibility of the results, ask participants to choose the most suitable letter from a random list.',\n  'score': '90'},\n {'answer': ' This article used a survey technique where participants were asked to choose the most suitable font for an illustration.',\n  'score': '80'},\n {'answer': ' The technique used in this article is to use two additional structure and style preserving losses (L𝑎𝑐𝑎𝑝 and L𝑡𝑜𝑛𝑒) to match the style of the letter illustration to the original font.',\n  'score': '100'},\n {'answer': ' SD Stable Diffusion and SDEdit', 'score': '100'},\n {'answer': ' This article used DallE2, DallE2+letter, and CLIPDraw.',\n  'score': '100'},\n {'answer': ' This article used Stable Diffusion (SD) and SDEdit.',\n  'score': '100'},\n {'answer': ' Word-As-Image for Semantic Typography', 'score': '100'},\n {'answer': ' Stable Diffusion, SDEdit, DallE2, DallE2 with a letter specific prompt, CLIPDraw and a single-letter result.',\n  'score': '80'},\n {'answer': ' DallE2', 'score': '80'},\n {'answer': ' CLIPDraw', 'score': '100'},\n {'answer': ' CLIPDraw with shape preservation losses', 'score': '100'},\n {'answer': ' Control points', 'score': '50'},\n {'answer': ' The article used the ∇ˆ𝑃LLSDS loss technique, and analyzed the effect of the weight 𝛼 applied to L𝑎𝑐𝑎𝑝 ranging from 1 to 0.',\n  'score': '90'},\n {'answer': ' This article used a CLIP based loss, while using proposed shape preservation terms.',\n  'score': '100'},\n {'answer': ' Stable Diffusion', 'score': '100'},\n {'answer': \" This article used a technique called P2P (2xP) to adjust control points as needed based on the user's personal taste and goals.\",\n  'score': '80'},\n {'answer': ' This article used a method for the automatic creation of vector-format word-as-image illustrations.',\n  'score': '100'},\n {'answer': ' This article used a technique of optimizing the shape of letters letter by letter.',\n  'score': '80'},\n {'answer': ' The article used methods such as Wang et al. 2022 and visual creativity to arrive at more synergistic design methods of ML models and humans.',\n  'score': '80'},\n {'answer': ' This article used a low pass filter with the L𝑡𝑜𝑛𝑒 loss and varying 𝜎parameters.',\n  'score': '90'},\n {'answer': ' This article used CLIP-based loss and SDS loss.',\n  'score': '100'},\n {'answer': ' This article used a technique called L𝑎𝑐𝑎𝑝, which alters the weight 𝛼of theL𝑎𝑐𝑎𝑝 loss.',\n  'score': '100'},\n {'answer': ' Word-As-Image for Semantic Typography', 'score': '100'},\n {'answer': ' This document does not answer the question.', 'score': '0'},\n {'answer': ' This article used SegDiff, an image segmentation technique with diffusion probabilistic models.',\n  'score': '100'},\n {'answer': ' Blended Diffusion and Multi-Content GAN', 'score': '100'},\n {'answer': ' Learning a Stroke-Based Representation for Fonts',\n  'score': '100'},\n {'answer': ' Stroke-Based Segmentation and Stylization of Fonts',\n  'score': '100'},\n {'answer': ' This article used manifold learning and transformer interpretability.',\n  'score': '80'},\n {'answer': ' ILVR: Conditioning Method for Denoising Diffusion Probabilistic Models',\n  'score': '100'},\n {'answer': ' SketchPatch: Sketch Stylization via Seamless Patch-Level Synthesis',\n  'score': '100'},\n {'answer': ' Text-to-Image Generation using Textual Inversion',\n  'score': '100'},\n {'answer': ' Designing an encoder for fast personalization of text-to-image models',\n  'score': '100'},\n {'answer': ' Denoising Diffusion Probabilistic Models', 'score': '100'},\n {'answer': ' VectorFusion: Text-to-SVG by Abstract', 'score': '100'},\n {'answer': ' Pixel-Based Diffusion Models', 'score': '100'},\n {'answer': ' EasyFont', 'score': '90'},\n {'answer': ' A learning-based system was used to build large-scale handwriting fonts.',\n  'score': '80'},\n {'answer': ' Towards Layer-wise Image Vectorization and Intelligent Typography: Artistic Text Style Transfer for Complex Texture and Structure.',\n  'score': '100'},\n {'answer': ' The article used Stochastic Differential Equations (SDE) for guided image synthesis and editing. ',\n  'score': '90'},\n {'answer': ' Latent-NeRF and Text2Mesh', 'score': '100'},\n {'answer': ' Glide: Towards photorealistic image generation and editing with text-guided diffusion models.',\n  'score': '100'},\n {'answer': ' Flexyfont and Dreamfusion', 'score': '100'},\n {'answer': ' Morphological analysis of shapes', 'score': '100'},\n {'answer': ' Hierarchical text-conditional image generation with clip latents.',\n  'score': '100'},\n {'answer': ' High-Resolution Image Synthesis with Latent Diffusion Models.',\n  'score': '100'},\n {'answer': ' DreamBooth: Fine Tuning Text-to-image Diffusion Models for Subject-Driven Generation.',\n  'score': '100'},\n {'answer': ' Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding and Diffusion Guided Domain Adaptation of Image Generators.',\n  'score': '100'},\n {'answer': ' Example-Based Automatic Font Generation and Thematic Reinforcement for Artistic Typography.',\n  'score': '100'},\n {'answer': ' Motionclip', 'score': '100'},\n {'answer': ' Word-As-Image for Semantic Typography', 'score': '100'},\n {'answer': ' Plug-and-Play Diffusion Features for Text-Driven Image-to-Image Translation and CLIPascene: Scene Sketching with Different Types and Levels of Abstraction.',\n  'score': '100'},\n {'answer': ' CLIPasso: Semantically-Aware Object Sketching', 'score': '100'},\n {'answer': ' Intelligent Text Style Transfer', 'score': '100'},\n {'answer': ' The article used DeepVecFont, a dual-modality learning technique, to synthesize high-quality vector fonts.',\n  'score': '100'},\n {'answer': ' Awesome Typography', 'score': '100'},\n {'answer': ' Statistics-Based Text Effects Transfer', 'score': '100'},\n {'answer': ' Shape-Matching GAN++: Scale Controllable Dynamic Artistic Text Style Transfer',\n  'score': '100'},\n {'answer': ' PointCLIP: Point Cloud Understanding by CLIP', 'score': '100'},\n {'answer': ' Shape skeletonization by identifying ', 'score': '100'},\n {'answer': ' Discrete local symmetries', 'score': '100'},\n {'answer': ' The pre-trained v1-5Stable Diffusion model [Rombach et al. 2021]',\n  'score': '100'},\n {'answer': ' The technique used in this article was Adam optimizer with a learning rate warm-up and exponential decay. ',\n  'score': '90'},\n {'answer': ' Random augmentations (perspective transform with a distortion scale of 0.5)',\n  'score': '100'},\n {'answer': ' The technique used was feeding a target word with the suffix \"a [ word ]. minimal flat 2d vector. lineal color. trending on artstation.\" into the text encoder of a pretrained CLIP model.',\n  'score': '100'},\n {'answer': ' Stable Diffusion and SDEdit', 'score': '100'},\n {'answer': ' This article used the Platen et al. 2022 implementation with 50 inference steps and a guidance scale of 7.5 and a strength value of 0.85. ',\n  'score': '100'},\n {'answer': \" The article used OpenAI's official website to run DallE2.\",\n  'score': '80'},\n {'answer': \" The article used the manipulation of a specific letter for DallE2+letter, and CLIPDraw with the author's official implementation and recommended hyper-parameters.\",\n  'score': '90'},\n {'answer': ' Word-as-image', 'score': '100'},\n {'answer': ' This article used a technique of dividing characters to radicals and applying the method only on the parts of the character.',\n  'score': '100'},\n {'answer': ' This article used a perceptual study to investigate the randomly chosen objects, fonts, and letters.',\n  'score': '80'},\n {'answer': ' This article used a proposed method combined with an SDS loss.',\n  'score': '100'},\n {'answer': ' This article used Word-As-Image for Semantic Typography.',\n  'score': '100'},\n {'answer': ' This article used Stable Diffusion, SDEdit, DallE2, DallE2 with a letter specific prompt, and CLIPDraw.',\n  'score': '100'},\n {'answer': ' This document does not answer the question.', 'score': '0'},\n {'answer': ' Word-as-image illustrations', 'score': '100'},\n {'answer': ' Word-as-image for Semantic Typography', 'score': '100'},\n {'answer': ' Word-as-image illustrations', 'score': '100'},\n {'answer': ' Word-as-image for Semantic Typography', 'score': '100'},\n {'answer': ' Word-as-image illustrations', 'score': '100'},\n {'answer': ' Word-as-image for Semantic Typography', 'score': '100'},\n {'answer': ' Word-as-image illustrations', 'score': '100'},\n {'answer': ' Word-As-Image for Semantic Typography', 'score': '100'},\n {'answer': ' This article used a technique to create word-as-image illustrations.',\n  'score': '80'},\n {'answer': ' Word-As-Image for Semantic Typography', 'score': '100'},\n {'answer': ' Word-as-image illustrations', 'score': '100'},\n {'answer': ' Word-as-image for Semantic Typography', 'score': '100'},\n {'answer': ' Word-as-image illustrations', 'score': '100'},\n {'answer': ' Word-as-image for Semantic Typography', 'score': '100'},\n {'answer': ' Word-as-image illustrations', 'score': '100'}]"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['intermediate_steps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be60b4e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
